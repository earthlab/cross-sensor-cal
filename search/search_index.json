{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"cross-sensor-cal","text":"<p>End-to-end NEON hyperspectral \u2192 ENVI export \u2192 BRDF+topo correction \u2192 cross-sensor convolution \u2192 Parquet export \u2192 DuckDB merge (new) \u2192 QA panel (restored).</p> <p>What\u2019s new</p> <ul> <li>Per-flightline master table written as <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code></li> <li>QA panel <code>&lt;prefix&gt;_qa.png</code> is emitted after the merge during full runs</li> </ul>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"benchmarks/#reproducible-timing-experiment-design","title":"Reproducible timing experiment design","text":"<ul> <li>Pin package versions and record hardware specifications.</li> <li>Use fixed random seeds and keep the system load constant.</li> <li>Run each benchmark multiple times, reporting mean and variance.</li> <li>Save the exact command line and configuration for future runs.</li> </ul>"},{"location":"benchmarks/#ray-cluster-knobs","title":"Ray cluster knobs","text":"<p>When scaling benchmarks on Ray, adjust:</p> <ul> <li><code>--num-cpus</code> and <code>--num-gpus</code> to control available resources.</li> <li><code>--object-store-memory</code> for large in-memory datasets.</li> <li><code>--temp-dir</code> to point to fast local storage.</li> <li><code>--dashboard-port</code> to monitor cluster status.</li> </ul>"},{"location":"benchmarks/#io-bottleneck-tips","title":"I/O bottleneck tips","text":"<ul> <li>Chunk rasters along the row and column dimensions so each worker reads contiguous blocks.</li> <li>Enable compression such as LZW or DEFLATE to reduce disk usage and transfer time.</li> <li>Cache intermediate products or use memory-mapped files to avoid repeated reads.</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The pipeline is configured through a <code>config.yaml</code> file that combines settings for every stage. Values shown below are the defaults unless marked as required.</p>"},{"location":"configuration/#schema","title":"Schema","text":"Key Type Default Required <code>base_folder</code> string <code>\"output\"</code> yes <code>download.site_code</code> string \u2014 yes <code>download.year_month</code> string (YYYYMM) \u2014 yes <code>download.flight_lines</code> list[string] \u2014 yes <code>download.product_code</code> string <code>\"DP1.30006.001\"</code> no <code>convert.export_ancillary</code> bool <code>true</code> no <code>convert.export_brdf_config</code> bool <code>true</code> no <code>topo_brdf.num_cpus</code> int <code>8</code> no <code>topo_brdf.file_type</code> string <code>\"envi\"</code> no <code>topo_brdf.corrections</code> list[string] <code>[\"topo\",\"brdf\"]</code> no <code>topo_brdf.bad_bands</code> list[int] <code>[]</code> no <code>topo_brdf.anc_files</code> map[string,str] \u2014 conditional\u2020 <code>topo_brdf.export.output_dir</code> string <code>\"./\"</code> no <code>topo_brdf.export.suffix</code> string <code>\"_corrected_envi\"</code> no <code>topo_brdf.export.image</code> bool <code>true</code> no <code>topo_brdf.export.masks</code> bool <code>true</code> no <code>topo_brdf.export.coeffs</code> bool <code>true</code> no <code>resample.method</code> string <code>\"convolution\"</code> no <code>resample.sensors</code> list[string] <code>[\"Landsat_8\"]</code> no <code>mask.polygon_layer</code> string \u2014 no <code>mask.raster_crs_override</code> string|int \u2014 no <code>mask.polygons_crs_override</code> string|int \u2014 no <code>mask.plot_output</code> bool <code>false</code> no <code>sort.remote_prefix</code> string <code>\"\"</code> no <code>sort.sync_files</code> bool <code>true</code> no <code>postprocess.reflectance_offset</code> int <code>0</code> no <p>\u2020 required when <code>topo_brdf.file_type</code> is <code>\"envi\"</code>.</p>"},{"location":"configuration/#example","title":"Example","text":"<pre><code>base_folder: output\n\ndownload:\n  site_code: NIWO\n  year_month: \"202008\"\n  flight_lines: [\"FL1\", \"FL2\"]\n  product_code: DP1.30006.001\n\nconvert:\n  export_ancillary: true\n  export_brdf_config: true\n\ntopo_brdf:\n  num_cpus: 8\n  file_type: envi\n  corrections: [\"topo\", \"brdf\"]\n  bad_bands: []\n  anc_files: {}\n  export:\n    output_dir: ./corrected\n    suffix: _corrected_envi\n    image: true\n    masks: true\n    coeffs: true\n\nresample:\n  method: convolution\n  sensors: [\"Landsat_8\"]\n\nmask:\n  polygon_layer: polygons.geojson\n  plot_output: false\n\nsort:\n  remote_prefix: \"\"\n  sync_files: true\n\npostprocess:\n  reflectance_offset: 0\n</code></pre>"},{"location":"configuration/#cli-overrides","title":"CLI overrides","text":"<p>The <code>cscal-pipeline</code> entry point automatically runs the download stage before spinning up per-flightline workers. Use <code>--max-workers</code> to opt into parallel processing once the <code>.h5</code> files are present. Command-line options override the corresponding entries in <code>config.yaml</code>:</p> <ul> <li><code>bin/jefe.py BASE_FOLDER SITE YEAR_MONTH FL1,FL2</code> sets <code>base_folder</code>, <code>download.site_code</code>, <code>download.year_month</code> and <code>download.flight_lines</code>.</li> <li><code>--polygon_layer_path</code> \u2192 <code>mask.polygon_layer</code></li> <li><code>--reflectance-offset</code> \u2192 <code>postprocess.reflectance_offset</code></li> <li><code>--remote-prefix</code> \u2192 <code>sort.remote_prefix</code></li> <li><code>--no-sync</code> sets <code>sort.sync_files</code> to <code>false</code></li> <li><code>--max-workers</code> sets the ThreadPool concurrency for <code>go_forth_and_multiply()</code></li> </ul>"},{"location":"cyverse-irods/","title":"CyVerse iRODS","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>CyVerse storage is accessed through iRODS paths handled by the <code>gocmd</code> utility. Remote locations are written with an <code>i:</code> prefix followed by the iRODS zone, for example <code>i:/iplant/home/your_username</code>.</p> <p>To authenticate, run <code>./gocmd init</code> once. The command records your credentials in <code>~/.irods</code> so future operations can reach the data store without re-entering them.</p> <p>Common operations:</p> <pre><code># list a collection\n./gocmd ls i:/iplant/home/your_username\n\n# download a file\n./gocmd get i:/iplant/home/your_username/data.txt\n\n# upload a file to a collection\n./gocmd put local_file.txt i:/iplant/home/your_username/\n</code></pre> <p>Scripts build remote paths using variables patterned as:</p> <pre><code>remote_path = f\"i:/iplant/{remote_prefix}/{dest_path}\"\n</code></pre> <p>Replace <code>remote_prefix</code> and <code>dest_path</code> with the appropriate subdirectory and filename for your project.</p>"},{"location":"dev-notes/","title":"Developer Notes","text":"<p>Use the following commands to work on the documentation locally:</p> <ol> <li>Install dependencies:    <code>bash    pip install -r docs/requirements.txt    # or    uv pip install -r docs/requirements.txt</code></li> <li>Start a live preview:    <code>bash    mkdocs serve</code></li> <li>Build the static site:    <code>bash    mkdocs build</code></li> </ol>"},{"location":"documentation-overview/","title":"Documentation","text":""},{"location":"documentation-overview/#overview","title":"Overview","text":"<p>This directory hosts project documentation, including the style guide that defines how you should write and maintain docs across the repository.</p>"},{"location":"documentation-overview/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Markdown viewer or editor</li> <li>Familiarity with basic Git workflows</li> </ul>"},{"location":"documentation-overview/#step-by-step-tutorial","title":"Step-by-step tutorial","text":"<ol> <li>Review the documentation style guide to    understand structure and formatting conventions.</li> <li>Create or update documentation in other folders using the guide's narrative    approach and examples.</li> <li>After editing, run <code>pytest</code> at the repository root to ensure code snippets    still execute.</li> </ol>"},{"location":"documentation-overview/#reference","title":"Reference","text":"<ul> <li><code>documentation_style_guide.md</code> \u2013 canonical guide for all project docs</li> </ul>"},{"location":"documentation-overview/#next-steps","title":"Next steps","text":"<p>Expand this folder with API references, architecture diagrams, or tutorials as the project evolves.</p>"},{"location":"documentation_style_guide/","title":"Cross-Sensor Calibration Documentation Style Guide","text":"<p>This guide establishes conventions for writing documentation in the Cross-Sensor Calibration project. Its goal is to create a linear, pedagogical narrative that makes the package easy to understand and adopt.</p>"},{"location":"documentation_style_guide/#philosophy","title":"Philosophy","text":"<ul> <li>Clarity first. Explain concepts in plain language before introducing technical jargon.</li> <li>Narrative flow. Documentation should guide the reader from inputs through processing to outputs in a logical order.</li> <li>Pragmatic examples. Every section should include code snippets or workflows that users can run directly.</li> <li>Minimal prerequisites. Link to background materials rather than assuming extensive prior knowledge.</li> </ul>"},{"location":"documentation_style_guide/#structure","title":"Structure","text":"<ol> <li>Overview \u2013 Briefly describe the purpose of the component and how it fits into the larger workflow.</li> <li>Prerequisites \u2013 List required data, dependencies, and setup steps.</li> <li>Step-by-step tutorial \u2013 Present instructions in chronological order.</li> <li>Reference \u2013 Provide detailed API descriptions, parameters, and links to source code.</li> <li>Next steps \u2013 Suggest follow-on tasks or sections.</li> </ol>"},{"location":"documentation_style_guide/#style","title":"Style","text":"<ul> <li>Use Markdown headings (<code>#</code>, <code>##</code>, <code>###</code>) to organize content.</li> <li>Write in the second person (\u201cyou\u201d) and active voice.</li> <li>Keep sentences concise; aim for one idea per sentence.</li> <li>Use numbered lists for sequences and bullet lists for options.</li> <li>Highlight file names, parameters, and code using backticks (<code>like_this</code>).</li> <li>Wrap code examples in fenced blocks with the appropriate language tag.</li> <li>Include diagrams or figures when they clarify complex processes.</li> <li>Cross-link related documents with relative paths.</li> </ul>"},{"location":"documentation_style_guide/#formatting","title":"Formatting","text":"<ul> <li>Line length: soft wrap at 100 characters.</li> <li>Use American English spelling.</li> <li>Date format: YYYY-MM-DD.</li> <li>Reference issues or pull requests with full links.</li> </ul>"},{"location":"documentation_style_guide/#maintenance","title":"Maintenance","text":"<ul> <li>Each documentation page must include a <code>Last updated: YYYY-MM-DD</code> line at the end.</li> <li>When updating docs, ensure examples are tested against the current codebase.</li> <li>Run <code>pytest</code> before committing changes that affect code examples.</li> </ul> <p>Following this guide will keep the documentation consistent and approachable for new contributors and users.</p>"},{"location":"env-setup/","title":"Environment Setup","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"env-setup/#conda-environment","title":"Conda environment","text":"<p>An example environment file for Conda is shown below. Save it as <code>environment.yaml</code> and create the environment with <code>conda env create -f environment.yaml</code>.</p> <pre><code>name: cross-sensor-cal\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.10\n  - gdal\n  - proj\n  - pip\n  - pip:\n      - ray[default]\n</code></pre>"},{"location":"env-setup/#uv-pip-alternative","title":"uv / pip alternative","text":"<p>Instead of Conda you can install the project with <code>uv</code> or plain <code>pip</code>:</p> <pre><code>uv pip install -r requirements.txt\n# or\npip install -r requirements.txt\n</code></pre>"},{"location":"env-setup/#gdal-proj-and-ray-notes","title":"GDAL, PROJ, and Ray notes","text":"<ul> <li>GDAL and PROJ require native libraries. Installing via the   <code>conda-forge</code> channel usually resolves most platform issues.</li> <li>Ray makes heavy use of shared memory. If Ray reports <code>/dev/shm</code> errors,   increase shared memory. For Docker containers use   <code>--shm-size=8g</code> (adjust as needed).</li> </ul>"},{"location":"env-setup/#known-os-quirks","title":"Known OS quirks","text":"<ul> <li>macOS: Homebrew installations of GDAL/PROJ may conflict with Conda.   Prefer the Conda packages or ensure <code>brew</code> paths come after Conda in <code>PATH</code>.</li> <li>Windows: enable long paths (<code>git config --system core.longpaths true</code>) to   avoid checkout errors.</li> </ul>"},{"location":"env-setup/#preview-documentation-locally","title":"Preview documentation locally","text":"<p>Run the MkDocs development server from the repository root:</p> <pre><code>mkdocs serve\n</code></pre> <p>Open http://127.0.0.1:8000 in a browser to view the docs.</p>"},{"location":"extending/","title":"Extending","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"extending/#add-a-sensor","title":"Add a sensor","text":""},{"location":"extending/#overview","title":"Overview","text":"<p>This recipe shows how to integrate a new sensor into the cross\u2011sensor calibration workflow.</p>"},{"location":"extending/#prerequisites","title":"Prerequisites","text":"<ul> <li>Spectral response function (SRF) curves for the sensor.</li> <li>Familiarity with the project's naming conventions.</li> </ul>"},{"location":"extending/#step-by-step-tutorial","title":"Step-by-step tutorial","text":"<ol> <li>Add SRFs. Place the sensor's SRF files in the data directory and register    them with the SRF loader.</li> <li>Update resampling/convolution mapping. Extend the resampling and    convolution dictionaries so the pipeline knows how to transform the sensor's    bands.</li> <li>Update the naming map. Insert the sensor's canonical name and band    identifiers into the shared naming map used across modules.</li> <li>Add a golden test and validation checklist.</li> <li>Create a golden test case with expected outputs.</li> <li>Document validation steps to confirm the sensor behaves correctly.</li> </ol>"},{"location":"extending/#next-steps","title":"Next steps","text":"<p>Run the full validation suite and submit a pull request for review.</p> <p>Last updated: 2025-08-18</p>"},{"location":"faq/","title":"FAQ","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"faq/#which-crs-should-i-use","title":"Which CRS should I use?","text":"<p>Use a projected CRS (e.g., UTM) consistent across inputs; the workflow reprojects mismatched scenes.</p>"},{"location":"faq/#how-are-missing-ancillary-inputs-handled","title":"How are missing ancillary inputs handled?","text":"<p>Stages log the omission and skip affected products; the run continues with available data.</p>"},{"location":"faq/#can-i-resume-a-partially-completed-run","title":"Can I resume a partially completed run?","text":"<p>Yes. Rerun the same stage and existing outputs are detected and skipped.</p>"},{"location":"faq/#how-do-i-add-support-for-a-new-sensor","title":"How do I add support for a new sensor?","text":"<p>Create a sensor definition with its band metadata and register it in the configuration file.</p>"},{"location":"faq/#why-dont-mesma-fractional-totals-sum-to-1","title":"Why don't MESMA fractional totals sum to 1?","text":"<p>Residual fractions capture unmodeled materials and numerical error, so sums may differ from one.</p>"},{"location":"faq/#where-can-i-find-logs-and-manifests","title":"Where can I find logs and manifests?","text":"<p>Each run writes to <code>logs/</code> and <code>manifests/</code> directories inside the output folder.</p>"},{"location":"faq/#do-i-have-to-run-every-processing-stage","title":"Do I have to run every processing stage?","text":"<p>No. You can run individual stages; each reads from the previous stage's outputs.</p>"},{"location":"faq/#how-do-i-change-the-working-directories","title":"How do I change the working directories?","text":"<p>Set <code>work_dir</code> and <code>output_dir</code> in the configuration to point to desired locations.</p>"},{"location":"faq/#how-should-i-cite-this-project","title":"How should I cite this project?","text":"<p>Reference the <code>CITATION.cff</code> file or the DOI listed in the repository.</p>"},{"location":"faq/#are-intermediate-files-cleaned-up-automatically","title":"Are intermediate files cleaned up automatically?","text":"<p>Temporary products remain unless you enable the cleanup option in the configuration.</p> <p>Last updated: 2025-08-18</p>"},{"location":"glossary/","title":"Glossary","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <ul> <li>AOP: Apparent Optical Property describing how a medium's optical characteristics vary with viewing geometry.</li> <li>BRDF: Bidirectional Reflectance Distribution Function giving reflectance as a function of illumination and view angles.</li> <li>SRF: Spectral Response Function representing a sensor's sensitivity across wavelengths.</li> <li>SNR: Signal-to-Noise Ratio, the level of desired signal relative to background noise.</li> <li>ENVI: Environment for Visualizing Images, a software package for processing geospatial imagery.</li> <li>MESMA: Multiple Endmember Spectral Mixture Analysis, an unmixing algorithm using variable endmember sets.</li> <li>DN: Digital Number, the raw quantized value recorded by a sensor.</li> <li>TOA: Top of Atmosphere reflectance measured above the atmosphere.</li> <li>BOA: Bottom of Atmosphere or surface reflectance after atmospheric correction.</li> <li>NIR: Near Infrared region of the electromagnetic spectrum, roughly 0.7\u20131.3 \u00b5m.</li> <li>SWIR: Shortwave Infrared region spanning approximately 1.3\u20132.5 \u00b5m.</li> <li>VIS: Visible portion of the electromagnetic spectrum between about 0.4\u20130.7 \u00b5m.</li> <li>FLAASH: Fast Line-of-sight Atmospheric Analysis of Spectral Hypercubes, an atmospheric correction tool.</li> <li>LiDAR: Light Detection and Ranging, active remote sensing using laser pulses to measure distance.</li> <li>UAV: Uncrewed Aerial Vehicle used as a platform for acquiring high-resolution imagery.</li> <li>NDVI: Normalized Difference Vegetation Index calculated from NIR and red bands to indicate vegetation vigor.</li> <li>MODIS: Moderate Resolution Imaging Spectroradiometer, a multispectral sensor on NASA's Terra and Aqua satellites.</li> <li>GSD: Ground Sample Distance, the ground size represented by one image pixel.</li> <li>RSR: Relative Spectral Response, the normalized sensitivity of a detector as a function of wavelength.</li> <li>AVIRIS: Airborne Visible/Infrared Imaging Spectrometer, a NASA hyperspectral imaging instrument.</li> </ul>"},{"location":"naming-conventions/","title":"Naming Conventions","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"naming-conventions/#canonical-filename-pattern","title":"Canonical Filename Pattern","text":"<p>All files produced by the pipeline use a common token order:</p> <pre><code>NEON_{site}_{YYYYMMDD}_{HHMMSS}_FL{line}_{product}{suffix}.ext\n</code></pre> <ul> <li><code>site</code> \u2013 NEON site code (e.g., <code>SJER</code>)</li> <li><code>YYYYMMDD</code> and <code>HHMMSS</code> \u2013 acquisition date and time in UTC</li> <li><code>FL{line}</code> \u2013 zero\u2011padded flight line identifier</li> <li><code>product</code> \u2013 base product name (e.g., <code>NIS</code>)</li> <li><code>suffix</code> \u2013 processing state (see table below)</li> <li><code>ext</code> \u2013 file extension such as <code>.img</code> or <code>.hdr</code></li> </ul> <p>Regex</p> <pre><code>^NEON_[A-Z0-9]{4}_\\d{8}_\\d{6}_FL\\d{3}_[A-Za-z0-9]+(?:_radiance|_ancillary|_corrected_envi|_reflectance)\\.(?:img|hdr)$\n</code></pre>"},{"location":"naming-conventions/#standard-suffixes","title":"Standard Suffixes","text":"Suffix Meaning <code>_radiance</code> Raw radiance from HDF5 conversion <code>_ancillary</code> Ancillary data produced with radiance <code>_corrected_envi</code> BRDF/TOPO corrected ENVI image <code>_reflectance</code> Final reflectance product"},{"location":"naming-conventions/#directory-layout","title":"Directory Layout","text":"<pre><code>site/\n\u2514\u2500\u2500 YYYYMMDD/\n    \u2514\u2500\u2500 FL###/\n        \u251c\u2500\u2500 raw/\n        \u2502   \u251c\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_radiance.img\n        \u2502   \u2514\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_ancillary.img\n        \u2514\u2500\u2500 derived/\n            \u251c\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_corrected_envi.img\n            \u2514\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_corrected_envi.hdr\n</code></pre>"},{"location":"naming-conventions/#common-violations-fixes","title":"Common Violations &amp; Fixes","text":"Violation Why it matters Fix Missing flight line token Downstream scripts cannot group files Include <code>_FL###</code> before the suffix Wrong suffix for directory (e.g., <code>_radiance</code> in <code>derived/</code>) Causes processing confusion Move file to <code>raw/</code> or rename with proper suffix Lower\u2011case site code Breaks regex patterns Use upper\u2011case site codes Spaces instead of underscores Parsing fails Replace spaces with <code>_</code>"},{"location":"overview/","title":"Overview","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The Cross\u2011Sensor Calibration workflow runs every NEON flight line through an idempotent, restart-safe series of five stages. Each stage emits tqdm-style progress bars, prefixes logs with <code>[flight_stem]</code>, and writes artifacts using canonical paths from :func:<code>cross_sensor_cal.utils.naming.get_flight_paths</code>.</p> <pre><code>flowchart LR\n    D[Download .h5]\n    E[Export ENVI]\n    J[Build BRDF+topo JSON]\n    C[Correct reflectance]\n    R[Resample + Parquet]\n    D --&gt; E --&gt; J --&gt; C --&gt; R\n</code></pre> <ul> <li>Download: <code>stage_download_h5()</code> restores automatic retrieval of NEON   directional reflectance cubes and leaves each <code>.h5</code> in the workspace root for   easy cleanup.</li> <li>ENVI export: Converts the HDF5 cube to   <code>&lt;base&gt;/&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.img/.hdr/.parquet</code> with per-tile   progress updates.</li> <li>BRDF + topo JSON: Computes correction parameters once per flight line and   records them in <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code> inside the   dedicated subdirectory.</li> <li>BRDF + topo correction: Streams a chunk progress bar while writing the   canonical corrected cube (<code>*_brdfandtopo_corrected_envi.img/.hdr/.parquet</code>).</li> <li>Sensor resample + Parquet: Produces per-sensor ENVI pairs and matching   Parquet summaries in the same subfolder, leaving the raw <code>.h5</code> untouched.</li> </ul> <p>Every derived artifact now lives under <code>&lt;base&gt;/&lt;flight_stem&gt;/</code>, keeping the workspace organized and allowing long-term retention of processed products without stockpiling multi-gigabyte <code>.h5</code> inputs. <code>_scoped_log_prefix()</code> keeps parallel runs legible while <code>max_workers</code> lets you opt into ThreadPool-powered concurrency once downloads finish.</p>"},{"location":"overview/#who-is-this-for","title":"Who is this for?","text":"<p>Researchers processing NEON AOP flight lines who need reproducible ENVI deliverables, per-sensor band stacks, and Parquet summaries for cross-sensor analysis. All scientific calculations remain unchanged from previous releases\u2014 the 2025 refresh focuses on workflow, performance, and restart safety.</p>"},{"location":"pipeline/","title":"Pipeline reference","text":"<p>Cross-Sensor Calibration orchestrates the same five ordered stages for every flight line. Each stage consults <code>get_flight_paths()</code> to locate its inputs, per-flightline working directory, and outputs, validates artifacts before working, and emits emoji-rich logs that make the restart-safe behavior explicit. All persistent products land inside <code>&lt;base_folder&gt;/&lt;flight_stem&gt;/</code> (with the raw <code>.h5</code> kept at the base root) and include ENVI (<code>.img/.hdr</code>), JSON metadata, and Parquet summaries.</p>"},{"location":"pipeline/#canonical-paths-via-get_flight_paths","title":"Canonical paths via <code>get_flight_paths()</code>","text":"<p><code>get_flight_paths(base_folder, flight_stem)</code> is the authoritative source of truth for every artifact the pipeline reads or writes. For a flight line with stem <code>&lt;flight_stem&gt;</code> it yields:</p> <ul> <li><code>h5_path</code> \u2192 <code>&lt;base_folder&gt;/&lt;flight_stem&gt;.h5</code></li> <li><code>work_dir</code> \u2192 <code>&lt;base_folder&gt;/&lt;flight_stem&gt;/</code></li> <li><code>raw_envi_img</code> / <code>raw_envi_hdr</code> \u2192 <code>&lt;flight_stem&gt;_envi.img</code> and   <code>&lt;flight_stem&gt;_envi.hdr</code> inside <code>work_dir</code></li> <li><code>correction_json</code> \u2192 <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code> in   <code>work_dir</code></li> <li><code>corrected_img</code> / <code>corrected_hdr</code> \u2192   <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.img</code> and   <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.hdr</code></li> <li><code>sensor_products</code> \u2192 a dict mapping each sensor (e.g. <code>landsat_tm</code>,   <code>landsat_etm+</code>, <code>landsat_oli</code>, <code>landsat_oli2</code>, <code>micasense</code>) to   <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.img</code> /   <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.hdr</code></li> <li><code>parquet_products</code> \u2192 optional Parquet summaries colocated with their source   rasters</li> </ul> <p>All stages request their expected paths from this function and refuse to invent filenames on the fly. If naming ever changes, update <code>get_flight_paths()</code> once rather than editing every stage.</p>"},{"location":"pipeline/#stage-by-stage-details","title":"Stage-by-stage details","text":"<p>Every stage is restart-safe: it skips itself when valid outputs already exist. Validation requires both sides of an ENVI pair to exist and be non-empty or, for JSON, the file must parse successfully. When a stage skips, it logs a <code>\u2705 ... (skipping)</code> message; otherwise it performs work and logs what it produced. Live tqdm progress bars accompany downloads, ENVI chunk exports, and BRDF+topo corrections.</p>"},{"location":"pipeline/#0-download-neon-hdf5","title":"0. Download NEON HDF5","text":"<ul> <li>Inputs</li> <li>NEON site code, product code, and flight stem.</li> <li>Outputs</li> <li><code>&lt;base_folder&gt;/&lt;flight_stem&gt;.h5</code> (left in the workspace root).</li> <li>Skip criteria</li> <li>Existing <code>.h5</code> file that passes a size/metadata sanity check.</li> <li>Logging</li> <li>Logs <code>\ud83d\udce5 stage_download_h5()</code> with a streaming byte counter while downloading.</li> <li>On skip emits <code>\u2705 stage_download_h5() found existing .h5 (skipping)</code>.</li> <li>Failure handling</li> <li>Raises on HTTP errors or truncated downloads; reruns resume by revalidating the file.</li> </ul>"},{"location":"pipeline/#1-envi-export","title":"1. ENVI export","text":"<ul> <li>Inputs</li> <li>NEON directional reflectance cube (<code>&lt;flight_stem&gt;.h5</code>).</li> <li>Outputs</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.img</code></li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.hdr</code></li> <li>Extras</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.parquet</code> (summary statistics per tile).</li> <li>Skip criteria</li> <li>Both ENVI files exist, are non-empty, and pass the internal ENVI validation.</li> <li>Logging</li> <li>Always logs <code>\ud83d\udd0e ENVI export target for &lt;flight_stem&gt; is ..._envi.img / ..._envi.hdr</code> with a chunked progress bar.</li> <li>On skip emits     <code>\u2705 ENVI export already complete for &lt;flight_stem&gt; -&gt; ..._envi.img / ..._envi.hdr (skipping heavy export)</code>.</li> <li>Otherwise streams progress as tiles are written and logs success.</li> <li>Failure handling</li> <li>Errors here stop the stage; reruns regenerate if outputs were missing or invalid.</li> </ul>"},{"location":"pipeline/#2-build-correction-json","title":"2. Build correction JSON","text":"<ul> <li>Inputs</li> <li>Uncorrected ENVI pair from stage 1.</li> <li>Output</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code></li> <li>Skip criteria</li> <li>JSON exists and parses.</li> <li>Logging</li> <li>On skip logs     <code>\u2705 Correction JSON already complete for &lt;flight_stem&gt; -&gt; ..._brdfandtopo_corrected_envi.json (skipping)</code>.</li> <li>Otherwise logs that it is computing parameters and then writing the JSON.</li> <li>Failure handling</li> <li>Failures propagate so that reruns recompute the JSON before downstream stages continue.</li> </ul>"},{"location":"pipeline/#3-brdf-topographic-correction","title":"3. BRDF + topographic correction","text":"<ul> <li>Inputs</li> <li>Uncorrected ENVI pair.</li> <li>Correction JSON from stage 2.</li> <li>Outputs</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.img</code></li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.hdr</code></li> <li>Extras</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.parquet</code></li> <li>Skip criteria</li> <li>Corrected ENVI pair exists, is non-empty, and validates.</li> <li>Logging</li> <li>On skip logs     <code>\u2705 BRDF+topo correction already complete for &lt;flight_stem&gt; -&gt; ..._brdfandtopo_corrected_envi.img / ..._brdfandtopo_corrected_envi.hdr (skipping)</code>.</li> <li>When recomputing, streams a chunk progress bar while writing and logs completion.</li> <li>Failure handling</li> <li>Failures raise immediately because the corrected cube is the canonical science product.     Reruns recompute just this stage if its outputs were missing or corrupt.</li> </ul>"},{"location":"pipeline/#4-sensor-convolution-resampling","title":"4. Sensor convolution / resampling","text":"<ul> <li>Inputs</li> <li>Corrected ENVI pair from stage 3. This stage never reads the raw <code>.h5</code>.</li> <li>Sensor spectral response library bundled with the project.</li> <li>Outputs</li> <li>For each known sensor, an ENVI pair following     <code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.img</code> /     <code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.hdr</code> (e.g.     <code>.../NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance_landsat_tm_envi.img</code>).</li> <li>Extras</li> <li>Optional Parquet tables named <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.parquet</code> in     the same folder.</li> <li>Skip criteria</li> <li>Individual sensor ENVI pairs that already exist and validate are skipped and reported.</li> <li>Logging</li> <li>Begins with <code>\ud83c\udfaf Convolving corrected reflectance for &lt;flight_stem&gt;</code>.</li> <li>On fresh generation logs     <code>\u2705 Wrote &lt;sensor_name&gt; product for &lt;flight_stem&gt; -&gt; ..._envi.img / ..._envi.hdr</code>.</li> <li>On skip logs     <code>\u2705 &lt;sensor_name&gt; product already complete for &lt;flight_stem&gt; -&gt; ... (skipping)</code>.</li> <li>Ends with     <code>\ud83d\udcca Sensor convolution summary for &lt;flight_stem&gt; | succeeded=[...] skipped=[...] failed=[...]</code>     followed by <code>\ud83c\udf89 Finished pipeline for &lt;flight_stem&gt;</code>.</li> <li>Failure handling</li> <li>Sensors are processed independently. Missing definitions or write failures mark that     sensor as <code>failed</code> but do not abort the stage unless all sensors fail and none were     previously valid. Partial success is acceptable.</li> </ul>"},{"location":"pipeline/#example-run-transcript","title":"Example run transcript","text":"<p>The restart-safe logs surface the exact work performed. A real rerun for one flight line now looks like:</p> <pre><code>[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\ude80 Processing ...\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udce5 stage_download_h5() found existing .h5 (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udd0e ENVI export target is ..._envi.img / ..._envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 ENVI export already complete -&gt; ..._envi.img / ..._envi.hdr (skipping heavy export)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Correction JSON already complete -&gt; ..._brdfandtopo_corrected_envi.json (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 BRDF+topo correction already complete -&gt; ..._brdfandtopo_corrected_envi.img / ..._brdfandtopo_corrected_envi.hdr (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83c\udfaf Convolving corrected reflectance\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Wrote landsat_tm product -&gt; ..._landsat_tm_envi.img / ..._landsat_tm_envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Wrote micasense product -&gt; ..._micasense_envi.img / ..._micasense_envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udcca Sensor convolution summary | succeeded=['landsat_tm', 'micasense'] skipped=['landsat_etm+', 'landsat_oli', 'landsat_oli2'] failed=[]\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83c\udf89 Finished pipeline\n</code></pre>"},{"location":"pipeline/#parallel-flightline-execution","title":"Parallel flightline execution","text":"<p>After all downloads succeed, <code>go_forth_and_multiply()</code> dispatches each flightline to a <code>ThreadPoolExecutor</code>. The <code>max_workers</code> argument controls the level of concurrency; leave it <code>None</code> to process sequentially. <code>_scoped_log_prefix()</code> prepends <code>[flight_stem]</code> to every log so parallel runs stay readable, and each worker writes only within its own <code>&lt;base&gt;/&lt;flight_stem&gt;/</code> directory to preserve idempotence.</p> <p>When <code>go_forth_and_multiply(...)</code> finishes looping over every requested flight line it logs <code>\u2705 All requested flightlines processed.</code> to confirm site-level completion.</p>"},{"location":"pipeline/#rerun-guidance","title":"Rerun guidance","text":"<p>Call <code>go_forth_and_multiply(...)</code> with the same parameters to rerun an entire site-month. The restart-safe checks ensure that valid artifacts are reused, missing or invalid stages are recomputed, and partial sensor failures do not stop progress across the rest of the flight lines. Because each sensor is accounted for independently, you can inspect the summary lists to see exactly which products succeeded, which were reused, and which need attention.</p>"},{"location":"qa/","title":"Quality Assurance (QA) panels","text":"<p>The <code>cscal-qa</code> command generates a summary PNG for each processed flight line. It combines visual checks and lightweight metadata to confirm that every stage of the pipeline completed successfully.</p> <p>QA figures are re-generated on every run so they always reflect the current pipeline settings. The spectral comparison panel converts reflectance to a unitless 0\u20131 scale and shades VIS/NIR/SWIR regions to make interpretation easier.</p> <pre><code>cscal-qa --base-folder output_demo\n# Optional: write all PNGs to a separate location\ncscal-qa --base-folder output_demo --out-dir qa-panels\n</code></pre> <p>QA panel example coming soon.</p> <p>Each panel validates a specific part of the workflow:</p> <ul> <li>Panel A \u2013 Raw ENVI RGB: Verifies that the uncorrected ENVI export opens and renders   with sensible colors and geospatial orientation.</li> <li>Panel B \u2013 Patch-mean spectrum: Overlays raw vs. BRDF+topo corrected spectra for a   central patch, highlights VIS/NIR/SWIR wavelength ranges, and plots the difference to   confirm the correction stage ran.</li> <li>Panel C \u2013 Corrected NIR preview: Displays a high-NIR band from the corrected cube to   spot striping, nodata gaps, or other artifacts.</li> <li>Panel D \u2013 Sensor thumbnails: Shows downsampled previews of each convolved sensor   product, confirming the resampling stage produced ENVI bandstacks.</li> <li>Panel E \u2013 Parquet summary: Lists the Parquet sidecars with file sizes so you can check   that tabular exports were written.</li> </ul> <p>Panels are written to <code>&lt;flight_stem&gt;_qa.png</code> inside each flight directory by default. Use <code>--out-dir</code> to aggregate them in a centralized folder for sharing or archival.</p>"},{"location":"qa/#qa-dashboard","title":"QA Dashboard","text":"<p>You can summarize QA performance across multiple flightlines with a single command:</p> <pre><code>cscal-qa-dashboard --base-folder output_fresh\n</code></pre> <p>This command:</p> <ul> <li>Aggregates all <code>*_qa_metrics.parquet</code> files,</li> <li>Computes per-flightline statistics,</li> <li>Writes a combined <code>qa_dashboard_summary.parquet</code>,</li> <li>Generates an overview plot (<code>qa_dashboard_summary.png</code>).</li> </ul> <p>Each bar represents the fraction of flagged bands per flightline. Values above <code>0.25</code> (25%) are marked with \u26a0\ufe0f and may require review.</p>"},{"location":"qa/#after-running","title":"\u2705 After running","text":"<p>Expected artifacts in <code>output_fresh/</code>:</p> <ul> <li><code>qa_dashboard_summary.parquet</code></li> <li><code>qa_dashboard_summary.png</code></li> </ul> <p>and log output similar to:</p> <pre><code>\ud83d\udcca Aggregated 12 flightlines (2400 rows)\n\u2705 Computed summary for 12 flightlines\n\ud83d\udcbe Wrote aggregated QA summary \u2192 qa_dashboard_summary.parquet\n\ud83d\uddbc\ufe0f Saved dashboard \u2192 qa_dashboard_summary.png\n</code></pre>"},{"location":"quickstart/","title":"Quickstart","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"quickstart/#small-dataset-quickstart","title":"Small Dataset Quickstart","text":"<p>This guide walks through processing a single NEON Airborne Observation Platform (AOP) hyperspectral flight line using the Cross\u2011Sensor Calibration workflow. It assumes only one flight line from the NIWO site in August 2023, which makes it a \"small dataset\" suitable for experimentation or learning.</p> <p>The workflow below demonstrates both the command\u2011line interface (CLI) and the equivalent Python API. All commands are copy\u2011paste ready and use the placeholder flight line:</p> <pre><code>NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance\n</code></pre>"},{"location":"quickstart/#1-environment-setup","title":"1. Environment Setup","text":"<ol> <li>Clone the repository and create a virtual environment.</li> <li>Activate the environment.</li> <li>Install the package in editable mode.</li> </ol> <pre><code>git clone https://github.com/example/cross-sensor-cal.git\ncd cross-sensor-cal\npython -m venv .venv\nsource .venv/bin/activate          # On Windows use: .venv\\Scripts\\activate\npip install -e .\n</code></pre>"},{"location":"quickstart/#2-prepare-the-data-directory","title":"2. Prepare the Data Directory","text":"<p>Create a dedicated base folder for this run. The pipeline will download each NEON <code>.h5</code> into this directory automatically and write derived products into per-flightline subfolders.</p> <pre><code>BASE=data/NIWO_2023-08\nmkdir -p \"$BASE\"\n</code></pre> <p>Optional: If you already have an HDF5 flight line, copy it into <code>\"$BASE\"</code>. Otherwise <code>stage_download_h5()</code> will stream it with a progress bar the first time you run the pipeline.</p>"},{"location":"quickstart/#3-run-the-cli-pipeline","title":"3. Run the CLI Pipeline","text":"<p>The <code>jefe.py</code> script orchestrates downloading, converting, correcting, and resampling in the refreshed five-stage order. The following command processes a single flight line and skips remote syncing.</p> <pre><code>FLIGHT_LINE=NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance\n\npython bin/jefe.py \\\n    \"$BASE\" \\\n    NIWO \\\n    2023-08 \\\n    \"$FLIGHT_LINE\" \\\n    --no-sync\n</code></pre> <p>Key options:</p> <ul> <li><code>\"$BASE\"</code> \u2013 output directory for all generated files.</li> <li><code>NIWO</code> \u2013 NEON site code.</li> <li><code>2023-08</code> \u2013 year and month of the flight.</li> <li><code>--no-sync</code> \u2013 generate results without uploading to iRODS.</li> </ul> <p>The script now shows per-flightline log prefixes and tqdm progress bars instead of the old <code>GRGRGR...</code> spam. Reruns surface idempotent skips such as:</p> <pre><code>[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udce5 stage_download_h5() found existing .h5 (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 ENVI export already complete -&gt; ..._envi.img / ..._envi.hdr (skipping heavy export)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 BRDF+topo correction already complete -&gt; ..._brdfandtopo_corrected_envi.img / ..._brdfandtopo_corrected_envi.hdr (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udcca Sensor convolution summary | succeeded=['landsat_tm', 'micasense'] skipped=['landsat_oli'] failed=[]\n</code></pre> <p>These messages confirm that outputs passed validation and the stage moved on without recomputing.</p>"},{"location":"quickstart/#4-python-api-equivalent","title":"4. Python API Equivalent","text":"<p>The same workflow can be scripted in Python for additional customization while preserving idempotent behaviour.</p> <pre><code>from pathlib import Path\n\nfrom cross_sensor_cal.pipelines.pipeline import go_forth_and_multiply\n\nbase = Path(\"data/NIWO_2023-08\")\nbase.mkdir(parents=True, exist_ok=True)\n\ngo_forth_and_multiply(\n    base_folder=base,\n    site_code=\"NIWO\",\n    year_month=\"2023-08\",\n    product_code=\"DP1.30006.001\",\n    flight_lines=[\n        \"NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance\",\n    ],\n    max_workers=2,\n)\n\n# Rerunning the exact command is safe; completed stages log \"skipping\" and are validated automatically.\n</code></pre>"},{"location":"quickstart/#5-expected-folder-structure","title":"5. Expected Folder Structure","text":"<p>Before running the pipeline:</p> <pre><code>data/\n\u2514\u2500\u2500 NIWO_2023-08/\n</code></pre> <p>After successful completion:</p> <pre><code>data/\n\u2514\u2500\u2500 NIWO_2023-08/\n    \u251c\u2500\u2500 NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance.h5\n    \u251c\u2500\u2500 NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance/\n    \u2502   \u251c\u2500\u2500 NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance_envi.img/.hdr/.parquet\n    \u2502   \u251c\u2500\u2500 NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance_brdfandtopo_corrected_envi.img/.hdr/.json/.parquet\n    \u2502   \u251c\u2500\u2500 NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance_landsat_tm_envi.img/.hdr/.parquet\n    \u2502   \u251c\u2500\u2500 NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance_micasense_envi.img/.hdr/.parquet\n    \u2502   \u2514\u2500\u2500 NIWO_brdf_model.json\n    \u2514\u2500\u2500 &lt;other flightlines follow the same pattern&gt;\n</code></pre> <p>The actual directory names may differ slightly depending on optional steps (e.g., polygon masking or resampling to additional sensors).</p>"},{"location":"quickstart/#6-minimal-validation-checklist","title":"6. Minimal Validation Checklist","text":"<ul> <li><code>&lt;flight_stem&gt;.h5</code> exists at the base folder root for each requested line.</li> <li><code>&lt;base&gt;/&lt;flight_stem&gt;/</code> contains ENVI, JSON, and Parquet products for that line.</li> <li>Logs include <code>[flight_stem]</code> prefixes with <code>\u2705 ... (skipping)</code> when rerunning on completed stages.</li> </ul> <p>All paths are relative to the repository root. Replace the placeholder flight line and site details as needed for other datasets.</p>"},{"location":"refactor_notes/","title":"Refactor Notes: HyTools-Free Pipeline","text":""},{"location":"refactor_notes/#purpose","title":"Purpose","text":"<p>These notes document the current cross-sensor-cal processing pipeline after removing the runtime dependency on HyTools. The steps below describe what the code does today so collaborators can reproduce results and audit intermediate products.</p>"},{"location":"refactor_notes/#end-to-end-pipeline","title":"End-to-End Pipeline","text":"<ol> <li> <p>Acquire NEON reflectance flightlines    Download or copy the required NEON Airborne Observation Platform (AOP) reflectance HDF5 files to a local workspace before running the pipeline.</p> </li> <li> <p>Convert HDF5 to ENVI without HyTools <code>neon_to_envi_no_hytools()</code> opens the HDF5 file with <code>NeonCube</code>, streams the cube out in spatial tiles, and writes a float32 BSQ ENVI dataset via <code>EnviWriter</code>. It simultaneously exports ancillary rasters (solar/sensor geometry, slope, aspect, etc.) needed for correction. The result is an uncorrected directional reflectance <code>.img/.hdr</code> pair for each flightline. HyTools and Ray are not invoked in this stage\u2014the conversion logic is entirely internal.</p> </li> <li> <p>Persist correction parameters <code>build_and_write_correction_json()</code> (in <code>brdf_topo.py</code>) inspects the flightline geometry, fits BRDF coefficients, and serialises the results as <code>&lt;flightline&gt;_brdfandtopo_corrected_envi.json</code>. The helper validates the JSON via <code>is_valid_json()</code> and reuses it on reruns when intact.</p> </li> <li> <p>Topographic and BRDF correction    The pipeline allocates a new corrected cube and uses <code>EnviWriter</code> to persist it. For every spatial tile it:</p> </li> <li>Reads the tile from the uncorrected ENVI export.</li> <li>Applies topographic correction using slope, aspect, and solar geometry rasters.</li> <li>Applies BRDF correction using the saved coefficient JSON. When coefficients are missing, unreadable, or poorly conditioned, the code logs a warning and falls back to neutral BRDF terms so the tile still receives topographic correction.</li> <li> <p>Optionally adds a <code>brightness_offset</code> before writing.    The corrected output <code>&lt;flightline&gt;_brdfandtopo_corrected_envi.img/.hdr</code> carries full spatial metadata plus the wavelength list, FWHM list, and wavelength units required for spectral resampling.</p> </li> <li> <p>Spectral convolution / sensor simulation <code>convolve_resample_product()</code> opens the corrected cube as a BSQ memmap, reads spatial tiles, transposes them to <code>(y, x, bands)</code>, and multiplies each tile by sensor-specific spectral response functions (SRFs). SRFs are loaded from JSON files under <code>cross_sensor_cal/data/</code> via package-relative paths. Each simulated sensor produces its own float32 BSQ ENVI product and header. Existing resampled outputs are validated with <code>is_valid_envi_pair()</code> and skipped when already complete.</p> </li> <li> <p>Downstream consumers (optional)    Additional tooling can derive pixel stacks, polygon summaries, or parquet tables from the corrected and resampled rasters. These consumers still function but are documented separately and are not detailed here.</p> </li> </ol> <p>Every step performs the same validation checks on reruns so the pipeline is safe to resume after interruptions or partial failures.</p> <ol> <li>Recommended artifact retention    Keep the following per flightline so downstream analyses and cross-sensor comparisons remain reproducible:</li> <li><code>&lt;flightline&gt;_directional_reflectance.img/.hdr</code></li> <li><code>&lt;flightline&gt;_brdfandtopo_corrected_envi.json</code></li> <li><code>&lt;flightline&gt;_brdfandtopo_corrected_envi.img/.hdr</code></li> <li><code>&lt;flightline&gt;_resampled_&lt;sensor&gt;.img/.hdr</code></li> </ol>"},{"location":"refactor_notes/#module-structure","title":"Module Structure","text":"<ul> <li><code>cross_sensor_cal/neon_cube.py</code></li> <li><code>NeonCube</code> class</li> <li>Opens NEON HDF5 reflectance, exposes dimensions, wavelengths, ancillary angles, etc.</li> <li>Iterates spatial tiles without requiring HyTools.</li> <li><code>cross_sensor_cal/envi_writer.py</code></li> <li><code>EnviWriter</code> class</li> <li>Writes BSQ float32 rasters (<code>.img/.hdr</code>).</li> <li>Used for uncorrected export, corrected cubes, and resampled products.</li> <li><code>cross_sensor_cal/corrections.py</code></li> <li><code>fit_and_save_brdf_model()</code></li> <li><code>apply_topo_correct()</code></li> <li><code>apply_brdf_correct()</code></li> <li>Includes helpers to load and apply BRDF coefficients.</li> <li><code>cross_sensor_cal/resample.py</code></li> <li><code>resample_chunk_to_sensor()</code></li> <li>SRF loading utilities</li> <li>Convolution-friendly helpers for chunk-wise processing.</li> <li><code>cross_sensor_cal/pipelines/pipeline.py</code></li> <li><code>go_forth_and_multiply()</code></li> <li>Orchestrates downloads, H5\u2192ENVI export (no HyTools), BRDF fitting, topographic+BRDF correction, and spectral convolution.</li> <li><code>cross_sensor_cal/data/</code></li> <li>SRF JSON files for Landsat, Sentinel, etc.</li> <li>Accessed via package-relative paths at runtime.</li> </ul>"},{"location":"refactor_notes/#licensing","title":"Licensing","text":"<p>Several algorithms and data-handling conventions in <code>NeonCube</code>, the correction routines, and ENVI export logic were adapted from the HyTools project (GPLv3). Although the refactored pipeline no longer imports HyTools at runtime, we continue to credit the original HyTools authors and comply with GPLv3 obligations for the adapted code.</p>"},{"location":"references/","title":"References","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"references/#cross-calibration","title":"Cross-calibration","text":"<ul> <li>Roy, D.P., Kovalskyy, V., Zhang, H., Vermote, E.F., &amp; Yan, L. (2016). Landsat-8 and Landsat-7 cross-calibration. Remote Sensing of Environment.</li> <li>Claverie, M., Ju, J., Masek, J.G., et al. (2018). The Harmonized Landsat and Sentinel-2 surface reflectance data set. Remote Sensing of Environment.</li> </ul>"},{"location":"references/#citing-this-project","title":"Citing this project","text":"<ul> <li>Earth Lab Data Innovation Team. (2025). Cross-Sensor Calibration (Version 2.2.0) [Software]. University of Colorado Boulder. https://github.com/earthlab/cross-sensor-cal</li> </ul>"},{"location":"references/#spectral-libraries","title":"Spectral libraries","text":"<ul> <li>Baldridge, A.M., Hook, S.J., Grove, C.I., &amp; Rivera, G. (2009). The ASTER spectral library version 2.0. Remote Sensing of Environment.</li> <li>Kokaly, R.F., Clark, R.N., et al. (2017). USGS Spectral Library Version 7. U.S. Geological Survey Data Series.</li> </ul>"},{"location":"references/#mesma","title":"MESMA","text":"<ul> <li>Roberts, D.A., Gardner, M., Church, R., Ustin, S., Scheer, G., &amp; Green, R.O. (1998). Mapping chaparral in the Santa Monica Mountains using multiple endmember spectral mixture models. Remote Sensing of Environment.</li> <li>Powell, R.L., Roberts, D.A., Dennison, P.E., &amp; Hess, L.L. (2007). Sub-pixel mapping of urban land cover using MESMA. Remote Sensing of Environment.</li> </ul>"},{"location":"references/#brdftopo","title":"BRDF/topo","text":"<ul> <li>Li, X., &amp; Strahler, A.H. (1992). Geometric-optical bidirectional reflectance modeling of the discrete crown vegetation canopy. IEEE Transactions on Geoscience and Remote Sensing.</li> <li>Schaaf, C.B., Gao, F., et al. (2002). First operational BRDF, albedo, and nadir reflectance products from MODIS. Remote Sensing of Environment.</li> <li>Colby, J.D. (1991). Topographic normalization in remote sensing. Remote Sensing of Environment.</li> </ul>"},{"location":"schemas/","title":"Schemas","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"schemas/#raster-band-metadata-schema","title":"Raster band metadata schema","text":"<p>Describes the properties of each raster band after resampling or convolution.</p> Field Type Units Description <code>band</code> int \u2013 Sequential band number <code>wavelength_nm</code> float nm Center wavelength <code>fwhm_nm</code> float nm Full width at half maximum <code>unit</code> string \u2013 Measurement units for reflectance <p>Example JSON:</p> <pre><code>[\n  {\"band\": 1, \"wavelength_nm\": 450.0, \"fwhm_nm\": 20.0, \"unit\": \"nm\"},\n  {\"band\": 2, \"wavelength_nm\": 550.0, \"fwhm_nm\": 25.0, \"unit\": \"nm\"}\n]\n</code></pre>"},{"location":"schemas/#pixel-table-schema","title":"Pixel table schema","text":"<p>Each row represents one pixel extracted from a raster scene.</p> Column Type Units Description <code>Pixel_ID</code> int \u2013 Unique pixel identifier <code>Pixel_Row</code> int row Raster row index (0\u2011based) <code>Pixel_Col</code> int col Raster column index (0\u2011based) <code>B1..Bn</code> float reflectance Band reflectance values <p>Example table:</p> Pixel_ID Pixel_Row Pixel_Col B1 B2 B3 1 10 15 0.12 0.09 0.03 2 11 16 0.10 0.08 0.02"},{"location":"schemas/#spectral-library-schema","title":"Spectral library schema","text":"<p>Spectral libraries store reference spectra for endmembers used during unmixing. When saved as JSON or Parquet, each record contains:</p> Field Type Description <code>spectrum_id</code> string Unique identifier <code>class_label</code> string Endmember class (e.g., soil, vegetation) <code>wavelength_nm</code> array Wavelength centers <code>reflectance</code> array Corresponding reflectance values <code>metadata</code> object Optional information (sensor, date, notes, etc.) <p>Example JSON entry:</p> <pre><code>{\n  \"spectrum_id\": \"veg01\",\n  \"class_label\": \"vegetation\",\n  \"wavelength_nm\": [450, 550, 650],\n  \"reflectance\": [0.12, 0.32, 0.45],\n  \"metadata\": {\"sensor\": \"NEON\", \"acquired\": \"2020-08-01\"}\n}\n</code></pre>"},{"location":"schemas/#mesma-outputs-schema","title":"MESMA outputs schema","text":"<p>Results from Multiple Endmember Spectral Mixture Analysis for each pixel.</p> Column Type Units Description <code>Pixel_ID</code> int \u2013 Input pixel identifier <code>fraction_*</code> float fraction Fractional abundance per endmember band <code>RMSE</code> float reflectance Root mean square error of the model fit <code>QA</code> int \u2013 Quality flag (0=good, higher=worse) <p>Example table:</p> Pixel_ID fraction_soil fraction_veg RMSE QA 1 0.40 0.60 0.01 0 2 0.55 0.45 0.02 1 <p>Example JSON line for one pixel:</p> <pre><code>{\n  \"Pixel_ID\": 1,\n  \"fraction_soil\": 0.40,\n  \"fraction_veg\": 0.60,\n  \"RMSE\": 0.01,\n  \"QA\": 0\n}\n</code></pre> <p>Last updated: 2025-08-18</p>"},{"location":"stage-03-pixel-extraction/","title":"Stage 03 Pixel Extraction","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"stage-03-pixel-extraction/#overview","title":"Overview","text":"<p>At this stage you sample pixels from the sorted scenes and write the values to a tabular file. The table becomes the input to spectral unmixing and other downstream analyses.</p>"},{"location":"stage-03-pixel-extraction/#sampling-rules","title":"Sampling rules","text":"<ol> <li>Define a consistent random seed so repeated runs draw the same pixels.</li> <li>Sample within each land\u2010cover class or tile to avoid geographic bias.</li> <li>Drop any pixel flagged by a quality mask or falling outside the region of interest.</li> </ol>"},{"location":"stage-03-pixel-extraction/#handling-nodata-and-masks","title":"Handling nodata and masks","text":"<ul> <li>Treat nodata values (<code>-9999</code> by default) as missing and skip those records.</li> <li>Apply cloud, shadow, and water masks before sampling so invalid pixels never reach the table.</li> <li>Keep a boolean <code>is_masked</code> column to track which values were rejected.</li> </ul>"},{"location":"stage-03-pixel-extraction/#tile-vs-full-scene","title":"Tile vs full scene","text":"<ul> <li>Tiles scale better for large mosaics and let you parallelize extraction.</li> <li>Full scenes are faster when memory allows and ensure contiguous coverage. Choose the approach that matches your hardware and scene size; the output format is identical.</li> </ul>"},{"location":"stage-03-pixel-extraction/#output-tables","title":"Output tables","text":"<p>Each row represents one pixel. Columns typically include <code>scene_id</code>, <code>tile_id</code>, <code>x</code>, <code>y</code>, band values, and <code>is_masked</code>. Write tables as CSV for quick inspection or Parquet for efficient storage. Keep Parquet outputs in a <code>full_extracted_pixels</code> folder that lives alongside the tile folder so the extracted tables sit next to, not inside, the source data. Partition by scene and tile so you can read subsets without loading the whole dataset.</p>"},{"location":"stage-03-pixel-extraction/#memory-tips","title":"Memory tips","text":"<ul> <li>Process one tile at a time and release arrays with <code>del</code> to free RAM.</li> <li>When writing CSV, stream rows with a generator instead of building a huge DataFrame.</li> <li>Prefer Parquet with compression to reduce disk use and load times.</li> </ul>"},{"location":"stage-03-pixel-extraction/#quick-integrity-checks","title":"Quick integrity checks","text":"<ul> <li>Confirm row counts match the number of valid pixels expected per tile.</li> <li>Scan for remaining nodata values: <code>rg -n \"-9999\" sample.csv</code>.</li> <li>Plot a histogram of one band to detect obvious outliers before moving on.</li> </ul>"},{"location":"stage-03-pixel-extraction/#next-steps","title":"Next steps","text":"<p>Continue to Stage 04 to build the spectral library from the extracted pixels.</p> <p>Last updated: 2025-08-18</p>"},{"location":"stage-04-spectral-library/","title":"Stage 04 Spectral Library","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The spectral library stores every spectrum with its full provenance. Each entry includes:</p> <ul> <li><code>site</code>: location identifier where you collected the field sample.</li> <li><code>sensor</code>: instrument or platform that measured the spectrum.</li> <li><code>wavelengths</code>: array of nanometer values shared across spectra.</li> </ul> <p>These fields live alongside the reflectance values in a row-oriented table or NetCDF group. Use them to filter spectra by site, compare sensors, or align data to the wavelength grid.</p>"},{"location":"stage-04-spectral-library/#quality-controls","title":"Quality controls","text":"<p>You can clean spectra before analysis:</p> <ol> <li>Outlier filtering \u2013 drop samples that exceed three standard deviations from the mean reflectance    at any wavelength.</li> <li>Smoothing \u2013 apply a Savitzky\u2013Golay or moving-average filter to reduce instrument noise while    preserving absorption features.</li> <li>Signal-to-noise ratio (SNR) \u2013 flag spectra with low SNR and exclude them from downstream    modeling.</li> </ol>"},{"location":"stage-04-spectral-library/#versioning-and-provenance","title":"Versioning and provenance","text":"<p>Each library release increments a semantic version. A <code>manifest.json</code> file lists source datasets, processing code commits, and software versions so you can reproduce the library or audit its origin.</p> <p>Last updated: 2025-08-18</p>"},{"location":"stage-05-mesma/","title":"Stage 05 MESMA","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"stage-05-mesma/#using-the-spectral-library","title":"Using the spectral library","text":"<p>The spectral library from Stage 04 provides the candidate endmember spectra. You load it as a NumPy array and pass it to the MESMA routine alongside the target image. MESMA iterates through library combinations to find the model with the lowest root mean square error (RMSE).</p> <pre><code>from unmixing.el_mesma import MesmaCore\n\nmesma = MesmaCore()\nfractions, residuals = mesma._mesma(image, library)\n</code></pre>"},{"location":"stage-05-mesma/#endmember-selection-strategies","title":"Endmember selection strategies","text":"<ul> <li>Exhaustive search \u2013 evaluate all combinations up to a fixed complexity.</li> <li>Class-based \u2013 restrict models to endmembers drawn from predefined   classes such as vegetation or soil.</li> <li>Random sampling \u2013 sample combinations to reduce runtime for large   libraries.</li> </ul>"},{"location":"stage-05-mesma/#outputs","title":"Outputs","text":"<ul> <li>Per-endmember fraction maps showing the proportional contribution of each   material and a shade fraction.</li> <li>A residual raster capturing the difference between observed and reconstructed   spectra.</li> </ul>"},{"location":"stage-05-mesma/#validation","title":"Validation","text":"<ul> <li>Verify that the fractions for each pixel sum to approximately <code>1.0</code>.</li> <li>Discard models with RMSE above a user-defined threshold to ensure a reliable   fit.</li> </ul> <p>Last updated: 2025-08-18</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> Symptom Likely cause Fix Ray <code>/dev/shm</code> warning Shared-memory mount <code>/dev/shm</code> is too small for Ray workers Re-run container with larger <code>--shm-size</code> or set <code>RAY_TMPDIR</code> to a directory with more space \u201cstrict filename parsing\u201d errors Input file names do not match expected naming pattern Rename files to conform to the expected pattern or disable strict parsing in configuration \u201cmetadata injection\u201d path mismatches Paths embedded in metadata don't match actual file layout Verify and correct paths before running metadata injection ENVI header/BSQ mismatches <code>.hdr</code> and <code>.bsq</code> files are out of sync or corrupted Recreate the header or regenerate the BSQ to ensure matching metadata and data files 255 max-value columns in CSVs Columns stored as unsigned 8-bit integers use 255 as a sentinel Convert columns to a wider type and replace 255 with a nodata value iRODS transient failures Temporary network or server issue when communicating with iRODS Retry the operation after a delay; consider using built-in retry mechanisms"},{"location":"validation/","title":"Validation","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The validation procedure ensures quality across the pipeline.</p>"},{"location":"validation/#stage-01-raster-processing","title":"Stage 01 \u2013 Raster Processing","text":"<ul> <li>[ ] Confirm input rasters exist and are readable.</li> <li>[ ] Check projection and resolution match expected values.</li> <li>[ ] Verify no bands contain all nodata values.</li> <li>[ ] Ensure output rasters write successfully.</li> </ul> <pre><code>import rasterio, numpy as np\nwith rasterio.open(\"image.tif\") as src:\n    data = src.read()\n    assert not np.isnan(data).all(axis=(1, 2))\n</code></pre>"},{"location":"validation/#stage-02-sorting","title":"Stage 02 \u2013 Sorting","text":"<ul> <li>[ ] Confirm filenames follow <code>YYYYMMDD_sensor.tif</code> pattern.</li> <li>[ ] Check chronological ordering after sorting.</li> <li>[ ] Verify number of files per date matches expected counts.</li> </ul> <pre><code>import pandas as pd, glob\nfiles = sorted(glob.glob(\"sorted/*.tif\"))\ndates = pd.to_datetime([f.split(\"_\")[0] for f in files])\nassert dates.is_monotonic_increasing\n</code></pre>"},{"location":"validation/#stage-03-pixel-extraction","title":"Stage 03 \u2013 Pixel Extraction","text":"<ul> <li>[ ] Ensure sample coordinates fall within raster bounds.</li> <li>[ ] Validate pixel value ranges for each band.</li> <li>[ ] Cross-check sample count with original list.</li> </ul> <pre><code>import numpy as np, pandas as pd\npixels = pd.read_csv(\"pixels.csv\")\nassert ((pixels['x']&gt;=0) &amp; (pixels['y']&gt;=0)).all()\nassert pixels.drop(columns=['x','y']).apply(np.isfinite).all().all()\n</code></pre>"},{"location":"validation/#stage-04-spectral-library","title":"Stage 04 \u2013 Spectral Library","text":"<ul> <li>[ ] Verify spectra length equals number of bands.</li> <li>[ ] Check for duplicated materials or IDs.</li> <li>[ ] Inspect outlier reflectance values.</li> </ul> <pre><code>import pandas as pd\nlib = pd.read_csv(\"library.csv\")\nlib.groupby(\"material\").size().pipe(print)\nassert (lib.filter(like=\"band\") &lt;= 1).all().all()\n</code></pre>"},{"location":"validation/#stage-05-mesma","title":"Stage 05 \u2013 MESMA","text":"<ul> <li>[ ] Confirm endmember sets sum to \u22641.</li> <li>[ ] Review residual errors per pixel.</li> <li>[ ] Flag negative abundance values.</li> </ul> <pre><code>import pandas as pd\nabund = pd.read_csv(\"mesma_output.csv\")\nassert (abund.filter(like=\"EM\").sum(axis=1) &lt;= 1.01).all()\nassert (abund.filter(like=\"EM\") &gt;= 0).all().all()\n</code></pre>"},{"location":"_build/doc_drift_report/","title":"Documentation Drift Report","text":""},{"location":"_build/doc_drift_report/#naming-rule","title":"Naming rule","text":"<ul> <li>Merged parquet naming in code: _merged_pixel_extraction.parquet"},{"location":"_build/doc_drift_report/#missing-items-in-docs","title":"Missing items in docs","text":"<ul> <li>Outputs: \u2014</li> <li>Sensors: micasense_to_match_oli_and_oli, micasense_to_match_oli_oli, micasense_to_match_tm_etm_plus</li> </ul>"},{"location":"_build/doc_drift_report/#stale-items-in-docs","title":"Stale items in docs","text":"<ul> <li>Outputs: _brdfandtopo_corrected_envi.parquet, _landsat_etm+_envi.img, _landsat_oli_envi.parquet, _landsat_tm_envi.hdr, _landsat_tm_envi.img, _micasense*_envi.img, _micasense_envi.hdr, _micasense_envi.img, _qa.json</li> <li>Sensors: MicaSense, MicaSense,, MicaSense,,, MicaSense,,,, MicaSense,,,,, MicaSense,,,,,, MicaSense,,,,,,, MicaSense,,,,,,,, Micasense,, Micasense,,, Micasense,,,, Micasense,,,,, Micasense,,,,,, Micasense,,,,,,, Micasense,,,,,,,, micasense'], micasense'],, micasense'],,, micasense'],,,, micasense'],,,,, micasense'],,,,,, micasense'],,,,,,, micasense_envi.img,, micasense_envi.img<code>, micasense*_envi.img</code>,, micasense_envi.hdr, micasense_envi.hdr,, micasense_envi.hdr,,, micasense_envi.hdr,,,, micasense_envi.hdr,,,,, micasense_envi.hdr,,,,,, micasense_envi.hdr,,,,,,, micasense_envi.img, micasense_envi.img,, micasense_envi.img,,, micasense_envi.img,,,, micasense_envi.img,,,,, micasense_envi.img,,,,,, micasense_envi.img,,,,,,, micasense_envi.img/.hdr/.parquet, micasense_envi.img/.hdr/.parquet,, micasense_envi.img/.hdr/.parquet,,, micasense_envi.img/.hdr/.parquet,,,, micasense_envi.img/.hdr/.parquet,,,,, micasense_envi.img/.hdr/.parquet,,,,,, micasense_envi.img/.hdr/.parquet,,,,,,, micasense_to_match_oli_and_oli,, micasense_to_match_oli_and_oli,,, micasense_to_match_oli_and_oli,,,, micasense_to_match_oli_and_oli,,,,, micasense_to_match_oli_and_oli,,,,,, micasense_to_match_oli_and_oli,,,,,,, micasense_to_match_oli_oli,, micasense_to_match_oli_oli,,, micasense_to_match_oli_oli,,,, micasense_to_match_oli_oli,,,,, micasense_to_match_oli_oli,,,,,, micasense_to_match_oli_oli,,,,,,, micasense_to_match_tm_etm+,,,,,,, micasense`)</li> </ul>"},{"location":"_build/doc_drift_report/#entry-points-pyproject","title":"Entry points (pyproject)","text":"<p>{   \"cscal-download\": \"cross_sensor_cal.cli:download_main\",   \"cscal-pipeline\": \"cross_sensor_cal.cli.pipeline_cli:main\",   \"cscal-qa\": \"cross_sensor_cal.cli.qa_cli:main\",   \"cscal-recover-raw\": \"cross_sensor_cal.cli.recover_cli:main\",   \"cscal-qa-metrics\": \"cross_sensor_cal.qa_metrics:main\",   \"cscal-qa-dashboard\": \"cross_sensor_cal.qa_dashboard:main\",   \"csc-merge-duckdb\": \"cross_sensor_cal.merge_duckdb:main\" }</p>"},{"location":"_build/doc_drift_report/#cli-flags-discovered","title":"CLI flags discovered","text":"<p>{   \"topo_and_brdf_correction.py\": [     \"--config_file\"   ],   \"neon_to_envi.py\": [     \"--brightness-offset\"   ],   \"qa_dashboard.py\": [     \"--base-folder\",     \"--out-parquet\",     \"--out-png\"   ],   \"merge_duckdb.py\": [     \"--corrected-glob\",     \"--data-root\",     \"--flightline-glob\",     \"--no-qa\",     \"--original-glob\",     \"--out-name\",     \"--resampled-glob\",     \"--write-feather\"   ],   \"qa_metrics.py\": [     \"--base-folder\",     \"--flight-stem\"   ],   \"standard_resample.py\": [     \"--hdr_path\",     \"--json_file\",     \"--output_path\",     \"--resampling_file_path\",     \"--sensor_type\"   ],   \"qa_cli.py\": [     \"--base-folder\",     \"--no-overwrite\",     \"--out-dir\",     \"--overwrite\"   ],   \"recover_cli.py\": [     \"--base-folder\",     \"--brightness-offset\"   ],   \"pipeline_cli.py\": [     \"--base-folder\",     \"--brightness-offset\",     \"--flight-lines\",     \"--max-workers\",     \"--product-code\",     \"--resample-method\",     \"--site-code\",     \"--year-month\"   ],   \"pipeline.py\": [     \"--brightness-offset\",     \"--no-sync\",     \"--polygon_layer_path\",     \"--reflectance-offset\",     \"--remote-prefix\",     \"--resample-method\",     \"--verbose\"   ],   \"download.py\": [     \"--flight\",     \"--output\",     \"--product\",     \"--year-month\"   ] }</p>"},{"location":"_build/doc_drift_report/#stage-markers-found-in-logs","title":"Stage markers found in logs","text":"<ul> <li>[cscal-qa] \u2705 QA panels written to: {target.resolve()}</li> <li>[merge] \u26a0\ufe0f QA panel failed: {e}</li> <li>[merge] \ud83d\uddbc\ufe0f  QA panel \u2192 {out_png} (exists={out_png.exists()})</li> <li>\u23ed\ufe0f Parquet already present for %s -&gt; %s (skipping)</li> <li>\u26a0\ufe0f Cannot create Parquet work directory for %s: %s</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .hdr is missing or empty</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .img is missing or empty</li> <li>\u26a0\ufe0f Cannot locate work directory for Parquet export: %s</li> <li>\u26a0\ufe0f Failed Parquet export for %s: %s</li> <li>\u26a0\ufe0f Merge failed for {future_map[future]}: {exc}</li> <li>\u26a0\ufe0f Skipping DuckDB merge for %s because no Parquet outputs were produced</li> <li>\u2705 BRDF+topo correction already complete for %s -&gt; %s / %s (skipping)</li> <li>\u2705 BRDF+topo correction already complete for %s, skipping</li> <li>\u2705 BRDF+topo correction completed for %s -&gt; %s / %s</li> <li>\u2705 Download complete for %s \u2192 %s</li> <li>\u2705 ENVI export already complete for %s -&gt; %s / %s (skipping heavy export)</li> <li>\u2705 ENVI export completed for %s -&gt; %s / %s</li> <li>\u2705 Parquet stage complete for %s</li> <li>\u2705 Wrote Parquet for %s -&gt; %s</li> <li>\ud83c\udf10 Downloading %s (%s, %s) into %s ...</li> <li>\ud83c\udf89 Finished pipeline for %s</li> <li>\ud83c\udf89 Finished pipeline for %s (parallel worker join)</li> <li>\ud83c\udfaf Convolving corrected reflectance for %s</li> <li>\ud83d\udce6 ENVI export not found or invalid for %s, generating from %s</li> <li>\ud83d\udce6 Parquet export for %s ...</li> <li>\ud83d\udd0e ENVI export target for %s is %s / %s</li> <li>\ud83d\uddbc\ufe0f  Overwriting QA panel -&gt; %s</li> <li>\ud83d\uddbc\ufe0f  Writing QA panel -&gt; %s</li> <li>\ud83d\uddbc\ufe0f  Wrote QA panel for %s -&gt; %s</li> </ul> <p>TODO: Review sensor labels in docs for formatting issues.</p>"},{"location":"api/merge_duckdb/","title":"API: merge_duckdb","text":"<p>Merge all pixel-level parquet tables for one flightline.</p>"},{"location":"api/merge_duckdb/#cross_sensor_cal.merge_duckdb.merge_flightline--parameters","title":"Parameters","text":"<p>flightline_dir : Path     Directory containing the flightline's parquet outputs. out_name : str, optional     Custom name for the merged parquet. If None, defaults to:     _merged_pixel_extraction.parquet original_glob : str, optional     Glob used to locate original reflectance parquet tables. corrected_glob : str, optional     Glob used to locate corrected reflectance parquet tables. resampled_glob : str, optional     Glob used to locate resampled sensor parquet tables. write_feather : bool, optional     If True, writes a Feather copy of the merged table alongside the parquet. emit_qa_panel : bool, default True     If True, renders the standard QA panel (_qa.png) after merging."},{"location":"api/merge_duckdb/#cross_sensor_cal.merge_duckdb.merge_flightline--returns","title":"Returns","text":"<p>Path     Path to the merged parquet file.</p>"},{"location":"api/qa_plots/","title":"API: qa_plots","text":"<p>Build and save the standard QA panel (_qa.png) in <code>flightline_dir</code>. <p>Returns the PNG Path. Raises on failure (caller will log traceback).</p>"},{"location":"dev/contributing/","title":"Contributing","text":"<ul> <li>Run tests</li> <li>Run docs drift audit before committing doc changes:   <code>bash   python tools/doc_drift_audit.py   python tools/apply_doc_fixes.py</code></li> <li>Preview docs locally:   <code>bash   pip install mkdocs mkdocs-material mkdocstrings[python]   mkdocs serve</code></li> </ul>"},{"location":"dev/doc_drift_report/","title":"Documentation Drift Report","text":""},{"location":"dev/doc_drift_report/#naming-rule","title":"Naming rule","text":"<ul> <li>Merged parquet naming in code: _merged_pixel_extraction.parquet"},{"location":"dev/doc_drift_report/#missing-items-in-docs","title":"Missing items in docs","text":"<ul> <li>Outputs: \u2014</li> <li>Sensors: micasense_to_match_oli_and_oli, micasense_to_match_oli_oli, micasense_to_match_tm_etm_plus</li> </ul>"},{"location":"dev/doc_drift_report/#stale-items-in-docs","title":"Stale items in docs","text":"<ul> <li>Outputs: _brdfandtopo_corrected_envi.parquet, _landsat_etm+_envi.img, _landsat_oli_envi.parquet, _landsat_tm_envi.hdr, _landsat_tm_envi.img, _micasense*_envi.img, _micasense_envi.hdr, _micasense_envi.img, _qa.json</li> <li>Sensors: MicaSense, MicaSense,, MicaSense,,, MicaSense,,,, MicaSense,,,,, MicaSense,,,,,, MicaSense,,,,,,, MicaSense,,,,,,,, Micasense,, Micasense,,, Micasense,,,, Micasense,,,,, Micasense,,,,,, Micasense,,,,,,, Micasense,,,,,,,, micasense'], micasense'],, micasense'],,, micasense'],,,, micasense'],,,,, micasense'],,,,,, micasense'],,,,,,, micasense_envi.img,, micasense_envi.img<code>, micasense*_envi.img</code>,, micasense_envi.hdr, micasense_envi.hdr,, micasense_envi.hdr,,, micasense_envi.hdr,,,, micasense_envi.hdr,,,,, micasense_envi.hdr,,,,,, micasense_envi.hdr,,,,,,, micasense_envi.img, micasense_envi.img,, micasense_envi.img,,, micasense_envi.img,,,, micasense_envi.img,,,,, micasense_envi.img,,,,,, micasense_envi.img,,,,,,, micasense_envi.img/.hdr/.parquet, micasense_envi.img/.hdr/.parquet,, micasense_envi.img/.hdr/.parquet,,, micasense_envi.img/.hdr/.parquet,,,, micasense_envi.img/.hdr/.parquet,,,,, micasense_envi.img/.hdr/.parquet,,,,,, micasense_envi.img/.hdr/.parquet,,,,,,, micasense_to_match_oli_and_oli,, micasense_to_match_oli_and_oli,,, micasense_to_match_oli_and_oli,,,, micasense_to_match_oli_and_oli,,,,, micasense_to_match_oli_and_oli,,,,,, micasense_to_match_oli_and_oli,,,,,,, micasense_to_match_oli_oli,, micasense_to_match_oli_oli,,, micasense_to_match_oli_oli,,,, micasense_to_match_oli_oli,,,,, micasense_to_match_oli_oli,,,,,, micasense_to_match_oli_oli,,,,,,, micasense_to_match_tm_etm+,,,,,,, micasense`)</li> </ul>"},{"location":"dev/doc_drift_report/#entry-points-pyproject","title":"Entry points (pyproject)","text":"<p>{   \"cscal-download\": \"cross_sensor_cal.cli:download_main\",   \"cscal-pipeline\": \"cross_sensor_cal.cli.pipeline_cli:main\",   \"cscal-qa\": \"cross_sensor_cal.cli.qa_cli:main\",   \"cscal-recover-raw\": \"cross_sensor_cal.cli.recover_cli:main\",   \"cscal-qa-metrics\": \"cross_sensor_cal.qa_metrics:main\",   \"cscal-qa-dashboard\": \"cross_sensor_cal.qa_dashboard:main\",   \"csc-merge-duckdb\": \"cross_sensor_cal.merge_duckdb:main\" }</p>"},{"location":"dev/doc_drift_report/#cli-flags-discovered","title":"CLI flags discovered","text":"<p>{   \"topo_and_brdf_correction.py\": [     \"--config_file\"   ],   \"neon_to_envi.py\": [     \"--brightness-offset\"   ],   \"qa_dashboard.py\": [     \"--base-folder\",     \"--out-parquet\",     \"--out-png\"   ],   \"merge_duckdb.py\": [     \"--corrected-glob\",     \"--data-root\",     \"--flightline-glob\",     \"--no-qa\",     \"--original-glob\",     \"--out-name\",     \"--resampled-glob\",     \"--write-feather\"   ],   \"qa_metrics.py\": [     \"--base-folder\",     \"--flight-stem\"   ],   \"standard_resample.py\": [     \"--hdr_path\",     \"--json_file\",     \"--output_path\",     \"--resampling_file_path\",     \"--sensor_type\"   ],   \"qa_cli.py\": [     \"--base-folder\",     \"--no-overwrite\",     \"--out-dir\",     \"--overwrite\"   ],   \"recover_cli.py\": [     \"--base-folder\",     \"--brightness-offset\"   ],   \"pipeline_cli.py\": [     \"--base-folder\",     \"--brightness-offset\",     \"--flight-lines\",     \"--max-workers\",     \"--product-code\",     \"--resample-method\",     \"--site-code\",     \"--year-month\"   ],   \"pipeline.py\": [     \"--brightness-offset\",     \"--no-sync\",     \"--polygon_layer_path\",     \"--reflectance-offset\",     \"--remote-prefix\",     \"--resample-method\",     \"--verbose\"   ],   \"download.py\": [     \"--flight\",     \"--output\",     \"--product\",     \"--year-month\"   ] }</p>"},{"location":"dev/doc_drift_report/#stage-markers-found-in-logs","title":"Stage markers found in logs","text":"<ul> <li>[cscal-qa] \u2705 QA panels written to: {target.resolve()}</li> <li>[merge] \u26a0\ufe0f QA panel failed: {e}</li> <li>[merge] \ud83d\uddbc\ufe0f  QA panel \u2192 {out_png} (exists={out_png.exists()})</li> <li>\u23ed\ufe0f Parquet already present for %s -&gt; %s (skipping)</li> <li>\u26a0\ufe0f Cannot create Parquet work directory for %s: %s</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .hdr is missing or empty</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .img is missing or empty</li> <li>\u26a0\ufe0f Cannot locate work directory for Parquet export: %s</li> <li>\u26a0\ufe0f Failed Parquet export for %s: %s</li> <li>\u26a0\ufe0f Merge failed for {future_map[future]}: {exc}</li> <li>\u26a0\ufe0f Skipping DuckDB merge for %s because no Parquet outputs were produced</li> <li>\u2705 BRDF+topo correction already complete for %s -&gt; %s / %s (skipping)</li> <li>\u2705 BRDF+topo correction already complete for %s, skipping</li> <li>\u2705 BRDF+topo correction completed for %s -&gt; %s / %s</li> <li>\u2705 Download complete for %s \u2192 %s</li> <li>\u2705 ENVI export already complete for %s -&gt; %s / %s (skipping heavy export)</li> <li>\u2705 ENVI export completed for %s -&gt; %s / %s</li> <li>\u2705 Parquet stage complete for %s</li> <li>\u2705 Wrote Parquet for %s -&gt; %s</li> <li>\ud83c\udf10 Downloading %s (%s, %s) into %s ...</li> <li>\ud83c\udf89 Finished pipeline for %s</li> <li>\ud83c\udf89 Finished pipeline for %s (parallel worker join)</li> <li>\ud83c\udfaf Convolving corrected reflectance for %s</li> <li>\ud83d\udce6 ENVI export not found or invalid for %s, generating from %s</li> <li>\ud83d\udce6 Parquet export for %s ...</li> <li>\ud83d\udd0e ENVI export target for %s is %s / %s</li> <li>\ud83d\uddbc\ufe0f  Overwriting QA panel -&gt; %s</li> <li>\ud83d\uddbc\ufe0f  Writing QA panel -&gt; %s</li> <li>\ud83d\uddbc\ufe0f  Wrote QA panel for %s -&gt; %s</li> </ul> <p>TODO: Review sensor labels in docs for formatting issues.</p>"},{"location":"pipeline/outputs/","title":"Outputs","text":"Output Pattern Notes ENVI (original) <code>*_envi.img/.hdr</code> 426 bands (NEON wavelengths) ENVI (corrected) <code>*_brdfandtopo_corrected_envi.img/.hdr</code> BRDF+topo corrected ENVI (convolved) <code>*_landsat_tm_envi.img</code>, <code>*_landsat_etm+_envi.img</code>, <code>*_landsat_oli[_oli2]_envi.img</code>, <code>*_micasense*_envi.img</code> Sensor-matched Parquet tables <code>*_envi.parquet</code>, <code>*_brdfandtopo_corrected_envi.parquet</code>, <code>*_landsat_oli_envi.parquet</code>, ... Per product Merged master (new) <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code> One row per pixel, all wavelengths + metadata QA Panel (PNG) <code>&lt;prefix&gt;_qa.png</code> Visual summary of original/corrected/convolved <p><code>&lt;prefix&gt;</code> resolves to the canonical scene prefix (e.g., <code>NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance</code>).</p>"},{"location":"pipeline/qa_panel/","title":"QA Panel","text":"<ul> <li>Generated automatically after the merge stage during full runs.</li> <li>Filename: <code>&lt;prefix&gt;_qa.png</code> in the flightline folder.</li> <li>If troubleshooting: enable verbose logs and ensure ENVI headers parse for band indices/wavelengths.</li> </ul> <p>Common fixes</p> <ul> <li>Ensure corrected/convolved ENVI headers have either numeric <code>wavelength</code> or <code>band names</code>.</li> <li>Our parser falls back to sensor-default RGB if only <code>bands = N</code> exists.</li> </ul>"},{"location":"pipeline/stages/","title":"Pipeline Stages","text":"<ol> <li>Download <code>*_directional_reflectance.h5</code></li> <li>Export to ENVI \u2192 <code>*_envi.img/.hdr</code></li> <li>Topographic + BRDF correction \u2192 <code>*_brdfandtopo_corrected_envi.img/.hdr</code> (+ JSON)</li> <li>Cross-sensor convolution (TM, ETM+, OLI/OLI-2, MicaSense variants)</li> <li>Parquet export for all ENVI products</li> <li>DuckDB Merge (new) \u2192 <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code></li> <li>QA Panel (restored) \u2192 <code>&lt;prefix&gt;_qa.png</code> (triggered post-merge)</li> </ol>"},{"location":"usage/cli/","title":"CLI &amp; Examples","text":""},{"location":"usage/cli/#merge-per-flightline-or-batch","title":"Merge (per flightline or batch)","text":"<pre><code># Batch: all flightlines under a root\npython -m bin.merge_duckdb --data-root /path/to/output --flightline-glob \"NEON_*\"\n\n# Single flightline directory (debug)\npython -m bin.merge_duckdb --flightline-dir /path/to/.../NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\n</code></pre> <p>Defaults</p> <ul> <li>Output name: <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code></li> <li>QA panel: enabled (produces <code>&lt;prefix&gt;_qa.png</code>)</li> </ul> <p>Flags</p> <ul> <li><code>--out-name</code> override output parquet name (optional)</li> <li><code>--no-qa</code> skip panel rendering</li> <li><code>--original-glob</code>, <code>--corrected-glob</code>, <code>--resampled-glob</code> to customize discovery</li> </ul>"}]}