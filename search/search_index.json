{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SpectralBridge","text":"<p>SpectralBridge (formerly cross-sensor-cal) translates reflectance among NEON AOP, uncrewed aerial system (e.g., MicaSense), and Landsat observations to place disparate datasets into a common Landsat-referenced frame. It is designed for notebook-first scientists who need reliable, reproducible harmonization to bridge fine-scale ecological measurements with the long-term continental Landsat record. The workflow is pipeline-based rather than a single correction, and it produces artifacts that can be inspected, reused, and resumed.</p> <p>Upgrading from older versions? Imports under <code>cross_sensor_cal</code> and legacy <code>cscal-*</code> CLI aliases still function, but new examples use the <code>spectralbridge</code> namespace and <code>spectralbridge-*</code> commands.</p>"},{"location":"#what-spectralbridge-does","title":"What SpectralBridge does","text":"<ul> <li>Normalizes directional reflectance through topographic and BRDF adjustments, then resamples spectra into Landsat and other target bandpasses for direct comparison.</li> <li>Bridges across ecological scales by aligning field, UAS, and airborne measurements with the Landsat time series, enabling cross-scale analyses and model transfer.</li> <li>Generates harmonized, provenance-rich spectral libraries alongside imagery so downstream modeling can start from analysis-ready data.</li> <li>Emits restart-safe outputs (ENVI, Parquet sidecars, merged pixel tables) plus QA panels that document every run.</li> </ul>"},{"location":"#why-this-approach-is-trustworthy","title":"Why this approach is trustworthy","text":"<ul> <li>Physics-informed normalization (topographic + BRDF) precedes empirical calibration to keep results grounded in surface reflectance rather than image brightness alone.</li> <li>Cross-sensor calibration is referenced to Landsat NBAR, providing an anchored target for spectral translation.</li> <li>Every run produces QA PNG/PDF panels and JSON summaries so users can interrogate performance and document decisions.</li> <li>The pipeline is deterministic and restartable: intermediate artifacts are written to disk, making runs auditable and recoverable.</li> </ul>"},{"location":"#connection-to-the-scientific-literature","title":"Connection to the scientific literature","text":"<p>This software implements the workflow described in the Remote Sensing of Environment manuscript, Bridging Scales for Macrosystems Ecology: Harmonizing Western US Plant Functional Types Spectral Data from Drones and NEON Airborne Imagery to Landsat Observations. It operationalizes that study's approach to aligning UAS and NEON hyperspectral data with Landsat, providing an open, inspectable implementation for reproducible science.</p>"},{"location":"#who-should-use-this","title":"Who should use this","text":"<ul> <li>Notebook-first scientists analyzing spectral libraries and reflectance products.</li> <li>Ecologists and remote sensing researchers needing to connect plot-level or flightline observations to Landsat's long-term record.</li> <li>Advanced users and developers integrating the pipeline into larger workflows or extending it to additional sensors.</li> </ul>"},{"location":"#next-steps","title":"Next steps","text":"<ul> <li>Quickstart</li> <li>Jupyter notebook example</li> <li>Tutorials</li> <li>Reference</li> </ul>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"benchmarks/#reproducible-timing-experiment-design","title":"Reproducible timing experiment design","text":"<ul> <li>Pin package versions and record hardware specifications.</li> <li>Use fixed random seeds and keep the system load constant.</li> <li>Run each benchmark multiple times, reporting mean and variance.</li> <li>Save the exact command line and configuration for future runs.</li> </ul>"},{"location":"benchmarks/#ray-cluster-knobs","title":"Ray cluster knobs","text":"<p>When scaling benchmarks on Ray, adjust:</p> <ul> <li><code>--num-cpus</code> and <code>--num-gpus</code> to control available resources.</li> <li><code>--object-store-memory</code> for large in-memory datasets.</li> <li><code>--temp-dir</code> to point to fast local storage.</li> <li><code>--dashboard-port</code> to monitor cluster status.</li> </ul>"},{"location":"benchmarks/#io-bottleneck-tips","title":"I/O bottleneck tips","text":"<ul> <li>Chunk rasters along the row and column dimensions so each worker reads contiguous blocks.</li> <li>Enable compression such as LZW or DEFLATE to reduce disk usage and transfer time.</li> <li>Cache intermediate products or use memory-mapped files to avoid repeated reads.</li> </ul>"},{"location":"brdf_topo_algorithm/","title":"Streamlined BRDF + Topographic corrections","text":"<p>This document summarises the updated streamlined correction path so it aligns with HyTools/FlexBRDF behaviour.</p>"},{"location":"brdf_topo_algorithm/#topographic-correction-scsc","title":"Topographic correction (SCS+C)","text":"<ul> <li>For each band a regression <code>rho = a*cos(i) + b</code> is fit over valid pixels to   recover the C-parameter <code>C=b/a</code>.</li> <li>The surface correction applies <code>(cos(theta_s)*cos(beta) + C)/(cos(i)+C)</code> to   the reflectance in unitless space before converting back to NEON scaling;   a small denominator guard prevents extreme ratios when <code>cos(i)+C</code> is nearly   zero.</li> <li>This SCS+C path is now the default; a cosine-ratio fallback remains available   via the <code>use_scs_c</code> flag.</li> </ul>"},{"location":"brdf_topo_algorithm/#topographic-modes-and-defaults","title":"Topographic modes and defaults","text":"<ul> <li><code>apply_topo_correct</code> supports two modes:</li> <li>Legacy cosine-ratio (<code>use_scs_c=False</code>).</li> <li>SCS+C (<code>use_scs_c=True</code>) matching HyTools/FlexBRDF behaviour.</li> <li>The current default is <code>use_scs_c=True</code>, which is a change from older   releases that defaulted to cosine-ratio. Callers that require the legacy   behaviour should explicitly pass <code>use_scs_c=False</code> (or the equivalent CLI   flag) to disable SCS+C.</li> </ul>"},{"location":"brdf_topo_algorithm/#ndvi-binning","title":"NDVI binning","text":"<ul> <li>NDVI is derived from bands nearest 665 nm and 865 nm after converting to   unitless reflectance.</li> <li>Pixels are assigned to configurable bins (defaults ~0.05\u20131.0 over 25 bins   with percentile clipping) used for BRDF fitting and application.</li> <li>When coefficients are missing or bin counts mismatch, neutral coefficients   are broadcast across all bins to avoid dropping pixels. Pixels with NDVI   outside the bin range are remapped into the first bin to preserve coverage   when no explicit coefficients are available.</li> </ul>"},{"location":"brdf_topo_algorithm/#brdf-fitting-and-application","title":"BRDF fitting and application","text":"<ul> <li>Per-band, per-bin regressions solve <code>rho = f_iso + f_vol*K_vol + f_geo*K_geo</code>.</li> <li>BRDF normalization uses the FlexBRDF ratio <code>R_ref/R_pix</code>, evaluating kernels   at both pixel geometry and a configurable reference geometry.</li> </ul>"},{"location":"brdf_topo_algorithm/#scaling-and-thresholds","title":"Scaling and thresholds","text":"<ul> <li>Modeling occurs in unitless reflectance; scale factors are applied only at the   edges. Optional clamps guard obviously invalid reflectance values.</li> <li>All masks propagate cube no-data and NDVI bin assignments; non-finite outputs   resolve to the cube <code>no_data</code> value.</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The pipeline is configured through a <code>config.yaml</code> file that combines settings for every stage. Values shown below are the defaults unless marked as required.</p>"},{"location":"configuration/#schema","title":"Schema","text":"Key Type Default Required <code>base_folder</code> string <code>\"output\"</code> yes <code>download.site_code</code> string \u2014 yes <code>download.year_month</code> string (YYYYMM) \u2014 yes <code>download.flight_lines</code> list[string] \u2014 yes <code>download.product_code</code> string <code>\"DP1.30006.001\"</code> no <code>convert.export_ancillary</code> bool <code>true</code> no <code>convert.export_brdf_config</code> bool <code>true</code> no <code>topo_brdf.num_cpus</code> int <code>8</code> no <code>topo_brdf.file_type</code> string <code>\"envi\"</code> no <code>topo_brdf.corrections</code> list[string] <code>[\"topo\",\"brdf\"]</code> no <code>topo_brdf.bad_bands</code> list[int] <code>[]</code> no <code>topo_brdf.anc_files</code> map[string,str] \u2014 conditional\u2020 <code>topo_brdf.export.output_dir</code> string <code>\"./\"</code> no <code>topo_brdf.export.suffix</code> string <code>\"_corrected_envi\"</code> no <code>topo_brdf.export.image</code> bool <code>true</code> no <code>topo_brdf.export.masks</code> bool <code>true</code> no <code>topo_brdf.export.coeffs</code> bool <code>true</code> no <code>resample.method</code> string <code>\"convolution\"</code> no <code>resample.sensors</code> list[string] <code>[\"Landsat_8\"]</code> no <code>mask.polygon_layer</code> string \u2014 no <code>mask.raster_crs_override</code> string|int \u2014 no <code>mask.polygons_crs_override</code> string|int \u2014 no <code>mask.plot_output</code> bool <code>false</code> no <code>sort.remote_prefix</code> string <code>\"\"</code> no <code>sort.sync_files</code> bool <code>true</code> no <code>postprocess.reflectance_offset</code> int <code>0</code> no <p>\u2020 required when <code>topo_brdf.file_type</code> is <code>\"envi\"</code>.</p>"},{"location":"configuration/#example","title":"Example","text":"<pre><code>base_folder: output\n\ndownload:\n  site_code: NIWO\n  year_month: \"202008\"\n  flight_lines: [\"FL1\", \"FL2\"]\n  product_code: DP1.30006.001\n\nconvert:\n  export_ancillary: true\n  export_brdf_config: true\n\ntopo_brdf:\n  num_cpus: 8\n  file_type: envi\n  corrections: [\"topo\", \"brdf\"]\n  bad_bands: []\n  anc_files: {}\n  export:\n    output_dir: ./corrected\n    suffix: _corrected_envi\n    image: true\n    masks: true\n    coeffs: true\n\nresample:\n  method: convolution\n  sensors: [\"Landsat_8\"]\n\nmask:\n  polygon_layer: polygons.geojson\n  plot_output: false\n\nsort:\n  remote_prefix: \"\"\n  sync_files: true\n\npostprocess:\n  reflectance_offset: 0\n</code></pre>"},{"location":"configuration/#cli-overrides","title":"CLI overrides","text":"<p>The <code>spectralbridge-pipeline</code> entry point automatically runs the download stage before spinning up per-flightline workers. Use <code>--max-workers</code> to opt into parallel processing once the <code>.h5</code> files are present, and <code>--engine</code> to pick the backend. Command-line options override the corresponding entries in <code>config.yaml</code>:</p> <ul> <li><code>bin/jefe.py BASE_FOLDER SITE YEAR_MONTH FL1,FL2</code> sets <code>base_folder</code>, <code>download.site_code</code>, <code>download.year_month</code> and <code>download.flight_lines</code>.</li> <li><code>--polygon_layer_path</code> \u2192 <code>mask.polygon_layer</code></li> <li><code>--reflectance-offset</code> \u2192 <code>postprocess.reflectance_offset</code></li> <li><code>--remote-prefix</code> \u2192 <code>sort.remote_prefix</code></li> <li><code>--no-sync</code> sets <code>sort.sync_files</code> to <code>false</code></li> <li><code>--max-workers</code> sets the parallel worker count for <code>go_forth_and_multiply()</code></li> <li><code>--engine</code> selects the backend (<code>thread</code>, <code>process</code>, or <code>ray</code>). Ray requires   the optional dependency and is only loaded when requested.</li> </ul>"},{"location":"cyverse-irods/","title":"CyVerse iRODS","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>CyVerse storage is accessed through iRODS paths handled by the <code>gocmd</code> utility. Remote locations are written with an <code>i:</code> prefix followed by the iRODS zone, for example <code>i:/iplant/home/your_username</code>.</p> <p>To authenticate, run <code>./gocmd init</code> once. The command records your credentials in <code>~/.irods</code> so future operations can reach the data store without re-entering them.</p> <p>Common operations:</p> <pre><code># list a collection\n./gocmd ls i:/iplant/home/your_username\n\n# download a file\n./gocmd get i:/iplant/home/your_username/data.txt\n\n# upload a file to a collection\n./gocmd put local_file.txt i:/iplant/home/your_username/\n</code></pre> <p>Scripts build remote paths using variables patterned as:</p> <pre><code>remote_path = f\"i:/iplant/{remote_prefix}/{dest_path}\"\n</code></pre> <p>Replace <code>remote_prefix</code> and <code>dest_path</code> with the appropriate subdirectory and filename for your project.</p>"},{"location":"dev-notes/","title":"Developer Notes","text":"<p>Use the following commands to work on the documentation locally:</p> <ol> <li>Install dependencies:    <pre><code>pip install -r docs/requirements.txt\n# or\nuv pip install -r docs/requirements.txt\n</code></pre></li> <li>Start a live preview:    <pre><code>mkdocs serve\n</code></pre></li> <li>Build the static site:    <pre><code>mkdocs build\n</code></pre></li> </ol>"},{"location":"documentation-overview/","title":"Documentation","text":""},{"location":"documentation-overview/#overview","title":"Overview","text":"<p>This directory hosts project documentation, including the style guide that defines how you should write and maintain docs across the repository.</p>"},{"location":"documentation-overview/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Markdown viewer or editor</li> <li>Familiarity with basic Git workflows</li> </ul>"},{"location":"documentation-overview/#step-by-step-tutorial","title":"Step-by-step tutorial","text":"<ol> <li>Review the documentation style guide to    understand structure and formatting conventions.</li> <li>Create or update documentation in other folders using the guide's narrative    approach and examples.</li> <li>After editing, run <code>pytest</code> at the repository root to ensure code snippets    still execute.</li> </ol>"},{"location":"documentation-overview/#reference","title":"Reference","text":"<ul> <li><code>documentation_style_guide.md</code> \u2013 canonical guide for all project docs</li> </ul>"},{"location":"documentation-overview/#next-steps","title":"Next steps","text":"<p>Expand this folder with API references, architecture diagrams, or tutorials as the project evolves.</p>"},{"location":"documentation_style_guide/","title":"Cross-Sensor Calibration Documentation Style Guide","text":"<p>This guide establishes conventions for writing documentation in the Cross-Sensor Calibration project. Its goal is to create a linear, pedagogical narrative that makes the package easy to understand and adopt.</p>"},{"location":"documentation_style_guide/#philosophy","title":"Philosophy","text":"<ul> <li>Clarity first. Explain concepts in plain language before introducing technical jargon.</li> <li>Narrative flow. Documentation should guide the reader from inputs through processing to outputs in a logical order.</li> <li>Pragmatic examples. Every section should include code snippets or workflows that users can run directly.</li> <li>Minimal prerequisites. Link to background materials rather than assuming extensive prior knowledge.</li> </ul>"},{"location":"documentation_style_guide/#structure","title":"Structure","text":"<ol> <li>Overview \u2013 Briefly describe the purpose of the component and how it fits into the larger workflow.</li> <li>Prerequisites \u2013 List required data, dependencies, and setup steps.</li> <li>Step-by-step tutorial \u2013 Present instructions in chronological order.</li> <li>Reference \u2013 Provide detailed API descriptions, parameters, and links to source code.</li> <li>Next steps \u2013 Suggest follow-on tasks or sections.</li> </ol>"},{"location":"documentation_style_guide/#style","title":"Style","text":"<ul> <li>Use Markdown headings (<code>#</code>, <code>##</code>, <code>###</code>) to organize content.</li> <li>Write in the second person (\u201cyou\u201d) and active voice.</li> <li>Keep sentences concise; aim for one idea per sentence.</li> <li>Use numbered lists for sequences and bullet lists for options.</li> <li>Highlight file names, parameters, and code using backticks (<code>like_this</code>).</li> <li>Wrap code examples in fenced blocks with the appropriate language tag.</li> <li>Include diagrams or figures when they clarify complex processes.</li> <li>Cross-link related documents with relative paths.</li> </ul>"},{"location":"documentation_style_guide/#formatting","title":"Formatting","text":"<ul> <li>Line length: soft wrap at 100 characters.</li> <li>Use American English spelling.</li> <li>Date format: YYYY-MM-DD.</li> <li>Reference issues or pull requests with full links.</li> </ul>"},{"location":"documentation_style_guide/#maintenance","title":"Maintenance","text":"<ul> <li>Each documentation page must include a <code>Last updated: YYYY-MM-DD</code> line at the end.</li> <li>When updating docs, ensure examples are tested against the current codebase.</li> <li>Run <code>pytest</code> before committing changes that affect code examples.</li> </ul> <p>Following this guide will keep the documentation consistent and approachable for new contributors and users.</p>"},{"location":"env-setup/","title":"Environment Setup","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"env-setup/#conda-environment","title":"Conda environment","text":"<p>An example environment file for Conda is shown below. Save it as <code>environment.yaml</code> and create the environment with <code>conda env create -f environment.yaml</code>.</p> <pre><code>name: SpectralBridge\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.10\n  - gdal\n  - proj\n  - pip\n  - pip:\n      - ray[default]\n</code></pre>"},{"location":"env-setup/#uv-pip-alternative","title":"uv / pip alternative","text":"<p>Instead of Conda you can install the project with <code>uv</code> or plain <code>pip</code>:</p> <pre><code>uv pip install -r requirements.txt\n# or\npip install -r requirements.txt\n</code></pre>"},{"location":"env-setup/#gdal-proj-and-ray-notes","title":"GDAL, PROJ, and Ray notes","text":"<ul> <li>GDAL and PROJ require native libraries. Installing via the   <code>conda-forge</code> channel usually resolves most platform issues.</li> <li>Ray makes heavy use of shared memory. If Ray reports <code>/dev/shm</code> errors,   increase shared memory. For Docker containers use   <code>--shm-size=8g</code> (adjust as needed).</li> </ul>"},{"location":"env-setup/#known-os-quirks","title":"Known OS quirks","text":"<ul> <li>macOS: Homebrew installations of GDAL/PROJ may conflict with Conda.   Prefer the Conda packages or ensure <code>brew</code> paths come after Conda in <code>PATH</code>.</li> <li>Windows: enable long paths (<code>git config --system core.longpaths true</code>) to   avoid checkout errors.</li> </ul>"},{"location":"env-setup/#preview-documentation-locally","title":"Preview documentation locally","text":"<p>Run the MkDocs development server from the repository root:</p> <pre><code>mkdocs serve\n</code></pre> <p>Open http://127.0.0.1:8000 in a browser to view the docs.</p>"},{"location":"env/","title":"Environment","text":"Component Known-good Python 3.10\u20133.12 OS macOS 13+, Ubuntu 22.04+ Core libs numpy, rasterio, gdal, ray, xarray, pandas"},{"location":"env/#setup-venv","title":"Setup (venv)","text":"<pre><code>python -m venv .venv &amp;&amp; source .venv/bin/activate\npip install -U pip\npip install spectralbridge\n</code></pre>"},{"location":"env/#setup-conda","title":"Setup (conda)","text":"<pre><code>conda create -n spectralbridge python=3.11 -y\nconda activate spectralbridge\npip install -U pip\npip install spectralbridge\n</code></pre>"},{"location":"extending/","title":"Extending","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"extending/#add-a-sensor","title":"Add a sensor","text":""},{"location":"extending/#overview","title":"Overview","text":"<p>This recipe shows how to integrate a new sensor into the cross\u2011sensor calibration workflow.</p>"},{"location":"extending/#prerequisites","title":"Prerequisites","text":"<ul> <li>Spectral response function (SRF) curves for the sensor.</li> <li>Familiarity with the project's naming conventions.</li> </ul>"},{"location":"extending/#step-by-step-tutorial","title":"Step-by-step tutorial","text":"<ol> <li>Add SRFs. Place the sensor's SRF files in the data directory and register    them with the SRF loader.</li> <li>Update resampling/convolution mapping. Extend the resampling and    convolution dictionaries so the pipeline knows how to transform the sensor's    bands.</li> <li>Update the naming map. Insert the sensor's canonical name and band    identifiers into the shared naming map used across modules.</li> <li>Add a golden test and validation checklist.</li> <li>Create a golden test case with expected outputs.</li> <li>Document validation steps to confirm the sensor behaves correctly.</li> </ol>"},{"location":"extending/#next-steps","title":"Next steps","text":"<p>Run the full validation suite and submit a pull request for review.</p> <p>Last updated: 2025-08-18</p>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"faq/#what-is-the-purpose-of-cross-sensor-calibration","title":"What is the purpose of cross-sensor calibration?","text":"<p>To make reflectance from NEON, drones, and satellites comparable by removing geometric artifacts and aligning spectral responses.</p>"},{"location":"faq/#why-does-neon-use-scaled-reflectance","title":"Why does NEON use scaled reflectance?","text":"<p>NEON stores reflectance as scaled integers for performance. The export stage automatically converts these into floating-point reflectance values using NEON\u2019s scale factors.</p>"},{"location":"faq/#do-i-need-both-topographic-and-brdf-correction","title":"Do I need both topographic and BRDF correction?","text":"<p>Yes, for most ecological analyses. Topographic correction removes slope/aspect artifacts; BRDF correction normalizes view/sun geometry.</p>"},{"location":"faq/#why-do-some-bands-look-noisy","title":"Why do some bands look noisy?","text":"<p>Low-SNR wavelength regions (especially in the SWIR) are more sensitive to BRDF fitting errors.</p>"},{"location":"faq/#what-sensors-can-i-harmonize-to","title":"What sensors can I harmonize to?","text":"<p>Currently:</p> <ul> <li>Landsat OLI / OLI-2  </li> <li>MicaSense RedEdge (via regression)  </li> </ul> <p>More sensors can be added as SRF tables become available.</p>"},{"location":"faq/#why-does-the-pipeline-take-so-long","title":"Why does the pipeline take so long?","text":"<p>NEON tiles are very large (tens of GB). BRDF and ENVI export steps are computationally expensive.</p> <p>Parallelization helps, but memory constraints matter.</p>"},{"location":"faq/#why-do-some-pixels-have-reflectance-1","title":"Why do some pixels have reflectance &gt; 1?","text":"<p>BRDF or DEM correction may amplify noise at certain angles or terrain slopes. Such pixels are reported in QA metrics and usually masked.</p>"},{"location":"faq/#can-i-run-analyses-without-touching-envi-files","title":"Can I run analyses without touching ENVI files?","text":"<p>Yes\u2014use the Parquet outputs (<code>*_merged_pixel_extraction.parquet</code>) for large-scale analysis.</p>"},{"location":"faq/#next-steps","title":"Next steps","text":"<ul> <li>Troubleshooting </li> <li>Pipeline outputs</li> </ul>"},{"location":"glossary/","title":"Glossary","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <ul> <li>AOP: Apparent Optical Property describing how a medium's optical characteristics vary with viewing geometry.</li> <li>BRDF: Bidirectional Reflectance Distribution Function giving reflectance as a function of illumination and view angles.</li> <li>SRF: Spectral Response Function representing a sensor's sensitivity across wavelengths.</li> <li>SNR: Signal-to-Noise Ratio, the level of desired signal relative to background noise.</li> <li>ENVI: Environment for Visualizing Images, a software package for processing geospatial imagery.</li> <li>MESMA: Multiple Endmember Spectral Mixture Analysis, an unmixing algorithm using variable endmember sets.</li> <li>DN: Digital Number, the raw quantized value recorded by a sensor.</li> <li>TOA: Top of Atmosphere reflectance measured above the atmosphere.</li> <li>BOA: Bottom of Atmosphere or surface reflectance after atmospheric correction.</li> <li>NIR: Near Infrared region of the electromagnetic spectrum, roughly 0.7\u20131.3 \u00b5m.</li> <li>SWIR: Shortwave Infrared region spanning approximately 1.3\u20132.5 \u00b5m.</li> <li>VIS: Visible portion of the electromagnetic spectrum between about 0.4\u20130.7 \u00b5m.</li> <li>FLAASH: Fast Line-of-sight Atmospheric Analysis of Spectral Hypercubes, an atmospheric correction tool.</li> <li>LiDAR: Light Detection and Ranging, active remote sensing using laser pulses to measure distance.</li> <li>UAV: Uncrewed Aerial Vehicle used as a platform for acquiring high-resolution imagery.</li> <li>NDVI: Normalized Difference Vegetation Index calculated from NIR and red bands to indicate vegetation vigor.</li> <li>MODIS: Moderate Resolution Imaging Spectroradiometer, a multispectral sensor on NASA's Terra and Aqua satellites.</li> <li>GSD: Ground Sample Distance, the ground size represented by one image pixel.</li> <li>RSR: Relative Spectral Response, the normalized sensitivity of a detector as a function of wavelength.</li> <li>AVIRIS: Airborne Visible/Infrared Imaging Spectrometer, a NASA hyperspectral imaging instrument.</li> </ul>"},{"location":"naming-conventions/","title":"Naming Conventions","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"naming-conventions/#canonical-filename-pattern","title":"Canonical Filename Pattern","text":"<p>All files produced by the pipeline use a common token order:</p> <pre><code>NEON_{site}_{YYYYMMDD}_{HHMMSS}_FL{line}_{product}{suffix}.ext\n</code></pre> <ul> <li><code>site</code> \u2013 NEON site code (e.g., <code>SJER</code>)</li> <li><code>YYYYMMDD</code> and <code>HHMMSS</code> \u2013 acquisition date and time in UTC</li> <li><code>FL{line}</code> \u2013 zero\u2011padded flight line identifier</li> <li><code>product</code> \u2013 base product name (e.g., <code>NIS</code>)</li> <li><code>suffix</code> \u2013 processing state (see table below)</li> <li><code>ext</code> \u2013 file extension such as <code>.img</code> or <code>.hdr</code></li> </ul> <p>Regex</p> <pre><code>^NEON_[A-Z0-9]{4}_\\d{8}_\\d{6}_FL\\d{3}_[A-Za-z0-9]+(?:_radiance|_ancillary|_corrected_envi|_reflectance)\\.(?:img|hdr)$\n</code></pre>"},{"location":"naming-conventions/#standard-suffixes","title":"Standard Suffixes","text":"Suffix Meaning <code>_radiance</code> Raw radiance from HDF5 conversion <code>_ancillary</code> Ancillary data produced with radiance <code>_corrected_envi</code> BRDF/TOPO corrected ENVI image <code>_reflectance</code> Final reflectance product"},{"location":"naming-conventions/#directory-layout","title":"Directory Layout","text":"<pre><code>site/\n\u2514\u2500\u2500 YYYYMMDD/\n    \u2514\u2500\u2500 FL###/\n        \u251c\u2500\u2500 raw/\n        \u2502   \u251c\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_radiance.img\n        \u2502   \u2514\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_ancillary.img\n        \u2514\u2500\u2500 derived/\n            \u251c\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_corrected_envi.img\n            \u2514\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_corrected_envi.hdr\n</code></pre>"},{"location":"naming-conventions/#common-violations-fixes","title":"Common Violations &amp; Fixes","text":"Violation Why it matters Fix Missing flight line token Downstream scripts cannot group files Include <code>_FL###</code> before the suffix Wrong suffix for directory (e.g., <code>_radiance</code> in <code>derived/</code>) Causes processing confusion Move file to <code>raw/</code> or rename with proper suffix Lower\u2011case site code Breaks regex patterns Use upper\u2011case site codes Spaces instead of underscores Parsing fails Replace spaces with <code>_</code>"},{"location":"overview/","title":"Overview","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The Cross\u2011Sensor Calibration workflow runs every NEON flight line through an idempotent, restart-safe series of five stages. Each stage emits tqdm-style progress bars, prefixes logs with <code>[flight_stem]</code>, and writes artifacts using canonical paths from :func:<code>spectralbridge.utils.naming.get_flight_paths</code>.</p> <pre><code>flowchart LR\n    D[Download .h5]\n    E[Export ENVI]\n    J[Build BRDF+topo JSON]\n    C[Correct reflectance]\n    R[Resample + Parquet]\n    D --&gt; E --&gt; J --&gt; C --&gt; R\n</code></pre> <ul> <li>Download: <code>stage_download_h5()</code> restores automatic retrieval of NEON   directional reflectance cubes and leaves each <code>.h5</code> in the workspace root for   easy cleanup.</li> <li>ENVI export: Converts the HDF5 cube to   <code>&lt;base&gt;/&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.img/.hdr/.parquet</code> with per-tile   progress updates.</li> <li>BRDF + topo JSON: Computes correction parameters once per flight line and   records them in <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code> inside the   dedicated subdirectory.</li> <li>BRDF + topo correction: Streams a chunk progress bar while writing the   canonical corrected cube (<code>*_brdfandtopo_corrected_envi.img/.hdr/.parquet</code>).</li> <li>Sensor resample + Parquet: Produces per-sensor ENVI pairs and matching   Parquet summaries in the same subfolder, leaving the raw <code>.h5</code> untouched.</li> </ul> <p>Every derived artifact now lives under <code>&lt;base&gt;/&lt;flight_stem&gt;/</code>, keeping the workspace organized and allowing long-term retention of processed products without stockpiling multi-gigabyte <code>.h5</code> inputs. <code>_scoped_log_prefix()</code> keeps parallel runs legible while <code>max_workers</code> lets you opt into ThreadPool-powered concurrency once downloads finish.</p>"},{"location":"overview/#who-is-this-for","title":"Who is this for?","text":"<p>Researchers processing NEON AOP flight lines who need reproducible ENVI deliverables, per-sensor band stacks, and Parquet summaries for cross-sensor analysis. All scientific calculations remain unchanged from previous releases\u2014 the 2025 refresh focuses on workflow, performance, and restart safety.</p>"},{"location":"pipeline/","title":"Pipeline reference","text":"<p>Cross-Sensor Calibration orchestrates the same five ordered stages for every flight line. Each stage consults <code>get_flight_paths()</code> to locate its inputs, per-flightline working directory, and outputs, validates artifacts before working, and emits emoji-rich logs that make the restart-safe behavior explicit. All persistent products land inside <code>&lt;base_folder&gt;/&lt;flight_stem&gt;/</code> (with the raw <code>.h5</code> kept at the base root) and include ENVI (<code>.img/.hdr</code>), JSON metadata, and Parquet summaries.</p>"},{"location":"pipeline/#canonical-paths-via-get_flight_paths","title":"Canonical paths via <code>get_flight_paths()</code>","text":"<p><code>get_flight_paths(base_folder, flight_stem)</code> is the authoritative source of truth for every artifact the pipeline reads or writes. For a flight line with stem <code>&lt;flight_stem&gt;</code> it yields:</p> <ul> <li><code>h5_path</code> \u2192 <code>&lt;base_folder&gt;/&lt;flight_stem&gt;.h5</code></li> <li><code>work_dir</code> \u2192 <code>&lt;base_folder&gt;/&lt;flight_stem&gt;/</code></li> <li><code>raw_envi_img</code> / <code>raw_envi_hdr</code> \u2192 <code>&lt;flight_stem&gt;_envi.img</code> and   <code>&lt;flight_stem&gt;_envi.hdr</code> inside <code>work_dir</code></li> <li><code>correction_json</code> \u2192 <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code> in   <code>work_dir</code></li> <li><code>corrected_img</code> / <code>corrected_hdr</code> \u2192   <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.img</code> and   <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.hdr</code></li> <li><code>sensor_products</code> \u2192 a dict mapping each sensor (e.g. <code>landsat_tm</code>,   <code>landsat_etm+</code>, <code>landsat_oli</code>, <code>landsat_oli2</code>, <code>micasense</code>) to   <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.img</code> /   <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.hdr</code></li> <li><code>parquet_products</code> \u2192 optional Parquet summaries colocated with their source   rasters</li> </ul> <p>All stages request their expected paths from this function and refuse to invent filenames on the fly. If naming ever changes, update <code>get_flight_paths()</code> once rather than editing every stage.</p>"},{"location":"pipeline/#stage-by-stage-details","title":"Stage-by-stage details","text":"<p>Every stage is restart-safe: it skips itself when valid outputs already exist. Validation requires both sides of an ENVI pair to exist and be non-empty or, for JSON, the file must parse successfully. When a stage skips, it logs a <code>\u2705 ... (skipping)</code> message; otherwise it performs work and logs what it produced. Live tqdm progress bars accompany downloads, ENVI chunk exports, and BRDF+topo corrections.</p>"},{"location":"pipeline/#0-download-neon-hdf5","title":"0. Download NEON HDF5","text":"<ul> <li>Inputs</li> <li>NEON site code, product code, and flight stem.</li> <li>Outputs</li> <li><code>&lt;base_folder&gt;/&lt;flight_stem&gt;.h5</code> (left in the workspace root).</li> <li>Skip criteria</li> <li>Existing <code>.h5</code> file that passes a size/metadata sanity check.</li> <li>Logging</li> <li>Logs <code>\ud83d\udce5 stage_download_h5()</code> with a streaming byte counter while downloading.</li> <li>On skip emits <code>\u2705 stage_download_h5() found existing .h5 (skipping)</code>.</li> <li>Failure handling</li> <li>Raises on HTTP errors or truncated downloads; reruns resume by revalidating the file.</li> </ul>"},{"location":"pipeline/#1-envi-export","title":"1. ENVI export","text":"<ul> <li>Inputs</li> <li>NEON directional reflectance cube (<code>&lt;flight_stem&gt;.h5</code>).</li> <li>Outputs</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.img</code></li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.hdr</code></li> <li>Extras</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.parquet</code> (summary statistics per tile).</li> <li>Skip criteria</li> <li>Both ENVI files exist, are non-empty, and pass the internal ENVI validation.</li> <li>Logging</li> <li>Always logs <code>\ud83d\udd0e ENVI export target for &lt;flight_stem&gt; is ..._envi.img / ..._envi.hdr</code> with a chunked progress bar.</li> <li>On skip emits     <code>\u2705 ENVI export already complete for &lt;flight_stem&gt; -&gt; ..._envi.img / ..._envi.hdr (skipping heavy export)</code>.</li> <li>Otherwise streams progress as tiles are written and logs success.</li> <li>Failure handling</li> <li>Errors here stop the stage; reruns regenerate if outputs were missing or invalid.</li> </ul>"},{"location":"pipeline/#2-build-correction-json","title":"2. Build correction JSON","text":"<ul> <li>Inputs</li> <li>Uncorrected ENVI pair from stage 1.</li> <li>Output</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code></li> <li>Skip criteria</li> <li>JSON exists and parses.</li> <li>Logging</li> <li>On skip logs     <code>\u2705 Correction JSON already complete for &lt;flight_stem&gt; -&gt; ..._brdfandtopo_corrected_envi.json (skipping)</code>.</li> <li>Otherwise logs that it is computing parameters and then writing the JSON.</li> <li>Failure handling</li> <li>Failures propagate so that reruns recompute the JSON before downstream stages continue.</li> </ul>"},{"location":"pipeline/#3-brdf-topographic-correction","title":"3. BRDF + topographic correction","text":"<ul> <li>Inputs</li> <li>Uncorrected ENVI pair.</li> <li>Correction JSON from stage 2.</li> <li>Outputs</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.img</code></li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.hdr</code></li> <li>Extras</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.parquet</code></li> <li>Skip criteria</li> <li>Corrected ENVI pair exists, is non-empty, and validates.</li> <li>Logging</li> <li>On skip logs     <code>\u2705 BRDF+topo correction already complete for &lt;flight_stem&gt; -&gt; ..._brdfandtopo_corrected_envi.img / ..._brdfandtopo_corrected_envi.hdr (skipping)</code>.</li> <li>When recomputing, streams a chunk progress bar while writing and logs completion.</li> <li>Failure handling</li> <li>Failures raise immediately because the corrected cube is the canonical science product.     Reruns recompute just this stage if its outputs were missing or corrupt.</li> </ul>"},{"location":"pipeline/#4-sensor-convolution-resampling","title":"4. Sensor convolution / resampling","text":"<ul> <li>Inputs</li> <li>Corrected ENVI pair from stage 3. This stage never reads the raw <code>.h5</code>.</li> <li>Sensor spectral response library bundled with the project.</li> <li>Outputs</li> <li>For each known sensor, an ENVI pair following     <code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.img</code> /     <code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.hdr</code> (e.g.     <code>.../NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance_landsat_tm_envi.img</code>).</li> <li>Extras</li> <li>Optional Parquet tables named <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.parquet</code> in     the same folder.</li> <li>Skip criteria</li> <li>Individual sensor ENVI pairs that already exist and validate are skipped and reported.</li> <li>Logging</li> <li>Begins with <code>\ud83c\udfaf Convolving corrected reflectance for &lt;flight_stem&gt;</code>.</li> <li>On fresh generation logs     <code>\u2705 Wrote &lt;sensor_name&gt; product for &lt;flight_stem&gt; -&gt; ..._envi.img / ..._envi.hdr</code>.</li> <li>On skip logs     <code>\u2705 &lt;sensor_name&gt; product already complete for &lt;flight_stem&gt; -&gt; ... (skipping)</code>.</li> <li>Ends with     <code>\ud83d\udcca Sensor convolution summary for &lt;flight_stem&gt; | succeeded=[...] skipped=[...] failed=[...]</code>     followed by <code>\ud83c\udf89 Finished pipeline for &lt;flight_stem&gt;</code>.</li> <li>Failure handling</li> <li>Sensors are processed independently. Missing definitions or write failures mark that     sensor as <code>failed</code> but do not abort the stage unless all sensors fail and none were     previously valid. Partial success is acceptable.</li> </ul>"},{"location":"pipeline/#example-run-transcript","title":"Example run transcript","text":"<p>The restart-safe logs surface the exact work performed. A real rerun for one flight line now looks like:</p> <pre><code>[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\ude80 Processing ...\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udce5 stage_download_h5() found existing .h5 (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udd0e ENVI export target is ..._envi.img / ..._envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 ENVI export already complete -&gt; ..._envi.img / ..._envi.hdr (skipping heavy export)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Correction JSON already complete -&gt; ..._brdfandtopo_corrected_envi.json (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 BRDF+topo correction already complete -&gt; ..._brdfandtopo_corrected_envi.img / ..._brdfandtopo_corrected_envi.hdr (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83c\udfaf Convolving corrected reflectance\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Wrote landsat_tm product -&gt; ..._landsat_tm_envi.img / ..._landsat_tm_envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Wrote micasense product -&gt; ..._micasense_envi.img / ..._micasense_envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udcca Sensor convolution summary | succeeded=['landsat_tm', 'micasense'] skipped=['landsat_etm+', 'landsat_oli', 'landsat_oli2'] failed=[]\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83c\udf89 Finished pipeline\n</code></pre>"},{"location":"pipeline/#parallel-flightline-execution","title":"Parallel flightline execution","text":"<p>After all downloads succeed, <code>go_forth_and_multiply()</code> dispatches each flightline to a <code>ThreadPoolExecutor</code>. The <code>max_workers</code> argument controls the level of concurrency; leave it <code>None</code> to process sequentially. <code>_scoped_log_prefix()</code> prepends <code>[flight_stem]</code> to every log so parallel runs stay readable, and each worker writes only within its own <code>&lt;base&gt;/&lt;flight_stem&gt;/</code> directory to preserve idempotence.</p> <p>When <code>go_forth_and_multiply(...)</code> finishes looping over every requested flight line it logs <code>\u2705 All requested flightlines processed.</code> to confirm site-level completion.</p>"},{"location":"pipeline/#rerun-guidance","title":"Rerun guidance","text":"<p>Call <code>go_forth_and_multiply(...)</code> with the same parameters to rerun an entire site-month. The restart-safe checks ensure that valid artifacts are reused, missing or invalid stages are recomputed, and partial sensor failures do not stop progress across the rest of the flight lines. Because each sensor is accounted for independently, you can inspect the summary lists to see exactly which products succeeded, which were reused, and which need attention.</p>"},{"location":"qa/","title":"Quality Assurance (QA) panels","text":"<p>The <code>spectralbridge-qa</code> command now emits both a PNG panel and a machine-readable <code>*_qa.json</code> file for every flightline. The PNG highlights spectral checks while the JSON records the underlying metrics so you can track drift over time or feed it into dashboards.</p> <pre><code># Deterministic quick pass (\u226425k sampled pixels per flightline)\nspectralbridge-qa --base-folder output_demo --quick\n\n# Exhaustive sampling with custom RGB mapping\nspectralbridge-qa --base-folder output_demo --full --n-sample 150000 --rgb-bands 650,550,480\n</code></pre> <p>Key sections on the panel:</p> <ul> <li>RGB quicklook \u2013 automatically picks 660/560/490 nm (override with   <code>--rgb-bands</code>). Red callouts overlay any flagged issues from the metrics.</li> <li>Histograms \u2013 pre vs post correction distributions with shared bins so you   can judge how BRDF/topo shifts the scene.</li> <li>\u0394 median vs wavelength \u2013 bandwise medians with IQR ribbon; uses header   wavelengths or sensor defaults.</li> <li>Convolved scatter \u2013 compares corrected data to any <code>*_convolved_envi</code>   or <code>*_resampled_&lt;sensor&gt;_envi</code> outputs with a 1:1 reference line.</li> </ul> <p>Each PNG lives alongside <code>&lt;prefix&gt;_qa.json</code>, which mirrors the <code>QAMetrics</code> dataclass (<code>provenance</code>, <code>header</code>, <code>mask</code>, <code>correction</code>, <code>convolution</code>, <code>negatives_pct</code>, <code>overbright_pct</code>, <code>issues</code>). When the brightness correction stage runs, the JSON also lists per-band gain/offsets so the QA team can trace changes back to illumination harmonisation.</p> <p>Use <code>--out-dir</code> if you want to collect all PNG/JSON pairs into a single folder for review. Re-running the command overwrites previous outputs, so a second pass after fixing headers or rerunning corrections always reflects the current state.</p>"},{"location":"qa/#qa-dashboard","title":"QA Dashboard","text":"<p>The legacy <code>cscal-qa-dashboard</code> command still expects <code>_qa_metrics.parquet</code> files. Until the dashboard is updated to read the new JSON schema, keep legacy parquet artifacts if you rely on that summary view.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>This Quickstart gives you two ways to run the pipeline end-to-end:</p> <ol> <li>CLI path \u2013 run <code>spectralbridge-pipeline</code> from a terminal  </li> <li>Notebook path \u2013 run the pipeline inside Jupyter</li> </ol> <p>Both produce the same ENVI, Parquet, and QA artifacts.</p>"},{"location":"quickstart/#install","title":"Install","text":"<p>Install from PyPI:</p> <pre><code>pip install spectralbridge\n</code></pre> <p>For Ray support:</p> <pre><code>pip install \"spectralbridge[full]\"\n</code></pre> <p>Upgrading from older versions? <code>cross_sensor_cal</code> imports and <code>cscal-*</code> commands still work, but new examples use <code>spectralbridge</code> imports and <code>spectralbridge-*</code> entry points.</p>"},{"location":"quickstart/#1-cli-path","title":"1. CLI path","text":"<p>Use the CLI if you run jobs on your laptop, server, or HPC cluster.</p>"},{"location":"quickstart/#run-a-neon-flight-line","title":"Run a NEON flight line","text":"<p>Choose an output directory:</p> <pre><code>BASE=output_quickstart\nmkdir -p \"$BASE\"\n</code></pre> <p>Run the pipeline:</p> <pre><code>spectralbridge-pipeline \\\n  --base-folder \"$BASE\" \\\n  --site-code NIWO \\\n  --year-month 2023-08 \\\n  --product-code DP1.30006.001 \\\n  --flight-lines NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance \\\n  --max-workers 2 \\\n  --engine thread\n</code></pre> <p>The first time this runs, it will:</p> <ul> <li>download NEON HDF5 tiles  </li> <li>export ENVI cubes  </li> <li>apply topographic + BRDF correction  </li> <li>convolve to Landsat-style reflectance  </li> <li>write Parquet tables  </li> <li>produce QA PNG, PDF, and JSON summaries  </li> </ul> <p>If rerun, completed stages are skipped safely.</p>"},{"location":"quickstart/#inspect-qa-files-example-on-macos","title":"Inspect QA files (example on macOS)","text":"<pre><code>open $BASE/NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance/*_qa.png\nopen $BASE/NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance/*_qa.pdf\n</code></pre>"},{"location":"quickstart/#2-notebook-path-jupyter","title":"2. Notebook path (Jupyter)","text":"<p>Use this if you want an interactive, reproducible workflow.</p>"},{"location":"quickstart/#run-the-pipeline-from-python","title":"Run the pipeline from Python","text":"<p>In a notebook cell:</p> <pre><code>from spectralbridge import go_forth_and_multiply\n\nbase = \"output_quickstart_py\"\n\ngo_forth_and_multiply(\n    base_folder=base,\n    site_code=\"NIWO\",\n    year_month=\"2023-08\",\n    product_code=\"DP1.30006.001\",\n    flight_lines=[\"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"],\n    max_workers=2,\n    engine=\"thread\",\n)\n</code></pre>"},{"location":"quickstart/#preview-the-merged-parquet-table","title":"Preview the merged Parquet table","text":"<pre><code>import duckdb, os\n\nfl = \"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"\nmerged = os.path.join(base, fl, f\"{fl}_merged_pixel_extraction.parquet\")\n\nduckdb.query(f\"SELECT * FROM '{merged}' LIMIT 5\").df()\n</code></pre> <p>For a more complete notebook-style walkthrough, see: Usage \u2192 Jupyter notebook example</p>"},{"location":"quickstart/#next-steps","title":"Next steps","text":"<ul> <li>Why cross-sensor calibration? </li> <li>Tutorials</li> <li>Pipeline overview &amp; stages</li> <li>Working with Parquet outputs</li> </ul>"},{"location":"refactor_notes/","title":"Refactor Notes: HyTools-Free Pipeline","text":""},{"location":"refactor_notes/#purpose","title":"Purpose","text":"<p>These notes document the current SpectralBridge processing pipeline after removing the runtime dependency on HyTools. The steps below describe what the code does today so collaborators can reproduce results and audit intermediate products.</p>"},{"location":"refactor_notes/#end-to-end-pipeline","title":"End-to-End Pipeline","text":"<ol> <li> <p>Acquire NEON reflectance flightlines    Download or copy the required NEON Airborne Observation Platform (AOP) reflectance HDF5 files to a local workspace before running the pipeline.</p> </li> <li> <p>Convert HDF5 to ENVI without HyTools <code>neon_to_envi_no_hytools()</code> opens the HDF5 file with <code>NeonCube</code>, streams the cube out in spatial tiles, and writes a float32 BSQ ENVI dataset via <code>EnviWriter</code>. It simultaneously exports ancillary rasters (solar/sensor geometry, slope, aspect, etc.) needed for correction. The result is an uncorrected directional reflectance <code>.img/.hdr</code> pair for each flightline. HyTools and Ray are not invoked in this stage\u2014the conversion logic is entirely internal.</p> </li> <li> <p>Persist correction parameters <code>build_and_write_correction_json()</code> (in <code>brdf_topo.py</code>) inspects the flightline geometry, fits BRDF coefficients, and serialises the results as <code>&lt;flightline&gt;_brdfandtopo_corrected_envi.json</code>. The helper validates the JSON via <code>is_valid_json()</code> and reuses it on reruns when intact.</p> </li> <li> <p>Topographic and BRDF correction    The pipeline allocates a new corrected cube and uses <code>EnviWriter</code> to persist it. For every spatial tile it:</p> </li> <li>Reads the tile from the uncorrected ENVI export.</li> <li>Applies topographic correction using slope, aspect, and solar geometry rasters.</li> <li>Applies BRDF correction using the saved coefficient JSON. When coefficients are missing, unreadable, or poorly conditioned, the code logs a warning and falls back to neutral BRDF terms so the tile still receives topographic correction.</li> <li> <p>Optionally adds a <code>brightness_offset</code> before writing.    The corrected output <code>&lt;flightline&gt;_brdfandtopo_corrected_envi.img/.hdr</code> carries full spatial metadata plus the wavelength list, FWHM list, and wavelength units required for spectral resampling.</p> </li> <li> <p>Spectral convolution / sensor simulation <code>convolve_resample_product()</code> opens the corrected cube as a BSQ memmap, reads spatial tiles, transposes them to <code>(y, x, bands)</code>, and multiplies each tile by sensor-specific spectral response functions (SRFs). SRFs are loaded from JSON files under <code>spectralbridge/data/</code> via package-relative paths. Each simulated sensor produces its own float32 BSQ ENVI product and header. Existing resampled outputs are validated with <code>is_valid_envi_pair()</code> and skipped when already complete.</p> </li> <li> <p>Downstream consumers (optional)    Additional tooling can derive pixel stacks, polygon summaries, or parquet tables from the corrected and resampled rasters. These consumers still function but are documented separately and are not detailed here.</p> </li> </ol> <p>Every step performs the same validation checks on reruns so the pipeline is safe to resume after interruptions or partial failures.</p> <ol> <li>Recommended artifact retention    Keep the following per flightline so downstream analyses and cross-sensor comparisons remain reproducible:</li> <li><code>&lt;flightline&gt;_directional_reflectance.img/.hdr</code></li> <li><code>&lt;flightline&gt;_brdfandtopo_corrected_envi.json</code></li> <li><code>&lt;flightline&gt;_brdfandtopo_corrected_envi.img/.hdr</code></li> <li><code>&lt;flightline&gt;_resampled_&lt;sensor&gt;.img/.hdr</code></li> </ol>"},{"location":"refactor_notes/#module-structure","title":"Module Structure","text":"<ul> <li><code>spectralbridge/neon_cube.py</code></li> <li><code>NeonCube</code> class</li> <li>Opens NEON HDF5 reflectance, exposes dimensions, wavelengths, ancillary angles, etc.</li> <li>Iterates spatial tiles without requiring HyTools.</li> <li><code>spectralbridge/envi_writer.py</code></li> <li><code>EnviWriter</code> class</li> <li>Writes BSQ float32 rasters (<code>.img/.hdr</code>).</li> <li>Used for uncorrected export, corrected cubes, and resampled products.</li> <li><code>spectralbridge/corrections.py</code></li> <li><code>fit_and_save_brdf_model()</code></li> <li><code>apply_topo_correct()</code></li> <li><code>apply_brdf_correct()</code></li> <li>Includes helpers to load and apply BRDF coefficients.</li> <li><code>spectralbridge/resample.py</code></li> <li><code>resample_chunk_to_sensor()</code></li> <li>SRF loading utilities</li> <li>Convolution-friendly helpers for chunk-wise processing.</li> <li><code>spectralbridge/pipelines/pipeline.py</code></li> <li><code>go_forth_and_multiply()</code></li> <li>Orchestrates downloads, H5\u2192ENVI export (no HyTools), BRDF fitting, topographic+BRDF correction, and spectral convolution.</li> <li><code>spectralbridge/data/</code></li> <li>SRF JSON files for Landsat, Sentinel, etc.</li> <li>Accessed via package-relative paths at runtime.</li> </ul>"},{"location":"refactor_notes/#licensing","title":"Licensing","text":"<p>Several algorithms and data-handling conventions in <code>NeonCube</code>, the correction routines, and ENVI export logic were adapted from the HyTools project (GPLv3). Although the refactored pipeline no longer imports HyTools at runtime, we continue to credit the original HyTools authors and comply with GPLv3 obligations for the adapted code.</p>"},{"location":"references/","title":"References","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"references/#cross-calibration","title":"Cross-calibration","text":"<ul> <li>Roy, D.P., Kovalskyy, V., Zhang, H., Vermote, E.F., &amp; Yan, L. (2016). Landsat-8 and Landsat-7 cross-calibration. Remote Sensing of Environment.</li> <li>Claverie, M., Ju, J., Masek, J.G., et al. (2018). The Harmonized Landsat and Sentinel-2 surface reflectance data set. Remote Sensing of Environment.</li> </ul>"},{"location":"references/#citing-this-project","title":"Citing this project","text":"<ul> <li>Earth Lab Data Innovation Team. (2025). SpectralBridge (Version 2.2.0) [Software]. University of Colorado Boulder. https://github.com/earthlab/spectralbridge</li> </ul>"},{"location":"references/#spectral-libraries","title":"Spectral libraries","text":"<ul> <li>Baldridge, A.M., Hook, S.J., Grove, C.I., &amp; Rivera, G. (2009). The ASTER spectral library version 2.0. Remote Sensing of Environment.</li> <li>Kokaly, R.F., Clark, R.N., et al. (2017). USGS Spectral Library Version 7. U.S. Geological Survey Data Series.</li> </ul>"},{"location":"references/#mesma","title":"MESMA","text":"<ul> <li>Roberts, D.A., Gardner, M., Church, R., Ustin, S., Scheer, G., &amp; Green, R.O. (1998). Mapping chaparral in the Santa Monica Mountains using multiple endmember spectral mixture models. Remote Sensing of Environment.</li> <li>Powell, R.L., Roberts, D.A., Dennison, P.E., &amp; Hess, L.L. (2007). Sub-pixel mapping of urban land cover using MESMA. Remote Sensing of Environment.</li> </ul>"},{"location":"references/#brdftopo","title":"BRDF/topo","text":"<ul> <li>Li, X., &amp; Strahler, A.H. (1992). Geometric-optical bidirectional reflectance modeling of the discrete crown vegetation canopy. IEEE Transactions on Geoscience and Remote Sensing.</li> <li>Schaaf, C.B., Gao, F., et al. (2002). First operational BRDF, albedo, and nadir reflectance products from MODIS. Remote Sensing of Environment.</li> <li>Colby, J.D. (1991). Topographic normalization in remote sensing. Remote Sensing of Environment.</li> </ul>"},{"location":"schemas/","title":"Schemas","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"schemas/#raster-band-metadata-schema","title":"Raster band metadata schema","text":"<p>Describes the properties of each raster band after resampling or convolution.</p> Field Type Units Description <code>band</code> int \u2013 Sequential band number <code>wavelength_nm</code> float nm Center wavelength <code>fwhm_nm</code> float nm Full width at half maximum <code>unit</code> string \u2013 Measurement units for reflectance <p>Example JSON:</p> <pre><code>[\n  {\"band\": 1, \"wavelength_nm\": 450.0, \"fwhm_nm\": 20.0, \"unit\": \"nm\"},\n  {\"band\": 2, \"wavelength_nm\": 550.0, \"fwhm_nm\": 25.0, \"unit\": \"nm\"}\n]\n</code></pre>"},{"location":"schemas/#pixel-table-schema","title":"Pixel table schema","text":"<p>Each row represents one pixel extracted from a raster scene.</p> Column Type Units Description <code>Pixel_ID</code> int \u2013 Unique pixel identifier <code>Pixel_Row</code> int row Raster row index (0\u2011based) <code>Pixel_Col</code> int col Raster column index (0\u2011based) <code>B1..Bn</code> float reflectance Band reflectance values <p>Example table:</p> Pixel_ID Pixel_Row Pixel_Col B1 B2 B3 1 10 15 0.12 0.09 0.03 2 11 16 0.10 0.08 0.02"},{"location":"schemas/#spectral-library-schema","title":"Spectral library schema","text":"<p>Spectral libraries store reference spectra for endmembers used during unmixing. When saved as JSON or Parquet, each record contains:</p> Field Type Description <code>spectrum_id</code> string Unique identifier <code>class_label</code> string Endmember class (e.g., soil, vegetation) <code>wavelength_nm</code> array Wavelength centers <code>reflectance</code> array Corresponding reflectance values <code>metadata</code> object Optional information (sensor, date, notes, etc.) <p>Example JSON entry:</p> <pre><code>{\n  \"spectrum_id\": \"veg01\",\n  \"class_label\": \"vegetation\",\n  \"wavelength_nm\": [450, 550, 650],\n  \"reflectance\": [0.12, 0.32, 0.45],\n  \"metadata\": {\"sensor\": \"NEON\", \"acquired\": \"2020-08-01\"}\n}\n</code></pre>"},{"location":"schemas/#mesma-outputs-schema","title":"MESMA outputs schema","text":"<p>Results from Multiple Endmember Spectral Mixture Analysis for each pixel.</p> Column Type Units Description <code>Pixel_ID</code> int \u2013 Input pixel identifier <code>fraction_*</code> float fraction Fractional abundance per endmember band <code>RMSE</code> float reflectance Root mean square error of the model fit <code>QA</code> int \u2013 Quality flag (0=good, higher=worse) <p>Example table:</p> Pixel_ID fraction_soil fraction_veg RMSE QA 1 0.40 0.60 0.01 0 2 0.55 0.45 0.02 1 <p>Example JSON line for one pixel:</p> <pre><code>{\n  \"Pixel_ID\": 1,\n  \"fraction_soil\": 0.40,\n  \"fraction_veg\": 0.60,\n  \"RMSE\": 0.01,\n  \"QA\": 0\n}\n</code></pre> <p>Last updated: 2025-08-18</p>"},{"location":"stage-03-pixel-extraction/","title":"Stage 03 Pixel Extraction","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"stage-03-pixel-extraction/#overview","title":"Overview","text":"<p>At this stage you sample pixels from the sorted scenes and write the values to a tabular file. The table becomes the input to spectral unmixing and other downstream analyses.</p>"},{"location":"stage-03-pixel-extraction/#sampling-rules","title":"Sampling rules","text":"<ol> <li>Define a consistent random seed so repeated runs draw the same pixels.</li> <li>Sample within each land\u2010cover class or tile to avoid geographic bias.</li> <li>Drop any pixel flagged by a quality mask or falling outside the region of interest.</li> </ol>"},{"location":"stage-03-pixel-extraction/#handling-nodata-and-masks","title":"Handling nodata and masks","text":"<ul> <li>Treat nodata values (<code>-9999</code> by default) as missing and skip those records.</li> <li>Apply cloud, shadow, and water masks before sampling so invalid pixels never reach the table.</li> <li>Keep a boolean <code>is_masked</code> column to track which values were rejected.</li> </ul>"},{"location":"stage-03-pixel-extraction/#tile-vs-full-scene","title":"Tile vs full scene","text":"<ul> <li>Tiles scale better for large mosaics and let you parallelize extraction.</li> <li>Full scenes are faster when memory allows and ensure contiguous coverage. Choose the approach that matches your hardware and scene size; the output format is identical.</li> </ul>"},{"location":"stage-03-pixel-extraction/#output-tables","title":"Output tables","text":"<p>Each row represents one pixel. Columns typically include <code>scene_id</code>, <code>tile_id</code>, <code>x</code>, <code>y</code>, band values, and <code>is_masked</code>. Write tables as CSV for quick inspection or Parquet for efficient storage. Keep Parquet outputs in a <code>full_extracted_pixels</code> folder that lives alongside the tile folder so the extracted tables sit next to, not inside, the source data. Partition by scene and tile so you can read subsets without loading the whole dataset.</p>"},{"location":"stage-03-pixel-extraction/#memory-tips","title":"Memory tips","text":"<ul> <li>Process one tile at a time and release arrays with <code>del</code> to free RAM.</li> <li>When writing CSV, stream rows with a generator instead of building a huge DataFrame.</li> <li>Prefer Parquet with compression to reduce disk use and load times.</li> </ul>"},{"location":"stage-03-pixel-extraction/#quick-integrity-checks","title":"Quick integrity checks","text":"<ul> <li>Confirm row counts match the number of valid pixels expected per tile.</li> <li>Scan for remaining nodata values: <code>rg -n \"-9999\" sample.csv</code>.</li> <li>Plot a histogram of one band to detect obvious outliers before moving on.</li> </ul>"},{"location":"stage-03-pixel-extraction/#next-steps","title":"Next steps","text":"<p>Continue to Stage 04 to build the spectral library from the extracted pixels.</p> <p>Last updated: 2025-08-18</p>"},{"location":"stage-04-spectral-library/","title":"Stage 04 Spectral Library","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The spectral library stores every spectrum with its full provenance. Each entry includes:</p> <ul> <li><code>site</code>: location identifier where you collected the field sample.</li> <li><code>sensor</code>: instrument or platform that measured the spectrum.</li> <li><code>wavelengths</code>: array of nanometer values shared across spectra.</li> </ul> <p>These fields live alongside the reflectance values in a row-oriented table or NetCDF group. Use them to filter spectra by site, compare sensors, or align data to the wavelength grid.</p>"},{"location":"stage-04-spectral-library/#quality-controls","title":"Quality controls","text":"<p>You can clean spectra before analysis:</p> <ol> <li>Outlier filtering \u2013 drop samples that exceed three standard deviations from the mean reflectance    at any wavelength.</li> <li>Smoothing \u2013 apply a Savitzky\u2013Golay or moving-average filter to reduce instrument noise while    preserving absorption features.</li> <li>Signal-to-noise ratio (SNR) \u2013 flag spectra with low SNR and exclude them from downstream    modeling.</li> </ol>"},{"location":"stage-04-spectral-library/#versioning-and-provenance","title":"Versioning and provenance","text":"<p>Each library release increments a semantic version. A <code>manifest.json</code> file lists source datasets, processing code commits, and software versions so you can reproduce the library or audit its origin.</p> <p>Last updated: 2025-08-18</p>"},{"location":"stage-05-mesma/","title":"Stage 05 MESMA","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"stage-05-mesma/#using-the-spectral-library","title":"Using the spectral library","text":"<p>The spectral library from Stage 04 provides the candidate endmember spectra. You load it as a NumPy array and pass it to the MESMA routine alongside the target image. MESMA iterates through library combinations to find the model with the lowest root mean square error (RMSE).</p> <pre><code>from unmixing.el_mesma import MesmaCore\n\nmesma = MesmaCore()\nfractions, residuals = mesma._mesma(image, library)\n</code></pre>"},{"location":"stage-05-mesma/#endmember-selection-strategies","title":"Endmember selection strategies","text":"<ul> <li>Exhaustive search \u2013 evaluate all combinations up to a fixed complexity.</li> <li>Class-based \u2013 restrict models to endmembers drawn from predefined   classes such as vegetation or soil.</li> <li>Random sampling \u2013 sample combinations to reduce runtime for large   libraries.</li> </ul>"},{"location":"stage-05-mesma/#outputs","title":"Outputs","text":"<ul> <li>Per-endmember fraction maps showing the proportional contribution of each   material and a shade fraction.</li> <li>A residual raster capturing the difference between observed and reconstructed   spectra.</li> </ul>"},{"location":"stage-05-mesma/#validation","title":"Validation","text":"<ul> <li>Verify that the fractions for each pixel sum to approximately <code>1.0</code>.</li> <li>Discard models with RMSE above a user-defined threshold to ensure a reliable   fit.</li> </ul> <p>Last updated: 2025-08-18</p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>This page lists common problems encountered when running the SpectralBridge pipeline, along with likely causes and recommended solutions. It is organized by pipeline stage.</p>"},{"location":"troubleshooting/#general-issues","title":"General issues","text":""},{"location":"troubleshooting/#the-pipeline-crashes-or-silently-stops","title":"The pipeline crashes or silently stops","text":"<p>Likely causes: - out-of-memory (OOM) errors - temporary directory filling up - unexpected NEON file structure  </p> <p>Solutions: - reduce <code>--max-workers</code> - set <code>CSCAL_TMPDIR</code> to a larger scratch disk - run stages independently using <code>--start-at</code> and <code>--end-at</code></p>"},{"location":"troubleshooting/#download-hdf5-access-issues","title":"Download &amp; HDF5 access issues","text":""},{"location":"troubleshooting/#missing-or-corrupted-hdf5-tiles","title":"Missing or corrupted HDF5 tiles","text":"<ul> <li>NEON occasionally updates directory structures  </li> <li>Cloud storage sessions may time out  </li> </ul> <p>Solutions: - manually verify the HDF5 path - re-run pipeline; downloads are restart-safe - use a fresh working directory  </p>"},{"location":"troubleshooting/#hdf5-envi-export-issues","title":"HDF5 \u2192 ENVI export issues","text":""},{"location":"troubleshooting/#envi-header-not-recognized-or-wavelengths-missing","title":"ENVI header not recognized or wavelengths missing","text":"<p>Causes: - malformed or incomplete HDF5 metadata - older NEON tiles with inconsistent naming conventions  </p> <p>Solutions: - verify the HDF5 product name includes <code>directional_reflectance</code> - ensure correct product code (usually <code>DP1.30006.001</code>) - re-run the export stage only:</p> <p>```bash spectralbridge-pipeline --start-at export-envi --end-at export-envi ... ENVI export produces extremely large or slow files This stage is I/O intensive. Solutions: avoid running many exports concurrently use local SSD scratch storage use thread engine instead of Ray for single-tile workflows Topographic correction issues Dark or clipped areas after topo correction Causes: deep shadows DEM mismatch slope/aspect irregularities Solutions: check DEM resolution visually inspect slope/aspect rasters mask problematic areas if needed BRDF correction issues BRDF correction produces NaNs or extreme values Causes: unstable BRDF coefficient fitting missing or unrealistic geometry values low-SNR or noisy bands Solutions: inspect BRDF coefficients in QA JSON limit BRDF correction to certain bands check for invalid view/solar geometry Sudden brightness shift after BRDF Possible causes: incorrect per-band scaling extreme solar/view geometry BRDF coefficients failing to converge Check the QA PNG or PDF to verify brightness changes. Convolution (sensor harmonization) issues Landsat-convolved reflectance looks wrong Causes: wavelength mismatch empty or incorrect SRF tables bright or dark artifacts from BRDF stage Solutions: inspect SRF metadata in QA JSON confirm NEON wavelengths match expected ranges compare band means to expected Landsat reflectance ranges Brightness coefficients are unusually large This indicates poor alignment between corrected spectra and sensor response functions. Check: reflectance scaling BRDF coefficient stability QA brightness plots Parquet extraction issues Memory errors during extraction or merge Solutions: reduce number of workers increase scratch space use DuckDB for large-table operations rather than pandas QA issues QA PNG or PDF missing Causes: pipeline interrupted before QA stage insufficient permissions in output directory Re-run: spectralbridge-pipeline --start-at qa ... When to reach out for help If the pipeline produces persistent artifacts, consider: sharing the QA PNG/PDF sharing a small snippet of metadata describing environment, RAM, and tile size These provide critical clues about where failure occurs. Next steps Pipeline stages QA metrics</p>"},{"location":"validation/","title":"Validation","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The validation procedure ensures quality across the pipeline.</p>"},{"location":"validation/#stage-01-raster-processing","title":"Stage 01 \u2013 Raster Processing","text":"<ul> <li>[ ] Confirm input rasters exist and are readable.</li> <li>[ ] Check projection and resolution match expected values.</li> <li>[ ] Verify no bands contain all nodata values.</li> <li>[ ] Ensure output rasters write successfully.</li> </ul> <pre><code>import rasterio, numpy as np\nwith rasterio.open(\"image.tif\") as src:\n    data = src.read()\n    assert not np.isnan(data).all(axis=(1, 2))\n</code></pre>"},{"location":"validation/#stage-02-sorting","title":"Stage 02 \u2013 Sorting","text":"<ul> <li>[ ] Confirm filenames follow <code>YYYYMMDD_sensor.tif</code> pattern.</li> <li>[ ] Check chronological ordering after sorting.</li> <li>[ ] Verify number of files per date matches expected counts.</li> </ul> <pre><code>import pandas as pd, glob\nfiles = sorted(glob.glob(\"sorted/*.tif\"))\ndates = pd.to_datetime([f.split(\"_\")[0] for f in files])\nassert dates.is_monotonic_increasing\n</code></pre>"},{"location":"validation/#stage-03-pixel-extraction","title":"Stage 03 \u2013 Pixel Extraction","text":"<ul> <li>[ ] Ensure sample coordinates fall within raster bounds.</li> <li>[ ] Validate pixel value ranges for each band.</li> <li>[ ] Cross-check sample count with original list.</li> </ul> <pre><code>import numpy as np, pandas as pd\npixels = pd.read_csv(\"pixels.csv\")\nassert ((pixels['x']&gt;=0) &amp; (pixels['y']&gt;=0)).all()\nassert pixels.drop(columns=['x','y']).apply(np.isfinite).all().all()\n</code></pre>"},{"location":"validation/#stage-04-spectral-library","title":"Stage 04 \u2013 Spectral Library","text":"<ul> <li>[ ] Verify spectra length equals number of bands.</li> <li>[ ] Check for duplicated materials or IDs.</li> <li>[ ] Inspect outlier reflectance values.</li> </ul> <pre><code>import pandas as pd\nlib = pd.read_csv(\"library.csv\")\nlib.groupby(\"material\").size().pipe(print)\nassert (lib.filter(like=\"band\") &lt;= 1).all().all()\n</code></pre>"},{"location":"validation/#stage-05-mesma","title":"Stage 05 \u2013 MESMA","text":"<ul> <li>[ ] Confirm endmember sets sum to \u22641.</li> <li>[ ] Review residual errors per pixel.</li> <li>[ ] Flag negative abundance values.</li> </ul> <pre><code>import pandas as pd\nabund = pd.read_csv(\"mesma_output.csv\")\nassert (abund.filter(like=\"EM\").sum(axis=1) &lt;= 1.01).all()\nassert (abund.filter(like=\"EM\") &gt;= 0).all().all()\n</code></pre>"},{"location":"_build/doc_drift_report/","title":"Documentation Drift Report","text":""},{"location":"_build/doc_drift_report/#naming-rule","title":"Naming rule","text":"<ul> <li>Merged parquet naming in code: _merged_pixel_extraction.parquet"},{"location":"_build/doc_drift_report/#missing-items-in-docs","title":"Missing items in docs","text":"<ul> <li>Outputs: \u2014</li> <li>Sensors: micasense_to_match_oli_and_oli, micasense_to_match_oli_oli, micasense_to_match_tm_etm_plus</li> </ul>"},{"location":"_build/doc_drift_report/#stale-items-in-docs","title":"Stale items in docs","text":"<ul> <li>Outputs: _landsat_convolved_envi.hdr, _landsat_convolved_envi.img, _landsat_etm+_envi.img, _landsat_oli_envi.parquet, _landsat_tm_envi.hdr, _landsat_tm_envi.img, _micasense*_envi.img, _micasense_envi.hdr, _micasense_envi.img</li> <li>Sensors: MicaSense, MicaSense), MicaSense),, MicaSense,, MicaSense,,, MicaSense,,,, MicaSense,,,,, MicaSense,,,,,, MicaSense,,,,,,, MicaSense,,,,,,,, MicaSense-matched, Micasense,, Micasense,,, Micasense,,,, Micasense,,,,, Micasense,,,,,, Micasense,,,,,,, Micasense,,,,,,,, micasense'], micasense'],, micasense'],,, micasense'],,,, micasense'],,,,, micasense'],,,,,, micasense'],,,,,,, micasense_envi.img,, micasense_envi.img<code>,, micasense-to-landsat, micasense.json</code>, micasense_envi\",, micasense_envi.hdr, micasense_envi.hdr,, micasense_envi.hdr,,, micasense_envi.hdr,,,, micasense_envi.hdr,,,,, micasense_envi.hdr,,,,,, micasense_envi.hdr,,,,,,, micasense_envi.img, micasense_envi.img,, micasense_envi.img,,, micasense_envi.img,,,, micasense_envi.img,,,,, micasense_envi.img,,,,,, micasense_envi.img,,,,,,, micasense_envi.img/.hdr/.parquet, micasense_envi.img/.hdr/.parquet,, micasense_envi.img/.hdr/.parquet,,, micasense_envi.img/.hdr/.parquet,,,, micasense_envi.img/.hdr/.parquet,,,,, micasense_envi.img/.hdr/.parquet,,,,,, micasense_envi.img/.hdr/.parquet,,,,,,, micasense_input, micasense_landsat_harmonized.parquet\"), micasense_to_landsat.csv, micasense_to_match_oli_and_oli,, micasense_to_match_oli_and_oli,,, micasense_to_match_oli_and_oli,,,, micasense_to_match_oli_and_oli,,,,, micasense_to_match_oli_and_oli,,,,,, micasense_to_match_oli_and_oli,,,,,,, micasense_to_match_oli_oli,, micasense_to_match_oli_oli,,, micasense_to_match_oli_oli,,,, micasense_to_match_oli_oli,,,,, micasense_to_match_oli_oli,,,,,, micasense_to_match_oli_oli,,,,,,, micasense_to_match_oli_oli2<code>, micasense_to_match_tm_etm+,,,,,,, micasense_to_match_tm_etm+</code>, micasense_to_match_tm_etm+<code>,, micasense</code>, micasense<code>), micasense</code>,</li> </ul>"},{"location":"_build/doc_drift_report/#entry-points-pyproject","title":"Entry points (pyproject)","text":"<p>{   \"spectralbridge-download\": \"spectralbridge.cli:download_main\",   \"spectralbridge-pipeline\": \"spectralbridge.cli.pipeline_cli:main\",   \"spectralbridge-qa\": \"spectralbridge.cli.qa_cli:main\",   \"spectralbridge-recover-raw\": \"spectralbridge.cli.recover_cli:main\",   \"spectralbridge-qa-dashboard\": \"spectralbridge.qa_dashboard:main\",   \"spectralbridge-merge-duckdb\": \"spectralbridge.merge_duckdb:main\",   \"cscal-download\": \"spectralbridge.cli:download_main\",   \"cscal-pipeline\": \"spectralbridge.cli.pipeline_cli:main\",   \"cscal-qa\": \"spectralbridge.cli.qa_cli:main\",   \"cscal-recover-raw\": \"spectralbridge.cli.recover_cli:main\",   \"cscal-qa-dashboard\": \"spectralbridge.qa_dashboard:main\",   \"csc-merge-duckdb\": \"spectralbridge.merge_duckdb:main\" }</p>"},{"location":"_build/doc_drift_report/#cli-flags-discovered","title":"CLI flags discovered","text":"<p>{   \"topo_and_brdf_correction.py\": [     \"--config_file\"   ],   \"neon_to_envi.py\": [     \"--brightness-offset\"   ],   \"qa_dashboard.py\": [     \"--base-folder\",     \"--out-parquet\",     \"--out-png\"   ],   \"merge_duckdb.py\": [     \"--corrected-glob\",     \"--data-root\",     \"--flightline-glob\",     \"--merge-memory-limit\",     \"--merge-row-group-size\",     \"--merge-temp-directory\",     \"--merge-threads\",     \"--no-qa\",     \"--original-glob\",     \"--out-name\",     \"--resampled-glob\",     \"--write-feather\"   ],   \"standard_resample.py\": [     \"--hdr_path\",     \"--json_file\",     \"--output_path\",     \"--resampling_file_path\",     \"--sensor_type\"   ],   \"qa_cli.py\": [     \"--base-folder\",     \"--full\",     \"--n-sample\",     \"--out-dir\",     \"--quick\",     \"--rgb-bands\",     \"--save-json\"   ],   \"recover_cli.py\": [     \"--base-folder\",     \"--brightness-offset\"   ],   \"pipeline_cli.py\": [     \"--base-folder\",     \"--brightness-offset\",     \"--engine\",     \"--flight-lines\",     \"--max-workers\",     \"--merge-memory-limit\",     \"--merge-row-group-size\",     \"--merge-temp-directory\",     \"--merge-threads\",     \"--parquet-chunk-size\",     \"--product-code\",     \"--resample-method\",     \"--site-code\",     \"--year-month\"   ],   \"pipeline.py\": [     \"--brightness-offset\",     \"--no-sync\",     \"--polygon_layer_path\",     \"--reflectance-offset\",     \"--remote-prefix\",     \"--resample-method\",     \"--verbose\"   ],   \"download.py\": [     \"--flight\",     \"--output\",     \"--product\",     \"--year-month\"   ] }</p>"},{"location":"_build/doc_drift_report/#stage-markers-found-in-logs","title":"Stage markers found in logs","text":"<ul> <li>Writing Parquet with row_group_size=%s</li> <li>[merge] \u26a0\ufe0f QA panel after merge failed for {prefix}: {e}</li> <li>[merge] \ud83d\uddbc\ufe0f  QA panel \u2192 {out_png_path} </li> <li>[{flight_stem}] \u2b07\ufe0f Download already complete \u2014 reusing existing files ({h5_path.name})</li> <li>[{flight_stem}] \ud83c\udf10 Downloading {flight_stem} ({site_code}, {year_month}) into {h5_path} ...</li> <li>\u23ed\ufe0f Parquet already present for %s -&gt; %s (skipping)</li> <li>\u26a0\ufe0f Cannot create Parquet work directory for %s: %s</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .hdr is missing or empty</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .img is missing or empty</li> <li>\u26a0\ufe0f Cannot locate work directory for Parquet export: %s</li> <li>\u26a0\ufe0f Cannot remove invalid Parquet for %s (%s)</li> <li>\u26a0\ufe0f Existing Parquet for %s is invalid (%s); regenerating</li> <li>\u26a0\ufe0f Failed Parquet export for %s: %s</li> <li>\u26a0\ufe0f Merge failed for {future_map[future]}: {exc}</li> <li>\u26a0\ufe0f Parquet validation reported an issue for %s: %s</li> <li>\u26a0\ufe0f Skipping DuckDB merge for %s because no Parquet outputs were produced</li> <li>\u2705 BRDF+topo correction already complete for %s -&gt; %s / %s (skipping)</li> <li>\u2705 BRDF+topo correction already complete for %s, skipping</li> <li>\u2705 BRDF+topo correction completed for %s -&gt; %s / %s</li> <li>\u2705 Discovered existing ENVI export \u2192 {discovered_img.name} / {discovered_hdr.name}</li> <li>\u2705 Download complete for %s \u2192 %s</li> <li>\u2705 ENVI export already complete for %s -&gt; %s / %s (skipping heavy export)</li> <li>\u2705 ENVI export created successfully \u2192 {raw_img_path.name} / {raw_hdr_path.name}</li> <li>\u2705 ENVI export found via discovery \u2192 {discovered_img.name} / {discovered_hdr.name}</li> <li>\u2705 Existing ENVI export found \u2014 skipping heavy export ({raw_img_path.name} / {raw_hdr_path.name})</li> <li>\u2705 Parquet stage complete for %s</li> <li>\u2705 Wrote Parquet for %s -&gt; %s</li> <li>\u2728 Existing ENVI exports detected \u2014 pipeline will reuse validated files automatically.</li> <li>\ud83c\udf89 Finished pipeline for %s</li> <li>\ud83c\udf89 Finished pipeline for %s (parallel worker join)</li> <li>\ud83c\udfaf Convolving corrected reflectance for %s</li> <li>\ud83d\udccd Preparing ENVI export at: {raw_img_path.name} / {raw_hdr_path.name}</li> <li>\ud83d\udce6 No existing ENVI export detected \u2014 creating a new one from source data {h5_path.name}</li> <li>\ud83d\udce6 Parquet export for %s ...</li> <li>\ud83e\uddf1 Parquet row group size = %s (legacy=%s)</li> <li>\ud83e\uddf1 Using Parquet row group size of %s rows</li> </ul> <p>TODO: Review sensor labels in docs for formatting issues.</p>"},{"location":"api/","title":"Python API","text":"<p>Use these functions when you need fine-grained control beyond the CLI.</p>"},{"location":"api/#quick-example","title":"Quick example","text":"<pre><code>from spectralbridge import merge_duckdb\nmerge_duckdb([\"parquet/a.parquet\",\"parquet/b.parquet\"], \"merged/all.parquet\")\n</code></pre>"},{"location":"api/#brightness-correction-entry-point","title":"Brightness correction entry point","text":""},{"location":"api/#apply_brightness_correctioncube-masknone-methodpercentile_match","title":"<code>apply_brightness_correction(cube, mask=None, method='percentile_match', ...)</code>","text":"<p>Normalizes per-band brightness for hyperspectral cubes before BRDF/topo stages. The docstring walks through the affine model, parameter choices, and examples. Use it when you need to harmonise tiles prior to the full pipeline; the QA JSON will surface the per-band gain/offsets when this stage runs.</p> <p>SpectralBridge public package surface.</p>"},{"location":"api/#spectralbridge._PLOT_EXPORTS","title":"<code>_PLOT_EXPORTS = (make_micasense_vs_landsat_panels.__name__, make_sensor_vs_neon_panels.__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#spectralbridge.__all__","title":"<code>__all__ = sorted(set(__all__ + (['apply_brightness_correction', load_brightness_coefficients.__name__] + list(_PLOT_EXPORTS))))</code>  <code>module-attribute</code>","text":""},{"location":"api/#spectralbridge.__version__","title":"<code>__version__ = '2.2.0'</code>  <code>module-attribute</code>","text":""},{"location":"api/#spectralbridge.__getattr__","title":"<code>__getattr__(name)</code>","text":""},{"location":"api/#spectralbridge.load_brightness_coefficients","title":"<code>load_brightness_coefficients(system_pair='landsat_to_micasense')</code>","text":"<p>Load brightness coefficients for a given system pair.</p>"},{"location":"api/#spectralbridge.load_brightness_coefficients--parameters","title":"Parameters","text":"<p>system_pair : str     Key identifying the pair of systems, e.g. \"landsat_to_micasense\".</p>"},{"location":"api/#spectralbridge.load_brightness_coefficients--returns","title":"Returns","text":"<p>dict[int, float]     Mapping from 1-based band index to brightness coefficient (percent).</p>"},{"location":"api/#spectralbridge.load_brightness_coefficients--notes","title":"Notes","text":"<ul> <li>Values are stored in percent (e.g., -7.3959 means \"reduce by 7.3959%\").</li> </ul>"},{"location":"api/#spectralbridge.make_micasense_vs_landsat_panels","title":"<code>make_micasense_vs_landsat_panels(merged_dir, out_dir=None, *, max_points=50000, sentinel_at_or_below=-9999.0)</code>","text":""},{"location":"api/#spectralbridge.make_sensor_vs_neon_panels","title":"<code>make_sensor_vs_neon_panels(merged_dir, out_dir=None, *, max_points=50000, sentinel_at_or_below=-9999.0)</code>","text":""},{"location":"api/merge_duckdb/","title":"API: merge_duckdb","text":"<p>Merge all pixel-level parquet tables for one flightline.</p>"},{"location":"api/merge_duckdb/#spectralbridge.merge_duckdb.merge_flightline--parameters","title":"Parameters","text":"<p>flightline_dir : Path     Directory containing the flightline's parquet outputs. out_name : str, optional     Custom name for the merged parquet. If None, defaults to:     _merged_pixel_extraction.parquet original_glob : str, optional     Glob used to locate original reflectance parquet tables. corrected_glob : str, optional     Glob used to locate corrected reflectance parquet tables. resampled_glob : str, optional     Glob used to locate resampled sensor parquet tables. write_feather : bool, optional     If True, writes a Feather copy of the merged table alongside the parquet. emit_qa_panel : bool, default True     If True, renders the standard QA panel (_qa.png) after merging. ray_cpus : int, optional     CPU budget forwarded to Ray validation of Parquet shards. Defaults to     <code>None</code> which allows the Ray helper to choose the configured default. merge_memory_limit_gb : float or str, optional     Upper bound on DuckDB's memory usage. Floats are interpreted as GiB.     Provide <code>None</code> to leave the default DuckDB behaviour unchanged. merge_threads : int, optional     Number of threads DuckDB should use for the merge. <code>None</code> keeps the     engine default (usually <code>os.cpu_count()</code>). merge_row_group_size : int or None, optional     Target number of rows per Parquet row group in the merged output.     If None, DuckDB will auto-determine the optimal size (better streaming performance). merge_temp_directory : Path, optional     Directory where DuckDB should spill temporary data. Defaults to a     <code>.duckdb_tmp</code> subdirectory inside <code>flightline_dir</code>."},{"location":"api/merge_duckdb/#spectralbridge.merge_duckdb.merge_flightline--returns","title":"Returns","text":"<p>Path     Path to the merged parquet file.</p>"},{"location":"api/qa_plots/","title":"API: qa_plots","text":"<p>Return (png_path, metrics_dict); also writes _qa.json/_qa.pdf when requested.</p>"},{"location":"concepts/why-calibration/","title":"Why cross-sensor calibration?","text":"<p>Understanding vegetation, disturbance, and ecosystem structure often requires integrating information from multiple sensors operating at different spatial, temporal, and spectral scales. These include:</p> <ul> <li>NEON airborne imaging spectroscopy  </li> <li>drone multispectral systems (e.g., MicaSense)  </li> <li>moderate-resolution satellites like Landsat and Sentinel  </li> </ul> <p>Each sensor \u201csees\u201d the landscape differently, and these differences can obscure the ecological signals we care about unless we account for them.</p>"},{"location":"concepts/why-calibration/#the-problem-apples-and-oranges-reflectance","title":"The problem: apples and oranges reflectance","text":"<p>Sensors differ in:</p> <ul> <li>spectral response (band centers, widths, shapes)  </li> <li>illumination geometry (solar zenith, azimuth, atmospheric path)  </li> <li>viewing geometry (sensor zenith, azimuth)  </li> <li>radiometric scaling and masking conventions </li> <li>ground sampling distance and spatial aggregation </li> </ul> <p>Even when they image the same location on the same day, their raw reflectance values are not directly comparable.</p> <p>This creates challenges when trying to:</p> <ul> <li>validate satellite products using NEON  </li> <li>relate drone measurements to NEON or Landsat  </li> <li>build cross-scale ecological models  </li> <li>interpret changes in reflectance through time or across terrain  </li> </ul>"},{"location":"concepts/why-calibration/#correcting-vs-harmonizing","title":"Correcting vs. harmonizing","text":"<p>SpectralBridge performs two distinct operations:</p>"},{"location":"concepts/why-calibration/#1-physical-corrections","title":"1. Physical corrections","text":"<p>These aim to reduce variation caused by illumination and terrain:</p> <ul> <li>topographic correction (slope and aspect effects)  </li> <li>BRDF correction (view/sun geometry effects)  </li> </ul> <p>The result is a reflectance product that is more comparable across acquisition conditions.</p>"},{"location":"concepts/why-calibration/#2-sensor-harmonization","title":"2. Sensor harmonization","text":"<p>This converts corrected hyperspectral data into another sensor\u2019s bandspace by integrating spectra against published spectral response functions (e.g., Landsat OLI, MicaSense RedEdge).</p> <p>Optional brightness adjustments are documented in the QA outputs.</p>"},{"location":"concepts/why-calibration/#why-neon-as-the-foundation","title":"Why NEON as the foundation?","text":"<p>NEON AOP data provide:</p> <ul> <li>high spectral resolution  </li> <li>per-pixel geometry information  </li> <li>consistent radiometric processing  </li> <li>spatial coverage aligned with ecological research sites  </li> </ul> <p>These properties make NEON a powerful intermediary between plot-scale measurements and satellite observations.</p> <p>SpectralBridge implements a reproducible stepwise process to:</p> <ol> <li>extract NEON reflectance into ENVI  </li> <li>correct it physically  </li> <li>harmonize it to satellite/drone sensors  </li> <li>output analysis-ready tables and QA documentation  </li> </ol>"},{"location":"concepts/why-calibration/#what-still-requires-care","title":"What still requires care","text":"<p>Even after calibration and harmonization:</p> <ul> <li>residual BRDF effects can remain  </li> <li>atmospheric differences between sensors matter  </li> <li>snow, smoke, water, and shadows require attention  </li> <li>scale mismatch affects interpretation  </li> <li>masks and quality flags differ across platforms  </li> </ul> <p>The pipeline aims to make all assumptions explicit\u2014every major processing step writes a JSON sidecar describing inputs, parameters, and results.</p>"},{"location":"concepts/why-calibration/#where-to-go-next","title":"Where to go next","text":"<ul> <li> <p>Learn how each pipeline stage works: Pipeline overview &amp; stages</p> </li> <li> <p>Follow a practical workflow: NEON \u2192 corrected ENVI</p> </li> <li> <p>Explore validation and metrics: QA panels &amp; metrics</p> </li> </ul>"},{"location":"dev/architecture/","title":"Package Architecture","text":"<p>This page describes how SpectralBridge is organized internally. Understanding this structure helps contributors extend the pipeline or integrate new sensors without breaking guarantees.</p>"},{"location":"dev/architecture/#design-philosophy-and-invariants","title":"Design philosophy and invariants","text":"<ul> <li>Reproducibility first. Pipeline behavior is predictable and restart-safe; stages skip when valid outputs already exist instead of recomputing.</li> <li>Fixed ordering. <code>process_one_flightline</code> and <code>go_forth_and_multiply</code> orchestrate the same sequence: ENVI export \u2192 BRDF/topographic parameter build \u2192 BRDF+topo correction \u2192 sensor convolution/resampling \u2192 Parquet exports \u2192 DuckDB merge \u2192 QA panels.</li> <li>File contracts. <code>FlightlinePaths</code> centralizes filenames and directories; stages communicate only through these artifacts. Downstream docs and CI treat the merged Parquet and QA products as required outputs.</li> <li>Outputs are the API. Functions return little; correctness is expressed through on-disk ENVI/Parquet and QA files that can be inspected or reused.</li> </ul>"},{"location":"dev/architecture/#pipeline-architecture-high-level","title":"Pipeline architecture (high level)","text":"<ul> <li>Stages are pure file transforms. Each consumes a known input set and writes ENVI, Parquet, and JSON/PNG sidecars. Stages do not mutate shared state.</li> <li>Orchestration happens in <code>pipelines/pipeline.py</code> via <code>process_one_flightline</code> (single flightline) and <code>go_forth_and_multiply</code> (batch). Both rely on <code>FlightlinePaths</code> to resolve paths and naming before delegating work.</li> <li>Communication between stages is file-based. The BRDF+topo-corrected ENVI is always the source for sensor resampling; Parquet exports derive from both raw and corrected ENVI; the merged Parquet and QA summaries consume all earlier artifacts.</li> <li>Restart safety is achieved because each stage validates its outputs and returns early when they already exist. Partial runs can be resumed without recomputation or corrupting prior files.</li> </ul>"},{"location":"dev/architecture/#directory-structure-python-package","title":"Directory structure (Python package)","text":"<ul> <li><code>spectralbridge/pipelines/</code>: orchestration entry points and Ray helpers</li> <li><code>spectralbridge/exports/</code>: ENVI export helpers</li> <li><code>spectralbridge/io/</code>: schema and I/O helpers (e.g., NEON schema resolution)</li> <li><code>spectralbridge/utils/</code>: shared utilities, naming/path helpers, memory management</li> <li><code>spectralbridge/data/</code>: spectral metadata and calibration tables</li> <li><code>landsat_band_parameters.json</code>: band centers/FWHM used for resampling</li> <li><code>brightness/*.json</code>: brightness adjustments between Landsat and MicaSense</li> <li><code>hyperspectral_bands.json</code>: reference metadata for hyperspectral inputs</li> <li><code>spectralbridge/qa_plots.py</code> and <code>spectralbridge/sensor_panel_plots.py</code>: QA visualization utilities</li> <li><code>spectralbridge/standard_resample.py</code>: spectral resampling and coefficients</li> </ul>"},{"location":"dev/architecture/#extending-the-system-safely","title":"Extending the system safely","text":""},{"location":"dev/architecture/#adding-or-modifying-a-target-sensor","title":"Adding or modifying a target sensor","text":"<ul> <li>Update spectral definitions in <code>spectralbridge/data/landsat_band_parameters.json</code> (or analogous table for the new sensor) and ensure resampling logic in <code>standard_resample.py</code> knows how to consume them.</li> <li>Confirm <code>get_flightline_products</code> and <code>FlightlinePaths</code> generate filenames for the new sensor; outputs must still include merged Parquet and QA artifacts.</li> <li>Add tests that validate band definitions and resampled outputs; do not bypass the existing stage ordering.</li> </ul>"},{"location":"dev/architecture/#updating-brightness-or-calibration-coefficients","title":"Updating brightness or calibration coefficients","text":"<ul> <li>Brightness and regression tables live under <code>spectralbridge/data/brightness/</code> and are loaded via <code>brightness_config</code>. Changes here affect downstream cross-sensor harmonization.</li> <li>Keep JSON schema and key names stable; update any dependent tests and documentation describing the coefficients.</li> <li>Validate against Landsat-referenced QA outputs to confirm calibrations remain within expected bounds.</li> </ul>"},{"location":"dev/architecture/#modifying-qa-outputs","title":"Modifying QA outputs","text":"<ul> <li>QA panels and JSON summaries are produced after merging outputs. Filenames such as <code>&lt;flight_id&gt;_qa.png</code> and <code>&lt;flight_id&gt;_qa.json</code> are assumed by docs and CI.</li> <li>If adding metrics or changing formats, ensure <code>_qa.png</code> and <code>_qa.json</code> remain available and update the QA tests under <code>tests/test_qa</code> accordingly.</li> <li>Maintain quick-mode rendering used in CI fixtures so drift checks continue to pass.</li> </ul>"},{"location":"dev/architecture/#relationship-to-scientific-reproducibility","title":"Relationship to scientific reproducibility","text":"<ul> <li>The repository encodes the workflow described in the RSE manuscript; artifacts (ENVI, Parquet, QA) are the evidence trail for analyses.</li> <li>Centralized naming, stage ordering, and idempotent execution make runs auditable and repeatable across environments.</li> <li>Contributors are expected to preserve these invariants so published and future analyses can be reproduced from the same on-disk products.</li> </ul>"},{"location":"dev/architecture/#next-steps","title":"Next steps","text":"<ul> <li>Contributing &amp; development workflow</li> <li>Guidelines for AI/Codex edits</li> </ul>"},{"location":"dev/codex-guidelines/","title":"Guidelines for AI / Codex Edits","text":"<p>This page defines explicit rules for using AI tools (such as GitHub Copilot, ChatGPT, or Codex) when editing this repository. The goal is to maintain scientific accuracy, structural integrity, and documentation consistency.</p>"},{"location":"dev/codex-guidelines/#core-rules","title":"Core rules","text":""},{"location":"dev/codex-guidelines/#1-do-not-invent-scientific-claims","title":"1. Do NOT invent scientific claims","text":"<p>All scientific statements must come from: - NEON documentation - sensor metadata - existing package logic - peer-reviewed sources  </p>"},{"location":"dev/codex-guidelines/#2-do-not-alter-conceptual-meaning-without-review","title":"2. Do NOT alter conceptual meaning without review","text":"<p>Edits must preserve: - scientific correctness - processing assumptions - pipeline logic  </p>"},{"location":"dev/codex-guidelines/#3-do-not-change-navigation-or-folder-structure-unless-instructed","title":"3. Do NOT change navigation or folder structure unless instructed","text":"<p>Documentation layout is intentional and should not be reorganized automatically.</p>"},{"location":"dev/codex-guidelines/#4-do-not-remove-placeholders-schemas-or-metadata","title":"4. Do NOT remove placeholders, schemas, or metadata","text":"<p>These are required for reproducibility.</p>"},{"location":"dev/codex-guidelines/#code-editing-rules","title":"Code-editing rules","text":"<ul> <li>Do not introduce new APIs without discussion  </li> <li>Do not refactor internal architecture without review  </li> <li>Avoid automatic renaming of variables or functions  </li> <li>Confirm that unit tests pass after any edit  </li> </ul>"},{"location":"dev/codex-guidelines/#documentation-editing-rules","title":"Documentation-editing rules","text":"<ul> <li>Only modify the files explicitly referenced in a prompt  </li> <li>Never rewrite entire sections unless provided with exact text  </li> <li>Preserve all fenced code blocks  </li> <li>Maintain consistency with mkdocs navigation  </li> </ul>"},{"location":"dev/codex-guidelines/#when-not-to-use-ai-tools","title":"When NOT to use AI tools","text":"<p>Avoid automatic editing when:</p> <ul> <li>adding new scientific explanations  </li> <li>modifying BRDF/topographic formulas  </li> <li>updating spectral response files  </li> <li>changing reflectance scaling logic  </li> </ul> <p>These require domain expertise.</p>"},{"location":"dev/codex-guidelines/#safe-tasks-for-ai-tools","title":"Safe tasks for AI tools","text":"<ul> <li>inserting text provided by the user  </li> <li>reorganizing text when explicitly instructed  </li> <li>generating placeholder scaffolding  </li> <li>performing mechanical refactors with tests  </li> </ul>"},{"location":"dev/codex-guidelines/#summary","title":"Summary","text":"<p>AI tools in this repository should behave like careful editors\u2014not authors. Always prioritize scientific correctness, reproducibility, and transparency.</p>"},{"location":"dev/codex-guidelines/#next-steps","title":"Next steps","text":"<ul> <li>Contributing &amp; development workflow </li> <li>Package architecture</li> </ul>"},{"location":"dev/contributing/","title":"Contributing &amp; Development Workflow","text":"<p>We welcome contributions from the community. This page outlines expectations for maintaining scientific guarantees, the checks that enforce them, and where to change code safely.</p>"},{"location":"dev/contributing/#design-philosophy-and-invariants","title":"Design philosophy and invariants","text":"<ul> <li>Preserve reproducibility: stages are idempotent and restart-safe; do not add side effects that bypass existing skip logic.</li> <li>Respect ordering: <code>process_one_flightline</code> and <code>go_forth_and_multiply</code> must continue to run stages in the documented sequence.</li> <li>Treat filenames as contracts: <code>FlightlinePaths</code> and naming utilities define how users and CI locate outputs.</li> <li>Outputs over returns: ENVI/Parquet/QA artifacts are the primary interface and must remain stable.</li> </ul>"},{"location":"dev/contributing/#continuous-integration-and-guarantees","title":"Continuous integration and guarantees","text":"<p>CI workflows enforce the invariants above:</p> <ul> <li>Lint + smoke (<code>ci.yml</code>, lite job): <code>ruff check src tests</code> and <code>pytest -q -m \"lite\"</code> with <code>CSCAL_TEST_MODE=lite</code> on Python 3.11.</li> <li>Full tests (<code>ci.yml</code>, unit job): <code>pytest -q</code> with <code>CSCAL_TEST_MODE=unit</code> after lite completes.</li> <li>QA quick check (<code>qa-ci.yml</code>): runs <code>pytest tests/test_qa -q</code> and renders a QA fixture image/JSON to ensure <code>_qa.*</code> outputs remain consistent.</li> <li>Docs build (<code>docs.yml</code>): <code>python tools/site_prepare.py</code> then <code>mkdocs build --strict</code> plus a best-effort link check.</li> <li>Docs drift (<code>docs-drift.yml</code>): <code>python tools/doc_drift_audit.py</code> flags missing mentions of critical artifacts; <code>_merged_pixel_extraction.parquet</code> and <code>_qa.png</code> are treated as required outputs in examples.</li> </ul> <p>Run the key checks locally before opening a PR:</p> <pre><code>ruff check src tests\npython -m pytest -m lite\npython -m pytest\npython tools/site_prepare.py &amp;&amp; mkdocs build --strict\n</code></pre>"},{"location":"dev/contributing/#how-to-extend-the-system-safely","title":"How to extend the system safely","text":""},{"location":"dev/contributing/#adding-or-modifying-a-target-sensor","title":"Adding or modifying a target sensor","text":"<ul> <li>Update spectral parameters in <code>spectralbridge/data/landsat_band_parameters.json</code> (or add an analogous entry) and ensure <code>standard_resample.py</code> can consume them.</li> <li>Confirm <code>get_flightline_products</code>/<code>FlightlinePaths</code> emit filenames for the new sensor and that merged Parquet and QA outputs remain unchanged.</li> <li>Add tests that validate resampled bands and naming; do not change stage ordering or skip logic.</li> </ul>"},{"location":"dev/contributing/#updating-brightness-or-calibration-coefficients","title":"Updating brightness or calibration coefficients","text":"<ul> <li>Coefficients live under <code>spectralbridge/data/brightness/</code> and are loaded via <code>brightness_config</code>. Keep keys stable so regression lookups continue to work.</li> <li>Re-run QA-focused tests and inspect QA outputs against Landsat-referenced expectations after changes.</li> </ul>"},{"location":"dev/contributing/#modifying-qa-outputs","title":"Modifying QA outputs","text":"<ul> <li>QA artifacts (<code>&lt;flight_id&gt;_qa.png</code>, <code>&lt;flight_id&gt;_qa.json</code>) are consumed by docs, drift checks, and downstream users. Preserve these filenames even if adding metrics or plots.</li> <li>Update <code>tests/test_qa</code> and any quick-mode fixtures if output contents change; ensure CI still passes without downloading large datasets.</li> </ul>"},{"location":"dev/contributing/#changing-extraction-or-merge-logic","title":"Changing extraction or merge logic","text":"<ul> <li>Merged Parquet files (<code>&lt;flight_id&gt;_merged_pixel_extraction.parquet</code>) are the contract for downstream analysis. Maintain column consistency and schema ordering expected by users and tests.</li> <li>If adding columns, keep existing ones intact and document the change in the outputs contract page.</li> </ul>"},{"location":"dev/contributing/#relationship-to-scientific-reproducibility","title":"Relationship to scientific reproducibility","text":"<ul> <li>The repository implements the workflow described in the RSE manuscript, so code changes can affect published analyses.</li> <li>Explicit artifacts (ENVI, Parquet, QA) plus drift and QA checks provide an audit trail; contributors are stewards of that record.</li> <li>When altering calibration tables, QA logic, or stage ordering, consider how prior runs would be reproduced and update documentation accordingly.</li> </ul>"},{"location":"dev/contributing/#development-environment","title":"Development environment","text":"<ul> <li>Install in editable mode: <code>pip install -e \".[dev]\"</code></li> <li>Prefer pure functions and clear logging; avoid needless in-memory copies.</li> <li>Update documentation alongside code changes to keep drift checks green.</li> <li>Open an issue, work on a feature branch, add tests, and submit a pull request once checks pass.</li> </ul>"},{"location":"dev/doc_drift/","title":"Doc drift","text":"<p>Maintain this page after any behavior change. Surface a short \"What changed?\" callout on Home if user-facing.</p>"},{"location":"dev/doc_drift/#documentation-drift-report","title":"Documentation Drift Report","text":""},{"location":"dev/doc_drift/#naming-rule","title":"Naming rule","text":"<ul> <li>Merged parquet naming in code: _merged_pixel_extraction.parquet"},{"location":"dev/doc_drift/#missing-items-in-docs","title":"Missing items in docs","text":"<ul> <li>Outputs: \u2014</li> <li>Sensors: micasense_to_match_oli_and_oli, micasense_to_match_oli_oli, micasense_to_match_tm_etm+</li> </ul>"},{"location":"dev/doc_drift/#stale-items-in-docs","title":"Stale items in docs","text":"<ul> <li>Outputs: _brdfandtopo_corrected_envi.parquet, _landsat_etm+_envi.img, _landsat_oli_envi.parquet, _landsat_tm_envi.hdr, _landsat_tm_envi.img, _micasense*_envi.img, _micasense_envi.hdr, _micasense_envi.img, _qa.json</li> <li>Sensors: MicaSense, MicaSense,, MicaSense,,, MicaSense,,,, MicaSense,,,,, MicaSense,,,,,, MicaSense,,,,,,, Micasense,, Micasense,,, Micasense,,,, Micasense,,,,, Micasense,,,,,, Micasense,,,,,,, micasense'], micasense'],, micasense'],,, micasense'],,,, micasense'],,,,, micasense'],,,,,, micasense*_envi.img<code>, micasense_envi.hdr, micasense_envi.hdr,, micasense_envi.hdr,,, micasense_envi.hdr,,,, micasense_envi.hdr,,,,, micasense_envi.hdr,,,,,, micasense_envi.img, micasense_envi.img,, micasense_envi.img,,, micasense_envi.img,,,, micasense_envi.img,,,,, micasense_envi.img,,,,,, micasense_envi.img/.hdr/.parquet, micasense_envi.img/.hdr/.parquet,, micasense_envi.img/.hdr/.parquet,,, micasense_envi.img/.hdr/.parquet,,,, micasense_envi.img/.hdr/.parquet,,,,, micasense_envi.img/.hdr/.parquet,,,,,, micasense_to_match_oli_and_oli,, micasense_to_match_oli_and_oli,,, micasense_to_match_oli_and_oli,,,, micasense_to_match_oli_and_oli,,,,, micasense_to_match_oli_and_oli,,,,,, micasense_to_match_oli_oli,, micasense_to_match_oli_oli,,, micasense_to_match_oli_oli,,,, micasense_to_match_oli_oli,,,,, micasense_to_match_oli_oli,,,,,, micasense_to_match_tm_etm+,,,,,, micasense</code>)</li> </ul>"},{"location":"dev/doc_drift/#entry-points-pyproject","title":"Entry points (pyproject)","text":"<p>{   \"spectralbridge-download\": \"spectralbridge.cli:download_main\",   \"spectralbridge-pipeline\": \"spectralbridge.cli.pipeline_cli:main\",   \"spectralbridge-qa\": \"spectralbridge.cli.qa_cli:main\",   \"spectralbridge-recover-raw\": \"spectralbridge.cli.recover_cli:main\",   \"spectralbridge-qa-dashboard\": \"spectralbridge.qa_dashboard:main\",   \"spectralbridge-merge-duckdb\": \"spectralbridge.merge_duckdb:main\" }</p>"},{"location":"dev/doc_drift/#cli-flags-discovered","title":"CLI flags discovered","text":"<p>{   \"topo_and_brdf_correction.py\": [     \"--config_file\"   ],   \"merge_duckdb.py\": [     \"--corrected-glob\",     \"--data-root\",     \"--flightline-glob\",     \"--no-qa\",     \"--original-glob\",     \"--out-name\",     \"--resampled-glob\",     \"--write-feather\"   ],   \"qa_metrics.py\": [     \"--base-folder\",     \"--flight-stem\"   ],   \"standard_resample.py\": [     \"--hdr_path\",     \"--json_file\",     \"--output_path\",     \"--resampling_file_path\",     \"--sensor_type\"   ],   \"qa_dashboard.py\": [     \"--base-folder\",     \"--out-parquet\",     \"--out-png\"   ],   \"neon_to_envi.py\": [     \"--brightness-offset\"   ],   \"pipeline_cli.py\": [     \"--base-folder\",     \"--brightness-offset\",     \"--flight-lines\",     \"--max-workers\",     \"--product-code\",     \"--resample-method\",     \"--site-code\",     \"--year-month\"   ],   \"recover_cli.py\": [     \"--base-folder\",     \"--brightness-offset\"   ],   \"qa_cli.py\": [     \"--base-folder\",     \"--out-dir\",     \"--quick\",     \"--full\",     \"--save-json\",     \"--no-save-json\",     \"--n-sample\",     \"--rgb-bands\"   ],   \"pipeline.py\": [     \"--brightness-offset\",     \"--no-sync\",     \"--polygon_layer_path\",     \"--reflectance-offset\",     \"--remote-prefix\",     \"--resample-method\",     \"--verbose\"   ],   \"download.py\": [     \"--flight\",     \"--output\",     \"--product\",     \"--year-month\"   ] }</p>"},{"location":"dev/doc_drift/#stage-markers-found-in-logs","title":"Stage markers found in logs","text":"<ul> <li>[spectralbridge-qa] \u2705 QA panels written to: {target.resolve()}</li> <li>\u23ed\ufe0f Parquet already present for %s -&gt; %s (skipping)</li> <li>\u26a0\ufe0f  QA panel generation failed for %s: %s</li> <li>\u26a0\ufe0f Cannot create Parquet work directory for %s: %s</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .hdr is missing or empty</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .img is missing or empty</li> <li>\u26a0\ufe0f Cannot locate work directory for Parquet export: %s</li> <li>\u26a0\ufe0f Failed Parquet export for %s: %s</li> <li>\u26a0\ufe0f Merge failed for {future_map[future]}: {exc}</li> <li>\u26a0\ufe0f QA panel after merge failed for {flightline_dir.name}: {e}</li> <li>\u2705 BRDF+topo correction already complete for %s -&gt; %s / %s (skipping)</li> <li>\u2705 BRDF+topo correction already complete for %s, skipping</li> <li>\u2705 BRDF+topo correction completed for %s -&gt; %s / %s</li> <li>\u2705 Download complete for %s \u2192 %s</li> <li>\u2705 ENVI export already complete for %s -&gt; %s / %s (skipping heavy export)</li> <li>\u2705 ENVI export completed for %s -&gt; %s / %s</li> <li>\u2705 Parquet stage complete for %s</li> <li>\u2705 Wrote Parquet for %s -&gt; %s</li> <li>\ud83c\udf10 Downloading %s (%s, %s) into %s ...</li> <li>\ud83c\udf89 Finished pipeline for %s</li> <li>\ud83c\udf89 Finished pipeline for %s (parallel worker join)</li> <li>\ud83c\udfaf Convolving corrected reflectance for %s</li> <li>\ud83d\udce6 ENVI export not found or invalid for %s, generating from %s</li> <li>\ud83d\udce6 Parquet export for %s ...</li> <li>\ud83d\udd0e ENVI export target for %s is %s / %s</li> <li>\ud83d\uddbc\ufe0f  Overwriting QA panel -&gt; %s</li> <li>\ud83d\uddbc\ufe0f  QA panel written \u2192 {prefix}_qa.png</li> <li>\ud83d\uddbc\ufe0f  Writing QA panel -&gt; %s</li> <li>\ud83d\uddbc\ufe0f  Wrote QA panel for %s -&gt; %s</li> </ul> <p>TODO: Review sensor labels in docs for formatting issues.</p>"},{"location":"dev/doc_drift_report/","title":"Documentation Drift Report","text":""},{"location":"dev/doc_drift_report/#naming-rule","title":"Naming rule","text":"<ul> <li>Merged parquet naming in code: _merged_pixel_extraction.parquet"},{"location":"dev/doc_drift_report/#missing-items-in-docs","title":"Missing items in docs","text":"<ul> <li>Outputs: \u2014</li> <li>Sensors: micasense_to_match_oli_and_oli, micasense_to_match_oli_oli, micasense_to_match_tm_etm_plus</li> </ul>"},{"location":"dev/doc_drift_report/#stale-items-in-docs","title":"Stale items in docs","text":"<ul> <li>Outputs: _landsat_convolved_envi.hdr, _landsat_convolved_envi.img, _landsat_etm+_envi.img, _landsat_oli_envi.parquet, _landsat_tm_envi.hdr, _landsat_tm_envi.img, _micasense*_envi.img, _micasense_envi.hdr, _micasense_envi.img</li> <li>Sensors: MicaSense, MicaSense), MicaSense),, MicaSense,, MicaSense,,, MicaSense,,,, MicaSense,,,,, MicaSense,,,,,, MicaSense,,,,,,, MicaSense,,,,,,,, MicaSense-matched, Micasense,, Micasense,,, Micasense,,,, Micasense,,,,, Micasense,,,,,, Micasense,,,,,,, Micasense,,,,,,,, micasense'], micasense'],, micasense'],,, micasense'],,,, micasense'],,,,, micasense'],,,,,, micasense'],,,,,,, micasense_envi.img,, micasense_envi.img<code>,, micasense-to-landsat, micasense.json</code>, micasense_envi\",, micasense_envi.hdr, micasense_envi.hdr,, micasense_envi.hdr,,, micasense_envi.hdr,,,, micasense_envi.hdr,,,,, micasense_envi.hdr,,,,,, micasense_envi.hdr,,,,,,, micasense_envi.img, micasense_envi.img,, micasense_envi.img,,, micasense_envi.img,,,, micasense_envi.img,,,,, micasense_envi.img,,,,,, micasense_envi.img,,,,,,, micasense_envi.img/.hdr/.parquet, micasense_envi.img/.hdr/.parquet,, micasense_envi.img/.hdr/.parquet,,, micasense_envi.img/.hdr/.parquet,,,, micasense_envi.img/.hdr/.parquet,,,,, micasense_envi.img/.hdr/.parquet,,,,,, micasense_envi.img/.hdr/.parquet,,,,,,, micasense_input, micasense_landsat_harmonized.parquet\"), micasense_to_landsat.csv, micasense_to_match_oli_and_oli,, micasense_to_match_oli_and_oli,,, micasense_to_match_oli_and_oli,,,, micasense_to_match_oli_and_oli,,,,, micasense_to_match_oli_and_oli,,,,,, micasense_to_match_oli_and_oli,,,,,,, micasense_to_match_oli_oli,, micasense_to_match_oli_oli,,, micasense_to_match_oli_oli,,,, micasense_to_match_oli_oli,,,,, micasense_to_match_oli_oli,,,,,, micasense_to_match_oli_oli,,,,,,, micasense_to_match_oli_oli2<code>, micasense_to_match_tm_etm+,,,,,,, micasense_to_match_tm_etm+</code>, micasense_to_match_tm_etm+<code>,, micasense</code>, micasense<code>), micasense</code>,</li> </ul>"},{"location":"dev/doc_drift_report/#entry-points-pyproject","title":"Entry points (pyproject)","text":"<p>{   \"spectralbridge-download\": \"spectralbridge.cli:download_main\",   \"spectralbridge-pipeline\": \"spectralbridge.cli.pipeline_cli:main\",   \"spectralbridge-qa\": \"spectralbridge.cli.qa_cli:main\",   \"spectralbridge-recover-raw\": \"spectralbridge.cli.recover_cli:main\",   \"spectralbridge-qa-dashboard\": \"spectralbridge.qa_dashboard:main\",   \"spectralbridge-merge-duckdb\": \"spectralbridge.merge_duckdb:main\",   \"cscal-download\": \"spectralbridge.cli:download_main\",   \"cscal-pipeline\": \"spectralbridge.cli.pipeline_cli:main\",   \"cscal-qa\": \"spectralbridge.cli.qa_cli:main\",   \"cscal-recover-raw\": \"spectralbridge.cli.recover_cli:main\",   \"cscal-qa-dashboard\": \"spectralbridge.qa_dashboard:main\",   \"csc-merge-duckdb\": \"spectralbridge.merge_duckdb:main\" }</p>"},{"location":"dev/doc_drift_report/#cli-flags-discovered","title":"CLI flags discovered","text":"<p>{   \"topo_and_brdf_correction.py\": [     \"--config_file\"   ],   \"neon_to_envi.py\": [     \"--brightness-offset\"   ],   \"qa_dashboard.py\": [     \"--base-folder\",     \"--out-parquet\",     \"--out-png\"   ],   \"merge_duckdb.py\": [     \"--corrected-glob\",     \"--data-root\",     \"--flightline-glob\",     \"--merge-memory-limit\",     \"--merge-row-group-size\",     \"--merge-temp-directory\",     \"--merge-threads\",     \"--no-qa\",     \"--original-glob\",     \"--out-name\",     \"--resampled-glob\",     \"--write-feather\"   ],   \"standard_resample.py\": [     \"--hdr_path\",     \"--json_file\",     \"--output_path\",     \"--resampling_file_path\",     \"--sensor_type\"   ],   \"qa_cli.py\": [     \"--base-folder\",     \"--full\",     \"--n-sample\",     \"--out-dir\",     \"--quick\",     \"--rgb-bands\",     \"--save-json\"   ],   \"recover_cli.py\": [     \"--base-folder\",     \"--brightness-offset\"   ],   \"pipeline_cli.py\": [     \"--base-folder\",     \"--brightness-offset\",     \"--engine\",     \"--flight-lines\",     \"--max-workers\",     \"--merge-memory-limit\",     \"--merge-row-group-size\",     \"--merge-temp-directory\",     \"--merge-threads\",     \"--parquet-chunk-size\",     \"--product-code\",     \"--resample-method\",     \"--site-code\",     \"--year-month\"   ],   \"pipeline.py\": [     \"--brightness-offset\",     \"--no-sync\",     \"--polygon_layer_path\",     \"--reflectance-offset\",     \"--remote-prefix\",     \"--resample-method\",     \"--verbose\"   ],   \"download.py\": [     \"--flight\",     \"--output\",     \"--product\",     \"--year-month\"   ] }</p>"},{"location":"dev/doc_drift_report/#stage-markers-found-in-logs","title":"Stage markers found in logs","text":"<ul> <li>Writing Parquet with row_group_size=%s</li> <li>[merge] \u26a0\ufe0f QA panel after merge failed for {prefix}: {e}</li> <li>[merge] \ud83d\uddbc\ufe0f  QA panel \u2192 {out_png_path} </li> <li>[{flight_stem}] \u2b07\ufe0f Download already complete \u2014 reusing existing files ({h5_path.name})</li> <li>[{flight_stem}] \ud83c\udf10 Downloading {flight_stem} ({site_code}, {year_month}) into {h5_path} ...</li> <li>\u23ed\ufe0f Parquet already present for %s -&gt; %s (skipping)</li> <li>\u26a0\ufe0f Cannot create Parquet work directory for %s: %s</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .hdr is missing or empty</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .img is missing or empty</li> <li>\u26a0\ufe0f Cannot locate work directory for Parquet export: %s</li> <li>\u26a0\ufe0f Cannot remove invalid Parquet for %s (%s)</li> <li>\u26a0\ufe0f Existing Parquet for %s is invalid (%s); regenerating</li> <li>\u26a0\ufe0f Failed Parquet export for %s: %s</li> <li>\u26a0\ufe0f Merge failed for {future_map[future]}: {exc}</li> <li>\u26a0\ufe0f Parquet validation reported an issue for %s: %s</li> <li>\u26a0\ufe0f Skipping DuckDB merge for %s because no Parquet outputs were produced</li> <li>\u2705 BRDF+topo correction already complete for %s -&gt; %s / %s (skipping)</li> <li>\u2705 BRDF+topo correction already complete for %s, skipping</li> <li>\u2705 BRDF+topo correction completed for %s -&gt; %s / %s</li> <li>\u2705 Discovered existing ENVI export \u2192 {discovered_img.name} / {discovered_hdr.name}</li> <li>\u2705 Download complete for %s \u2192 %s</li> <li>\u2705 ENVI export already complete for %s -&gt; %s / %s (skipping heavy export)</li> <li>\u2705 ENVI export created successfully \u2192 {raw_img_path.name} / {raw_hdr_path.name}</li> <li>\u2705 ENVI export found via discovery \u2192 {discovered_img.name} / {discovered_hdr.name}</li> <li>\u2705 Existing ENVI export found \u2014 skipping heavy export ({raw_img_path.name} / {raw_hdr_path.name})</li> <li>\u2705 Parquet stage complete for %s</li> <li>\u2705 Wrote Parquet for %s -&gt; %s</li> <li>\u2728 Existing ENVI exports detected \u2014 pipeline will reuse validated files automatically.</li> <li>\ud83c\udf89 Finished pipeline for %s</li> <li>\ud83c\udf89 Finished pipeline for %s (parallel worker join)</li> <li>\ud83c\udfaf Convolving corrected reflectance for %s</li> <li>\ud83d\udccd Preparing ENVI export at: {raw_img_path.name} / {raw_hdr_path.name}</li> <li>\ud83d\udce6 No existing ENVI export detected \u2014 creating a new one from source data {h5_path.name}</li> <li>\ud83d\udce6 Parquet export for %s ...</li> <li>\ud83e\uddf1 Parquet row group size = %s (legacy=%s)</li> <li>\ud83e\uddf1 Using Parquet row group size of %s rows</li> </ul> <p>TODO: Review sensor labels in docs for formatting issues.</p>"},{"location":"pipeline/outputs/","title":"Outputs &amp; File Structure","text":""},{"location":"pipeline/outputs/#purpose-of-this-page","title":"Purpose of this page","text":"<ul> <li>Outputs on disk are the primary interface of SpectralBridge.</li> <li>Downstream analyses should rely on these artefacts, not return values from the Python API.</li> </ul>"},{"location":"pipeline/outputs/#canonical-per-flightline-outputs","title":"Canonical per-flightline outputs","text":"<p>Naming stems come from <code>spectralbridge.paths.FlightlinePaths</code> and <code>spectralbridge.utils.naming.get_flightline_products</code>; sensor-specific stems come from <code>SensorProductPaths</code>.</p> Output type Canonical filename pattern Description Notes / guarantees Raw ENVI (when available) <code>&lt;flight_id&gt;_envi.(img|hdr|parquet)</code> Direct export of the NEON HDF5 reflectance cube. Used when present to seed later stages; parquet sidecar is written when exported. BRDF + topographic corrected ENVI <code>&lt;flight_id&gt;_brdfandtopo_corrected_envi.(img|hdr|json|parquet)</code> Physics-informed normalization and correction JSON produced before sensor resampling. One corrected set per flightline; parquet mirrors the corrected ENVI cube. Sensor-resampled ENVI + Parquet <code>&lt;flight_id&gt;_&lt;sensor&gt;_envi.(img|hdr|parquet)</code> where <code>&lt;sensor&gt;</code> is one of <code>landsat_tm</code>, <code>landsat_etm+</code>, <code>landsat_oli</code>, <code>landsat_oli2</code>, <code>micasense</code>, <code>micasense_to_match_tm_etm+</code>, <code>micasense_to_match_oli_oli2</code> Reflectance cubes resampled into the Landsat-referenced frame and MicaSense variants. Each sensor has its own ENVI/Parquet trio; stems are consistent with <code>FlightlinePaths.sensor_products</code>. Merged Parquet <code>&lt;flight_id&gt;_merged_pixel_extraction.parquet</code> Master table that merges Parquet sidecars across stages into one analysis-ready spectral library. Exactly one per flightline; treated as the primary success signal. QA artefacts <code>&lt;flight_id&gt;_qa.png</code>, <code>&lt;flight_id&gt;_qa.json</code>, optional <code>&lt;flight_id&gt;_qa.pdf</code> Visual and numeric QA summaries aligned to the merged outputs. PNG and JSON are expected for every completed run; PDF is produced when rendering is enabled. QA metrics parquet <code>&lt;flight_id&gt;_qa_metrics.parquet</code> Structured QA metrics by band and sensor. Emitted alongside QA JSON/PNG when QA calculation runs."},{"location":"pipeline/outputs/#what-success-means","title":"What \u201csuccess\u201d means","text":"<ul> <li>The merged parquet exists and is readable: <code>&lt;flight_id&gt;_merged_pixel_extraction.parquet</code>.</li> <li>The QA PNG renders: <code>&lt;flight_id&gt;_qa.png</code> (with matching <code>&lt;flight_id&gt;_qa.json</code>).</li> <li>Sensor-specific ENVI/Parquet products exist as configured; absence may reflect configuration rather than failure.</li> <li>If the merged parquet and QA PNG are present, the pipeline completed successfully for that flightline.</li> </ul>"},{"location":"pipeline/outputs/#idempotence-and-restart-safety","title":"Idempotence and restart-safety","text":"<p><code>process_one_flightline</code> and <code>go_forth_and_multiply</code> skip stages whose outputs already exist and validate, so re-running the pipeline will not recompute completed products. This skip-if-valid behavior makes restarts safe and is relied upon in notebook workflows and batch processing alike.</p>"},{"location":"pipeline/outputs/#ci-and-documentation-guarantees","title":"CI and documentation guarantees","text":"<ul> <li>Documentation drift checks (<code>tools/doc_drift_audit.py</code>) assert that <code>_merged_pixel_extraction.parquet</code> and <code>_qa.png</code> remain part of the documented contract.</li> <li>QA expectations and output stems are shared between user-facing docs and automated validation to protect reproducibility.</li> </ul>"},{"location":"pipeline/outputs/#how-to-rely-on-these-outputs","title":"How to rely on these outputs","text":"<ul> <li>Load Parquet products directly (especially the merged parquet) for analysis; they are the authoritative API.</li> <li>Inspect QA PNG/JSON before downstream modeling to confirm spectral health and calibration quality.</li> <li>Treat intermediate ENVI products as optional diagnostics; most workflows can ignore them once Parquet and QA artefacts are present.</li> </ul>"},{"location":"pipeline/polygons/","title":"Polygon spectral library pipeline","text":"<p>The polygon workflow augments the standard flightline processing by producing per-polygon spectral libraries from the existing pixel-level Parquet products. The pipeline is optional today and can be invoked programmatically without changing the default <code>spectralbridge-pipeline</code> behaviour.</p>"},{"location":"pipeline/polygons/#overview","title":"Overview","text":"<p>The polygon pipeline performs three steps for each flightline:</p> <ol> <li>Polygon\u2013pixel index \u2013 rasterises a polygon layer against a chosen NEON    product (BRDF/topography corrected ENVI by default) and records the pixels    that intersect each polygon, including spatial metadata and polygon    attributes, in <code>*_polygon_pixel_index.parquet</code>.</li> <li>Polygon-only Parquets \u2013 filters the existing per-product Parquet tables    so that only pixels found in the index are retained.  Outputs follow the    pattern <code>*_envi_polygons.parquet</code>,    <code>*_brdfandtopo_corrected_envi_polygons.parquet</code> and    <code>*_landsat_tm_envi_polygons.parquet</code> (etc.).</li> <li>Merged polygon spectral library \u2013 joins the polygon-only Parquets with    the polygon index to produce a compact spectral library for all polygons in a    flightline: <code>*_polygons_merged_pixel_extraction.parquet</code>.</li> </ol> <p>The helper functions live in :mod:<code>spectralbridge.polygons</code> and are available for bespoke workflows while we evaluate the approach.</p>"},{"location":"pipeline/polygons/#data-requirements","title":"Data requirements","text":"<ul> <li>A processed flightline directory with the usual per-product Parquet tables.</li> <li>A polygon vector file readable by GeoPandas (e.g. GeoPackage, Shapefile,   GeoJSON).  The repository ships with a sample data set at   <code>Datasets/niwot_aop_polygons_2023_12_8_23_analysis_ready_half_diam.gpkg</code>.</li> </ul> <p>Polygons are reprojected automatically to match the reference raster used for the index.  A <code>polygon_id</code> column is honoured if present; otherwise a unique identifier is generated.</p>"},{"location":"pipeline/polygons/#example-usage","title":"Example usage","text":"<pre><code>from spectralbridge.paths import FlightlinePaths\nfrom spectralbridge.polygons import run_polygon_pipeline_for_flightline\n\nflight_paths = FlightlinePaths(\"/data/flightlines\", \"NEON_D12_NIWO_2021\")\npolygons_path = \"Datasets/niwot_aop_polygons_2023_12_8_23_analysis_ready_half_diam.gpkg\"\n\nresult = run_polygon_pipeline_for_flightline(\n    flight_paths,\n    polygons_path,\n    products=[\n        \"envi\",\n        \"brdfandtopo_corrected_envi\",\n        \"landsat_tm_envi\",\n        \"landsat_oli_envi\",\n        \"micasense_envi\",\n    ],\n)\n\nprint(result[\"polygon_index_path\"])\nprint(result[\"polygon_merged_parquet\"])\n</code></pre> <p>Each helper is also available individually for advanced scenarios:</p> <ul> <li>:func:<code>build_polygon_pixel_index</code> \u2013 create the polygon pixel lookup table.</li> <li>:func:<code>extract_polygon_parquets_for_flightline</code> \u2013 generate polygon-only   Parquet tables for a subset of products.</li> <li>:func:<code>merge_polygon_parquets_for_flightline</code> \u2013 merge polygon Parquets into a   single spectral library.</li> </ul>"},{"location":"pipeline/polygons/#status-and-roadmap","title":"Status and roadmap","text":"<p>The polygon pipeline is opt-in today and does not run as part of the standard flightline orchestration.  The utilities introduced here allow data teams to experiment with polygon spectral libraries ahead of tighter integration in a future release.</p>"},{"location":"pipeline/qa/","title":"QA Panels &amp; Metrics","text":"<p>Each processed NEON flight line generates a set of quality assurance (QA) artifacts designed to summarize reflectance distributions, masks, geometry, and harmonization decisions.</p> <p>This page describes the QA PNG, QA PDF, and QA JSON outputs.</p>"},{"location":"pipeline/qa/#qa-png","title":"QA PNG","text":"<p>The QA PNG provides a quick visual summary of:</p> <ul> <li>reflectance distributions for key wavelengths  </li> <li>spatial distribution of masks  </li> <li>before/after brightness comparison  </li> <li>BRDF correction diagnostics  </li> <li>wavelength alignment checks  </li> </ul> <p>A typical PNG includes panels for:</p> <ol> <li>reflectance histograms  </li> <li>strip-based brightness summaries  </li> <li>cloud/water/snow/invalid pixel frequencies  </li> <li>wavelength metadata  </li> <li>sensor-specific diagnostics  </li> </ol> <p>Use this for fast visual inspection.</p>"},{"location":"pipeline/qa/#qa-pdf","title":"QA PDF","text":"<p>The PDF includes:</p> <ul> <li>all PNG content  </li> <li>multi-page extended diagnostics  </li> <li>tabulated statistics  </li> <li>optional per-band summaries  </li> <li>BRDF coefficient tables  </li> <li>brightness adjustment coefficients  </li> </ul> <p>This document serves as a flight-line-level audit record.</p>"},{"location":"pipeline/qa/#qa-json","title":"QA JSON","text":"<p>The JSON file contains machine-readable metrics including:</p>"},{"location":"pipeline/qa/#reflectance-metrics","title":"Reflectance metrics","text":"<ul> <li>min/max/median for each band  </li> <li>proportion of saturated or masked pixels  </li> <li>brightness differences across correction stages  </li> </ul>"},{"location":"pipeline/qa/#mask-summary-metrics","title":"Mask summary metrics","text":"<ul> <li>percent cloud  </li> <li>percent cloud shadow  </li> <li>percent snow  </li> <li>percent water  </li> <li>percent invalid  </li> </ul>"},{"location":"pipeline/qa/#brdf-metrics","title":"BRDF metrics","text":"<ul> <li>per-band BRDF coefficients  </li> <li>reconstruction error statistics  </li> </ul>"},{"location":"pipeline/qa/#sensor-harmonization-metrics","title":"Sensor harmonization metrics","text":"<ul> <li>brightness coefficients (per band)  </li> <li>spectral alignment checks  </li> <li>per-band RMSE for regression-based harmonization (if applicable)  </li> </ul>"},{"location":"pipeline/qa/#geometry-metadata","title":"Geometry metadata","text":"<ul> <li>solar zenith/azimuth  </li> <li>view zenith/azimuth  </li> <li>DEM statistics  </li> </ul>"},{"location":"pipeline/qa/#interpreting-qa-results","title":"Interpreting QA results","text":"<p>Flags to watch for:</p> <ul> <li>Reflectance values &gt; 1.5 \u2192 possible BRDF or DEM issues  </li> <li>Large brightness shifts \u2192 check convolution stage  </li> <li>High invalid or shadow fraction \u2192 consider masking strategy  </li> <li>Noisy BRDF coefficients \u2192 unstable correction in low-SNR regions  </li> </ul>"},{"location":"pipeline/qa/#next-steps","title":"Next steps","text":"<ul> <li>Pipeline stages </li> <li>Outputs &amp; file structure </li> <li>Troubleshooting</li> </ul>"},{"location":"pipeline/qa_panel/","title":"QA panel","text":"<p>The QA panel couples a metrics JSON file with an annotated PNG so that engineering and science teams can track both spectral statistics and the visual context for every flightline. See How to Interpret the Panel and the validation reference for deeper guidance on each metric.</p> <p>Additional QA products created from the merged Parquet:</p> <ul> <li> <p><code>&lt;prefix&gt;_merged__BY_SENSOR_vs_NEON_directional_BRDFTopo.png</code>   Sensor-by-sensor scatter panels versus NEON directional BRDFTopo.</p> </li> <li> <p><code>&lt;prefix&gt;_merged__MS_vs_Landsat_FIXED.png</code>   MicaSense-matched (X) versus Landsat (Y) scatter panels by band.</p> </li> </ul>"},{"location":"pipeline/qa_panel/#multi-page-qa-report","title":"Multi-page QA report","text":"<p>In addition to the single PNG QA panel (<code>&lt;prefix&gt;_qa.png</code>), the pipeline now writes a multi-page PDF report (<code>&lt;prefix&gt;_qa.pdf</code>) with three pages:</p> <ol> <li> <p>Page 1 \u2013 ENVI overview    One row with one panel per ENVI product. This is a quick visual check that    all ENVI files exist and render correctly.</p> </li> <li> <p>Page 2 \u2013 Topographic &amp; BRDF diagnostics </p> </li> <li>Row 1: pre vs post histograms and \u0394 median vs wavelength for the combined      topographic + BRDF correction stage.  </li> <li> <p>Row 2: summaries of topographic (slope/aspect) and BRDF geometry      (solar/sensor angles) derived from the correction JSON.</p> </li> <li> <p>Page 3 \u2013 Remaining QA diagnostics </p> </li> <li>Convolution scatter plots (expected vs computed bands).  </li> <li>Header and wavelength integrity summary (flags when sensor defaults are used).</li> <li>Mask coverage, negatives %, and &gt;1.2 reflectance % summary.</li> <li>Issues/warnings, including brightness coefficients that were applied.</li> </ol>"},{"location":"pipeline/qa_panel/#qa-panel-and-validation-tests","title":"QA Panel and Validation Tests","text":"<p>The QA panel is the final diagnostic step of the Cross-Sensor Calibration pipeline. It provides both a visual and quantitative summary of how well each product behaved through all correction stages (topographic, BRDF, brightness, convolution).  </p>"},{"location":"pipeline/qa_panel/#what-the-qa-tests-measure","title":"What the QA Tests Measure","text":"Test What It Checks Why It Matters Reflectance Range (negatives &amp; &gt;1.2 %) Fraction of pixels below 0 or above 1.2 Reflectance should remain physically bounded. Large negative or &gt;1.2 values indicate poor radiometric scaling or unmasked clouds/shadows. Header &amp; Wavelength Integrity Presence, count, monotonicity, and provenance of <code>wavelength</code> values in ENVI headers Ensures each band is correctly aligned; missing, non-monotonic, or defaulted wavelengths break convolution and spectral analyses. \u0394Reflectance (Pre\u2192Post Correction) Median and IQR difference in reflectance before and after BRDF/topo correction Quantifies how much the correction changed the data. Large deltas in flat terrain suggest over-correction; near-zero deltas in complex terrain may suggest under-correction. Brightness Normalization (if applied) Per-band gain and offset used in brightness correction Tracks whether correction parameters remain within expected limits (e.g., gain \u2208 [0.9, 1.1]). Large deviations imply inconsistent illumination normalization. Convolution Accuracy (per target sensor) RMSE and Spectral Angle Mapper (SAM) between expected vs computed bands Confirms spectral resampling is physically consistent. High RMSE or large SAM (&gt;0.05 radians) indicates wavelength misalignment or incorrect response functions. Mask Coverage % of valid pixels used for metrics Low valid coverage (&lt;60%) signals missing masks or unfiltered NaNs. Histogram Shape Consistency Visual histogram overlay of pre/post corrections Skewed or bimodal shapes suggest scene heterogeneity or masking issues."},{"location":"pipeline/qa_panel/#brightness-coefficients","title":"Brightness coefficients","text":"<p>When NEON data are convolved to Landsat bands, we optionally apply small per-band brightness adjustments so that Landsat-like products match a MicaSense reference.</p> <ul> <li>Coefficients are stored in <code>landsat_to_micasense.json</code> (units: percent).</li> <li>The adjustment is multiplicative:</li> </ul> <p><code>L_adj = L_raw * (1 + coeff / 100)</code>, where negative coefficients darken   Landsat bands slightly.</p> <ul> <li>Applied coefficients are recorded in the QA JSON under   <code>brightness_coefficients.landsat_to_micasense</code> and displayed on Page 3 of   the QA PDF.</li> </ul> <p>This makes it easy to verify when a brightness adjustment was applied and to audit the exact per-band values.</p>"},{"location":"pipeline/qa_panel/#why-these-tests-are-appropriate","title":"Why These Tests Are Appropriate","text":"<p>These diagnostics are physically interpretable and sensor-agnostic:</p> <ul> <li>Radiometric realism: Reflectance outside [0,1.2] is physically implausible and signals calibration drift or shadow contamination.  </li> <li>Spectral continuity: Monotonic wavelengths ensure that per-band corrections and convolutions follow real sensor band order.  </li> <li>Conservation principle: \u0394Reflectance checks whether corrections preserve brightness globally (no systematic over-darkening).  </li> <li>Geometric realism: Mask coverage and illumination correlation prevent interpreting shadowed or topographically inverted pixels as valid reflectance.  </li> <li>Spectral fidelity: RMSE and SAM compare corrected spectra to expected bandpasses, verifying physical sensor compatibility.</li> </ul>"},{"location":"pipeline/qa_panel/#how-to-interpret-the-panel","title":"How to Interpret the Panel","text":"<p>Each panel includes:</p> <ol> <li>Left: RGB quicklook using auto-selected bands (660, 560, 490 nm).  </li> <li>Uniform color tone: good illumination normalization.  </li> <li>Patchy shadows or gradients: check DTM alignment or BRDF model.</li> <li>Top-right: Pre (gray) vs Post (green) histograms.  </li> <li>Slight narrowing: normal (flattening illumination gradients).  </li> <li>Severe shift left/right: over- or under-correction.</li> <li>Middle-right: \u0394Reflectance vs Wavelength curve (median \u00b1 IQR).  </li> <li>Smooth near-zero line: ideal.  </li> <li>Large band-specific spikes: band-specific sensor noise or cloud edges.</li> <li>Bottom-right: Convolution scatter (expected vs computed).  </li> <li>Points close to 1:1 line: good.  </li> <li>Systematic bias or slope \u2260 1: check wavelength alignment or FWHM mismatch.</li> <li>Footer: Metadata (flightline ID, date, package version, git SHA).</li> </ol>"},{"location":"pipeline/qa_panel/#quantitative-thresholds-for-not-good","title":"Quantitative Thresholds for \u201cNot Good\u201d","text":"Metric Acceptable Range \u201cNeeds Review\u201d \u201cProblematic\u201d Negatives % &lt; 0.5 % 0.5\u20132 % &gt; 2 % &gt;1.2 reflectance % &lt; 0.5 % 0.5\u20132 % &gt; 2 % \u0394Reflectance median &lt; 0.02 (normally good) &gt; 0.05 (over/under-correction) Brightness gain 0.9\u20131.1 0.85\u20130.9 / 1.1\u20131.15 &lt; 0.85 or &gt; 1.15 Convolution RMSE &lt; 0.02 0.02\u20130.05 &gt; 0.05 SAM (radians) &lt; 0.03 0.03\u20130.05 &gt; 0.05 Mask coverage &gt; 80 % 60\u201380 % &lt; 60 %"},{"location":"pipeline/qa_panel/#deciding-when-a-product-fails-qa","title":"Deciding When a Product Fails QA","text":"<p>Mark a product as Needs Review when: - \u2265 2 metrics fall in the \u201cNeeds Review\u201d column, or - Any single metric hits the \u201cProblematic\u201d range.</p> <p>Mark a product as Fail when: - &gt; 10 % of bands exceed thresholds (e.g., \u0394Reflectance &gt; 0.05), - Wavelengths are missing or non-monotonic, - Convolution RMSE &gt; 0.05 and SAM &gt; 0.05, - Mask coverage &lt; 60 %.</p> <p>All QA results are summarized in the sidecar JSON (<code>*_qa.json</code>), enabling programmatic filtering.</p>"},{"location":"pipeline/qa_panel/#next-steps-after-qa-flags","title":"Next Steps After QA Flags","text":"Issue Likely Cause Recommended Fix Many negatives or high reflectance Mis-scaled input, wrong gain offset Re-run brightness correction or check calibration constants. Non-monotonic wavelengths Corrupted or edited header Re-export ENVI or fix <code>wavelength</code> list manually. Large \u0394Reflectance Over-aggressive BRDF correction Adjust BRDF parameters or review illumination mask. High RMSE/SAM Wrong sensor response curves Verify target sensor config file. Low mask coverage Cloud or DTM mask mismatch Improve masking or fill small gaps before QA."},{"location":"pipeline/qa_panel/#automating-qa-review","title":"Automating QA Review","text":"<p>Each QA JSON includes numeric thresholds. You can quickly summarize or flag tiles programmatically:</p> <pre><code>import json, glob\nbad = []\nfor f in glob.glob(\"*/**/*_qa.json\", recursive=True):\n    q = json.load(open(f))\n    if (\n        q[\"negatives_pct\"] &gt; 2.0\n        or q.get(\"overbright_pct\", 0) &gt; 2.0\n        or q[\"mask\"][\"valid_pct\"] &lt; 60\n    ):\n        bad.append(f)\nprint(\"Tiles needing review:\", bad)\n</code></pre>"},{"location":"pipeline/stages/","title":"Pipeline Overview &amp; Stages","text":"<p>The SpectralBridge pipeline transforms NEON HDF5 directional reflectance into physically corrected and sensor-harmonized reflectance products. Each stage is restart-safe and produces structured, auditable outputs.</p> <p>This page describes every stage of the pipeline, what it consumes, what it produces, and what can go wrong.</p>"},{"location":"pipeline/stages/#pipeline-stages-and-idempotence","title":"Pipeline stages and idempotence","text":"<p>The orchestrators <code>process_one_flightline</code> and <code>go_forth_and_multiply</code> enforce the following order:</p> <ol> <li>Download HDF5 (via <code>stage_download_h5</code>).</li> <li>Export ENVI.</li> <li>Build correction JSON.</li> <li>Apply BRDF + topo correction.</li> <li>Resample/convolve all sensors.</li> <li>Export Parquet sidecars.</li> <li>DuckDB merge to merged parquet.</li> <li>Render QA panel + metrics.</li> </ol> <p>Each stage checks whether its expected outputs already exist and are valid, logs a skip message when they do, and recomputes missing or corrupted artefacts. Recovery mode exists for raw ENVI exports when corrected outputs are present (<code>stage_export_envi_from_h5</code> supports <code>recover_missing_raw</code>, used by <code>spectralbridge-recover-raw</code>).</p> <p></p>"},{"location":"pipeline/stages/#1-data-acquisition","title":"1. Data acquisition","text":"<p>Inputs: - NEON API paths or local HDF5 files</p> <p>Outputs: - cached HDF5 tiles stored under the selected <code>--base-folder</code></p> <p>Downloads are handled by <code>stage_download_h5</code> and are triggered automatically by <code>go_forth_and_multiply</code>.</p> <p></p>"},{"location":"pipeline/stages/#2-hdf5-envi-export","title":"2. HDF5 \u2192 ENVI export","text":"<p>Inputs: - <code>*_directional_reflectance.h5</code> - per-pixel geometry and metadata</p> <p>Outputs: - <code>*_envi.img/.hdr</code> (see Outputs)</p> <p><code>stage_export_envi_from_h5</code> creates the ENVI pair using the canonical naming in <code>FlightlinePaths</code>, with optional brightness offsets.</p> <p></p>"},{"location":"pipeline/stages/#3-topographic-brdf-correction","title":"3. Topographic + BRDF correction","text":"<p>Inputs: - directional or raw ENVI exports - DEM-derived slope and aspect - solar/view geometry</p> <p>Outputs: - <code>&lt;flight_id&gt;_brdfandtopo_corrected_envi.(img|hdr|json)</code></p> <p><code>stage_build_and_write_correction_json</code> writes the parameter JSON, and <code>stage_apply_brdf_and_topo</code> applies the combined correction before downstream resampling.</p> <p></p>"},{"location":"pipeline/stages/#4-sensor-harmonization-spectral-convolution","title":"4. Sensor harmonization (spectral convolution)","text":"<p>Inputs: - BRDF+topo corrected ENVI - sensor spectral response functions (SRFs)</p> <p>Outputs: - <code>&lt;flight_id&gt;_&lt;sensor&gt;_envi.(img|hdr|parquet)</code></p> <p><code>stage_convolve_all_sensors</code> delegates to the configured resample method (convolution, legacy, or resample) and iterates through <code>FlightlinePaths.sensor_products</code>.</p> <p></p>"},{"location":"pipeline/stages/#5-parquet-extraction-merging","title":"5. Parquet extraction &amp; merging","text":"<p>Inputs: - any ENVI cube produced by earlier stages</p> <p>Outputs: - Parquet files for raw, corrected, and resampled cubes - <code>&lt;flight_id&gt;_merged_pixel_extraction.parquet</code></p> <p><code>_export_parquet_stage</code> builds the per-product Parquet sidecars, and <code>merge_flightline</code> (DuckDB) consolidates them with schema validation before optional QA rendering.</p> <p></p>"},{"location":"pipeline/stages/#6-quality-assurance-qa","title":"6. Quality assurance (QA)","text":"<p>Inputs: - merged parquet and supporting ENVI files</p> <p>Outputs: - <code>&lt;flight_id&gt;_qa.png</code> - <code>&lt;flight_id&gt;_qa.json</code> - <code>&lt;flight_id&gt;_qa.pdf</code> (when rendered)</p> <p>QA artefacts come from <code>render_flightline_panel</code> and mirror the canonical stems listed in Outputs.</p>"},{"location":"pipeline/stages/#next-steps","title":"Next steps","text":"<ul> <li>Outputs &amp; file structure</li> <li>QA panels &amp; metrics</li> </ul>"},{"location":"reference/configuration/","title":"Configuration","text":"<p>Most users can rely on default configuration, but the pipeline allows fine-grained control over processing stages, performance, and file handling.</p> <p>This page documents the available configuration parameters and how they affect pipeline behavior.</p>"},{"location":"reference/configuration/#configuration-sources","title":"Configuration sources","text":"<ol> <li>Command-line options (highest priority)  </li> <li>Environment variables  </li> <li>Default internal settings  </li> </ol>"},{"location":"reference/configuration/#common-settings","title":"Common settings","text":""},{"location":"reference/configuration/#base-folder","title":"<code>base-folder</code>","text":"<p>Directory where:</p> <ul> <li>downloaded HDF5 tiles  </li> <li>ENVI exports  </li> <li>Parquet tables  </li> <li>QA artifacts  </li> </ul> <p>are written.</p>"},{"location":"reference/configuration/#engine","title":"<code>engine</code>","text":"<p>Execution backend:</p> <ul> <li><code>thread</code> (default)  </li> <li><code>ray</code> (distributed/hyperparallel workflows)</li> </ul>"},{"location":"reference/configuration/#max-workers","title":"<code>max-workers</code>","text":"<p>Controls concurrency in:</p> <ul> <li>ENVI export  </li> <li>BRDF and topo correction  </li> <li>Parquet extraction  </li> </ul> <p>Use cautiously when memory is limited.</p>"},{"location":"reference/configuration/#pipeline-scope","title":"Pipeline scope","text":"<p>The CLI currently runs the full stage sequence; idempotent checks in <code>process_one_flightline</code> skip work when outputs already exist.</p>"},{"location":"reference/configuration/#environment-variables","title":"Environment variables","text":"Variable Meaning <code>CSCAL_TMPDIR</code> Override temporary directory <code>CSCAL_LOGLEVEL</code> Set logging verbosity <code>CSCAL_RAY_ADDRESS</code> Use an existing Ray cluster <p>Advanced configuration These settings primarily matter for large-scale workflows:</p> <ul> <li>chunk sizes for Parquet extraction</li> <li>memory thresholds for Ray worker processes</li> <li>default CRS assignments</li> <li>sensor SRF paths</li> </ul> <p>Details of internal architecture appear in the Developer section.</p>"},{"location":"reference/configuration/#sensor-support-configuration-sources","title":"Sensor support &amp; configuration sources","text":"<p>Supported sensor outputs (from <code>FlightlinePaths.sensor_products</code>):</p> <ul> <li><code>landsat_tm</code></li> <li><code>landsat_etm+</code></li> <li><code>landsat_oli</code></li> <li><code>landsat_oli2</code></li> <li><code>micasense</code></li> <li><code>micasense_to_match_tm_etm+</code></li> <li><code>micasense_to_match_oli_oli2</code></li> </ul> <p>Spectral configuration comes from:</p> <ul> <li><code>spectralbridge/data/landsat_band_parameters.json</code></li> <li><code>spectralbridge/data/hyperspectral_bands.json</code></li> <li>brightness coefficients loaded via <code>load_brightness_coefficients(system_pair)</code> in <code>spectralbridge/brightness_config.py</code> with tables stored under <code>spectralbridge/data/brightness/*.json</code></li> </ul> <p>If you update brightness coefficients, refresh the JSON tables accordingly. Provenance/citation for brightness regression tables: (needs project decision). Next steps JSON schemas Validation metrics Pipeline stages</p>"},{"location":"reference/extending/","title":"Extending","text":"<p>When do I need this? When adding a new target sensor or swapping readers/writers; follow the extension points listed here.</p>"},{"location":"reference/extending/#purpose","title":"Purpose","text":"<p>Guide contributions that add sensors to Stage 5 or new exporters feeding Outputs.</p>"},{"location":"reference/extending/#inputs","title":"Inputs","text":"<ul> <li>Bandpass definitions (CSV/JSON) for the new sensor</li> <li>Implementation classes under <code>spectralbridge</code> to register</li> <li>Tests covering the new workflow</li> </ul>"},{"location":"reference/extending/#outputs","title":"Outputs","text":"<p>Updated convolution products and schemas consumed by Parquet export &amp; merge.</p>"},{"location":"reference/extending/#run-it","title":"Run it","text":"<pre><code>pytest tests/convolution/test_new_sensor.py\n</code></pre> <pre><code>from spectralbridge.convolution import registry\n\nprint(registry.available_sensors())\n</code></pre>"},{"location":"reference/extending/#pitfalls","title":"Pitfalls","text":"<ul> <li>Forgetting to update schemas will break Stage 6 merges.</li> <li>Ship lightbox-friendly QA thumbnails when adding new visualization layers.</li> <li>Document new sensors in Pipeline Stages and Troubleshooting.</li> </ul>"},{"location":"reference/schemas/","title":"JSON Schemas","text":"<p>The pipeline emits several JSON files containing structured metadata and QA metrics. These files allow downstream tools to audit processing decisions and validate outputs.</p> <p>This page summarizes the purpose and structure of each schema.</p>"},{"location":"reference/schemas/#1-envi-export-metadata","title":"1. ENVI export metadata","text":"<p>Recorded in:</p> <p>*_export_metadata.json</p> <p>Contains:</p> <ul> <li>wavelength array  </li> <li>band names  </li> <li>reflectance scaling (NEON conventions)  </li> <li>mask types and bit fields  </li> <li>CRS and affine transform  </li> </ul>"},{"location":"reference/schemas/#2-topographic-correction-metadata","title":"2. Topographic correction metadata","text":"<p>*_topo_metadata.json</p> <p>Includes:</p> <ul> <li>slope and aspect statistics  </li> <li>solar geometry used  </li> <li>mask adjustments  </li> <li>correction parameters  </li> </ul>"},{"location":"reference/schemas/#3-brdf-metadata","title":"3. BRDF metadata","text":"<p>*_brdf_metadata.json</p> <p>Includes:</p> <ul> <li>BRDF coefficients per wavelength  </li> <li>RMSE of BRDF fits  </li> <li>flags for unstable fits  </li> <li>view/sun geometry summaries  </li> </ul>"},{"location":"reference/schemas/#4-convolution-metadata-sensor-harmonization","title":"4. Convolution metadata (sensor harmonization)","text":"<p>*_convolution_metadata.json</p> <p>Contains:</p> <ul> <li>SRF files used  </li> <li>wavelength alignment checks  </li> <li>brightness correction coefficients  </li> <li>bandpass integration statistics  </li> </ul>"},{"location":"reference/schemas/#5-qa-metrics-schema","title":"5. QA metrics schema","text":"<p>The QA JSON file contains:</p> <ul> <li>reflectance summary statistics  </li> <li>mask percentages  </li> <li>wavelength metadata  </li> <li>BRDF/brightness coefficients  </li> <li>geometry metadata  </li> </ul> <p>Exact fields are defined in the validation section.</p>"},{"location":"reference/schemas/#using-schemas-in-downstream-workflows","title":"Using schemas in downstream workflows","text":"<p>These JSON files support:</p> <ul> <li>reproducibility  </li> <li>debugging  </li> <li>statistical evaluation of harmonization quality  </li> <li>provenance tracking for scientific analyses  </li> </ul>"},{"location":"reference/schemas/#next-steps","title":"Next steps","text":"<ul> <li>Validation metrics </li> <li>Pipeline outputs</li> </ul>"},{"location":"reference/validation/","title":"Validation Metrics","text":"<p>This page documents the validation metrics generated by SpectralBridge and recorded primarily in the QA JSON file. These metrics characterize reflectance quality, BRDF stability, harmonization accuracy, and mask distributions.</p>"},{"location":"reference/validation/#reflectance-metrics","title":"Reflectance metrics","text":"<ul> <li>min/max/median per band  </li> <li>out-of-range counts (&gt;1.5 or &lt;0)  </li> <li>percent masked </li> <li>per-band histograms (in QA PNG/PDF)  </li> </ul> <p>High out-of-range values may indicate issues in BRDF correction or DEM artifacts.</p>"},{"location":"reference/validation/#mask-metrics","title":"Mask metrics","text":"<ul> <li>cloud fraction  </li> <li>cloud-shadow fraction  </li> <li>snow fraction  </li> <li>water fraction  </li> <li>invalid/no-data fraction  </li> </ul> <p>These metrics help identify flights with adverse conditions or sensor anomalies.</p>"},{"location":"reference/validation/#brdf-metrics","title":"BRDF metrics","text":"<ul> <li>per-band BRDF model coefficients  </li> <li>reconstruction RMSE  </li> <li>flags for unstable or ill-conditioned fits  </li> </ul> <p>These diagnostics help identify pixels or bands where geometric normalization may be unreliable.</p>"},{"location":"reference/validation/#convolution-harmonization-metrics","title":"Convolution / harmonization metrics","text":"<ul> <li>brightness adjustment coefficients  </li> <li>per-band regression statistics (if applicable)  </li> <li>spectral alignment differences  </li> <li>RMSE for harmonized vs. reference spectra  </li> </ul> <p>These values help assess the quality of sensor harmonization.</p>"},{"location":"reference/validation/#geometry-and-ancillary-metrics","title":"Geometry and ancillary metrics","text":"<ul> <li>solar zenith / azimuth  </li> <li>view zenith / azimuth  </li> <li>DEM slope/aspect summaries  </li> </ul> <p>These values allow interpretation of scene illumination conditions.</p>"},{"location":"reference/validation/#using-metrics-for-quality-control","title":"Using metrics for quality control","text":"<p>Typical red flags:</p> <ul> <li>Large brightness shifts (&gt;0.1 reflectance)  </li> <li>High invalid fraction (&gt;20%)  </li> <li>Poor BRDF fits (RMSE &gt; threshold for the site/sensor)  </li> <li>Unusual wavelength alignment differences </li> </ul> <p>These indicators suggest reviewing the flight line before using it in ecological analyses.</p>"},{"location":"reference/validation/#next-steps","title":"Next steps","text":"<ul> <li>QA panels </li> <li>JSON schemas</li> </ul>"},{"location":"tutorials/cloud-workflow/","title":"Tutorial: Cloud &amp; HPC Workflows","text":"<p>This tutorial describes how to run the SpectralBridge pipeline efficiently in cloud or HPC environments where data access, storage, and memory constraints differ from a local workstation.</p>"},{"location":"tutorials/cloud-workflow/#overview","title":"Overview","text":"<p>You will learn:</p> <ul> <li>best practices for running the pipeline in object-storage environments  </li> <li>when to use thread mode vs. Ray mode  </li> <li>how to work with large NEON datasets without local persistence  </li> <li>strategies for scaling multi-flightline workflows  </li> </ul>"},{"location":"tutorials/cloud-workflow/#1-working-with-object-storage-eg-cyverse","title":"1. Working with object storage (e.g., CyVerse)","text":"<p>NEON HDF5 tiles can be accessed using <code>gocmd</code> or iRODS commands.</p> <p>Recommended workflow:</p> <ol> <li>Stage a small number of HDF5 tiles into a temporary working directory  </li> <li>Run the pipeline on those tiles  </li> <li>Upload corrected ENVI + Parquet outputs to persistent storage  </li> <li>Clean intermediate files to save space  </li> </ol> <p>Example staging command:</p> <p>```bash gocmd get i:/iplant/home/.../NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance.h5 . 2. Engine selection: threads vs Ray Thread engine Best for: small to medium flight lines machines with limited memory single-tile debugging Ray engine Best for: many flight lines distributed cloud environments parallel extraction and merging Enable Ray: pip install spectralbridge[ray] Run: spectralbridge-pipeline ... --engine ray 3. Memory considerations Large NEON flight lines may be tens of gigabytes. To avoid memory pressure: reduce chunk sizes use --max-workers conservatively prefer per-tile processing rather than large batch merging avoid keeping many ENVI cubes in memory simultaneously In Ray mode, ensure worker memory matches expected tile size (e.g., 16\u201332 GB per worker). 4. Recommended HPC workflow Submit one job per flight line Request enough memory for a single NEON tile (~20\u201340 GB) Use local scratch storage for temporary files Upload final ENVI + Parquet products to shared storage Merge results downstream using DuckDB or Python This scales cleanly across sites and years. 5. Example SLURM script</p>"},{"location":"tutorials/cloud-workflow/#binbash","title":"!/bin/bash","text":""},{"location":"tutorials/cloud-workflow/#sbatch-job-namecscal","title":"SBATCH --job-name=cscal","text":""},{"location":"tutorials/cloud-workflow/#sbatch-mem64g","title":"SBATCH --mem=64G","text":""},{"location":"tutorials/cloud-workflow/#sbatch-cpus-per-task8","title":"SBATCH --cpus-per-task=8","text":"<p>module load python</p> <p>BASE=$SCRATCH/cscal_${SLURM_JOB_ID} mkdir -p \"$BASE\"</p> <p>spectralbridge-pipeline \\   --base-folder \"$BASE\" \\   --site-code NIWO \\   --year-month 2023-08 \\   --product-code DP1.30006.001 \\   --flight-lines NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance \\   --engine thread \\   --max-workers 8 6. Next steps Pipeline stages Using Parquet outputs Troubleshooting</p>"},{"location":"tutorials/micasense-to-landsat/","title":"Tutorial: MicaSense \u2192 Landsat Harmonization","text":"<p>This tutorial demonstrates how to harmonize drone-scale multispectral reflectance (e.g., MicaSense RedEdge) into Landsat-equivalent band values using the SpectralBridge regression workflow.</p>"},{"location":"tutorials/micasense-to-landsat/#overview","title":"Overview","text":"<p>You will learn how to:</p> <ol> <li>prepare MicaSense reflectance inputs  </li> <li>apply band mapping and wavelength matching  </li> <li>use regression tables to harmonize reflectance  </li> <li>inspect harmonized Landsat-style products  </li> </ol> <p>This allows direct comparison between drone and satellite observations.</p>"},{"location":"tutorials/micasense-to-landsat/#1-inputs","title":"1. Inputs","text":"<p>You need reflectance values from a calibrated drone multispectral system. These can be:</p> <ul> <li>stacked reflectance TIFFs  </li> <li>ENVI-formatted band images  </li> <li>Parquet tables exported from your workflow  </li> </ul> <p>Each band should have known center wavelengths.</p>"},{"location":"tutorials/micasense-to-landsat/#2-harmonization-workflow","title":"2. Harmonization workflow","text":"<p>SpectralBridge uses regression relationships linking MicaSense band values to Landsat OLI bands. These regressions are derived from calibrated field and NEON comparisons.</p> <p>Run the following command:</p> <p>```bash spectralbridge-micasense-to-landsat \\   --input your_micasense_input \\   --output ms_to_ls_output \\   --regression-table data/regression/micasense_to_landsat.csv Outputs include: Landsat-equivalent reflectance table diagnostic statistics optional ENVI export 3. Inspecting harmonized reflectance Example: import pandas as pd</p> <p>df = pd.read_parquet(\"ms_to_ls_output/micasense_landsat_harmonized.parquet\") df.head() Columns will match Landsat bands: Blue Green Red NIR SWIR1 SWIR2 4. NDVI sanity check df[\"ndvi\"] = (df[\"NIR\"] - df[\"Red\"]) / (df[\"NIR\"] + df[\"Red\"]) df[\"ndvi\"].describe() If harmonization worked correctly, NDVI should fall within typical vegetation ranges (0.1\u20130.9 for most cases). 5. Next steps Integrate drone \u2192 NEON \u2192 Landsat comparisons Combine harmonized products with NEON-derived spectra Use the merged output in ecological modeling workflows See also: NEON \u2192 Landsat tutorial Pipeline outputs</p>"},{"location":"tutorials/neon-to-envi/","title":"Tutorial: NEON \u2192 Corrected ENVI (BRDF + Topographic)","text":"<p>This tutorial walks through converting NEON hyperspectral HDF5 files into physically corrected ENVI reflectance cubes. The output is the foundational product used in all downstream harmonization workflows (e.g., Landsat-style reflectance).</p>"},{"location":"tutorials/neon-to-envi/#overview","title":"Overview","text":"<p>You will learn how to:</p> <ol> <li>download NEON directional reflectance tiles  </li> <li>export them to ENVI format  </li> <li>apply topographic correction  </li> <li>apply BRDF correction  </li> <li>inspect corrected outputs and QA artifacts  </li> </ol> <p>This tutorial assumes you have installed SpectralBridge and have run through the Quickstart.</p>"},{"location":"tutorials/neon-to-envi/#1-set-up-a-working-directory","title":"1. Set up a working directory","text":"<p>```bash BASE=output_neon_to_envi mkdir -p \"$BASE\" 2. Run the pipeline for one flight line Here we process a single NEON hyperspectral flight line at NIWO. spectralbridge-pipeline \\   --base-folder \"$BASE\" \\   --site-code NIWO \\   --year-month 2023-08 \\   --product-code DP1.30006.001 \\   --flight-lines NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance \\   --engine thread \\   --max-workers 2 The command will: fetch the necessary HDF5 files export directional reflectance to ENVI (_envi.img/.hdr) apply topographic correction apply BRDF correction write corrected ENVI reflectance (_brdfandtopo_corrected_envi.img) generate QA PNG, PDF, and JSON files Re-running the command will skip completed stages. 3. What the corrected ENVI product contains A corrected flight line directory contains files such as: _directional_reflectance_envi.img _topocorrected_envi.img _brdfandtopo_corrected_envi.img _qa.png _qa.pdf _qa.json The key output is: *_brdfandtopo_corrected_envi.img This file contains physically corrected reflectance values suitable for sensor harmonization or modeling. 4. Inspect the corrected ENVI cube You can view the ENVI product using: ENVI/IDL QGIS (with raster bands exposed) Python libraries such as rioxarray or spectral Example in Python: import rioxarray as rxr</p> <p>cube = rxr.open_rasterio(\"path/to/..._brdfandtopo_corrected_envi.img\") cube This loads the corrected reflectance cube into an xarray DataArray. 5. Inspect QA outputs Open the QA PNG: open \"$BASE/..._qa.png\" The QA panel includes: reflectance range checks brightness differences across correction stages mask summary statistics wavelength and band metadata BRDF / topographic coefficient summaries The PDF version includes multi-page diagnostics and expanded panels. 6. Next steps Proceed to: NEON \u2192 Landsat reflectance Pipeline stages for in-depth explanations Working with Parquet to extract and analyze pixel spectra</p>"},{"location":"tutorials/neon-to-landsat/","title":"Tutorial: NEON \u2192 Landsat-Style Reflectance","text":"<p>This tutorial shows how to convert physically corrected NEON ENVI reflectance into Landsat-equivalent reflectance using sensor spectral response functions (SRFs).</p> <p>The output is a set of ENVI cubes and Parquet tables representing NEON reflectance expressed in the Landsat bandspace.</p>"},{"location":"tutorials/neon-to-landsat/#prerequisites","title":"Prerequisites","text":"<p>Before running this tutorial, complete:</p> <ul> <li>NEON \u2192 corrected ENVI</li> </ul> <p>You will need the <code>*_brdfandtopo_corrected_envi.img</code> output for convolution.</p>"},{"location":"tutorials/neon-to-landsat/#1-select-a-corrected-envi-cube","title":"1. Select a corrected ENVI cube","text":"<p>Your corrected data should look like:</p> <p>.../NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance/ NEON_D13_NIWO_..._brdfandtopo_corrected_envi.img</p> <p>This file is the input to Landsat bandpass convolution.</p>"},{"location":"tutorials/neon-to-landsat/#2-run-the-convolution-stage","title":"2. Run the convolution stage","text":"<p>If you used the main pipeline, convolution runs automatically after BRDF+topo correction. To run only the convolution stage manually:</p> <p>```bash spectralbridge-pipeline \\   --base-folder \"$BASE\" \\   --site-code NIWO \\   --year-month 2023-08 \\   --product-code DP1.30006.001 \\   --flight-lines NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance \\   --max-workers 2 \\   --engine thread \\   --start-at convolution Outputs include: _landsat_convolved_envi.img _landsat_convolved_envi.hdr *_landsat_convolved.parquet 3. Understanding Landsat bandpass integration The convolution stage integrates each corrected spectrum against Landsat OLI SRFs: Coastal / Blue / Green / Red NIR SWIR1 SWIR2 This process produces reflectance values aligned to Landsat definitions, enabling: direct comparison to satellite imagery validation exercises cross-scale modeling harmonized NDVI and other vegetation indices 4. Inspecting Landsat-like ENVI outputs Example in Python: import rioxarray as rxr</p> <p>landsat = rxr.open_rasterio(\"path/to/..._landsat_convolved_envi.img\") landsat Band order, wavelengths, and metadata will match the Landsat OLI sensor. 5. Checking the QA metrics The QA JSON and QA PNG will now include: brightness adjustments used in Landsat harmonization bandwise statistics after convolution wavelength alignment checks mask and no-data diagnostics Use this to verify successful harmonization. 6. Using the Parquet tables The *_landsat_convolved.parquet file contains: one row per pixel columns for each Landsat-equivalent band pixel geometry and mask indicators Example: import duckdb</p> <p>duckdb.query(\"\"\"     SELECT Red, NIR, (NIR - Red) / (NIR + Red) AS ndvi     FROM '..._landsat_convolved.parquet'     LIMIT 5 \"\"\").df() 7. Next steps Continue to: MicaSense \u2192 Landsat harmonization Working with Parquet Pipeline QA</p>"},{"location":"usage/cli/","title":"Command-Line Interface (CLI)","text":"<p>The CLI provides restart-safe entry points for downloading NEON flightlines, running the full pipeline, generating QA outputs, and merging Parquet artefacts.</p> <p>Legacy <code>cscal-*</code>/<code>csc-*</code> entry points still work and forward to the same implementation, but the primary names are <code>spectralbridge-*</code>.</p>"},{"location":"usage/cli/#spectralbridge-download","title":"<code>spectralbridge-download</code>","text":"<p>Purpose: Download NEON HDF5 flightlines into a workspace (<code>spectralbridge.cli:download_main</code>).</p> <p>Usage:</p> <pre><code>spectralbridge-download\n</code></pre> <p>Key options: - <code>site</code> (positional) and <code>--year-month</code> (required) identify the NEON flightlines. - <code>--flight</code> (repeatable) lists flightline IDs. - <code>--product</code> sets the NEON product code (default <code>DP1.30006.001</code>). - <code>--output</code> controls the destination directory (default <code>data</code>).</p> <p>Outputs: HDF5 files saved under <code>&lt;output&gt;/&lt;site&gt;/</code> for later <code>spectralbridge-pipeline</code> runs.</p>"},{"location":"usage/cli/#spectralbridge-pipeline","title":"<code>spectralbridge-pipeline</code>","text":"<p>Purpose: Run the full cross-sensor pipeline (<code>spectralbridge.cli.pipeline_cli:main</code>).</p> <p>Usage:</p> <pre><code>spectralbridge-pipeline\n</code></pre> <p>Key options: - Required: <code>--base-folder</code>, <code>--site-code</code>, <code>--year-month</code>, <code>--product-code</code>, <code>--flight-lines</code>. - Resampling: <code>--resample-method</code> (<code>convolution</code>, <code>legacy</code>, or <code>resample</code>). - Performance: <code>--engine</code> (<code>thread</code>, <code>process</code>, <code>ray</code>), <code>--max-workers</code> (defaults to 8), <code>--parquet-chunk-size</code>. - Merge tuning: <code>--merge-memory-limit</code>, <code>--merge-threads</code>, <code>--merge-row-group-size</code>, <code>--merge-temp-directory</code>. - Radiometry: <code>--brightness-offset</code> for ENVI export.</p> <p>Outputs: Everything listed in Outputs, including <code>_merged_pixel_extraction.parquet</code> and <code>_qa.png</code>.</p>"},{"location":"usage/cli/#spectralbridge-qa","title":"<code>spectralbridge-qa</code>","text":"<p>Purpose: Re-render QA panels/metrics for existing flightline folders (<code>spectralbridge.cli.qa_cli:main</code>).</p> <p>Usage:</p> <pre><code>spectralbridge-qa\n</code></pre> <p>Key options: - <code>--base-folder</code> (required) points to the workspace containing flightline directories. - Sampling: <code>--quick</code> (25k deterministic sample) vs <code>--full</code> (use configured size), <code>--n-sample</code> to override pixel count. - <code>--rgb-bands</code> to override RGB band selection. - <code>--save-json</code> to toggle writing <code>&lt;flight_id&gt;_qa.json</code>. - <code>--out-dir</code> to copy PNG/JSON outputs elsewhere after generation.</p> <p>Outputs: QA PNG/JSON (and PDF if rendered) following the naming in Outputs.</p>"},{"location":"usage/cli/#spectralbridge-recover-raw","title":"<code>spectralbridge-recover-raw</code>","text":"<p>Purpose: Backfill raw ENVI exports when corrected products already exist (<code>spectralbridge.cli.recover_cli:main</code>).</p> <p>Usage:</p> <pre><code>spectralbridge-recover-raw\n</code></pre> <p>Key options: - <code>--base-folder</code> (required) where HDF5 and flightline folders live. - <code>--brightness-offset</code> to pass through to <code>stage_export_envi_from_h5</code>.</p> <p>Outputs: Restores <code>&lt;flight_id&gt;_envi.(img|hdr)</code> so later stages can proceed or be revalidated.</p>"},{"location":"usage/cli/#spectralbridge-qa-dashboard","title":"<code>spectralbridge-qa-dashboard</code>","text":"<p>Purpose: Aggregate QA metrics across flightlines and build an overview plot (<code>spectralbridge.qa_dashboard:main</code>).</p> <p>Usage:</p> <pre><code>spectralbridge-qa-dashboard\n</code></pre> <p>Key options: - <code>--base-folder</code> (required) root containing flightline outputs. - <code>--out-parquet</code> to choose the aggregated summary parquet path. - <code>--out-png</code> to choose the dashboard PNG path.</p> <p>Outputs: <code>qa_dashboard_summary.parquet</code> and <code>qa_dashboard_summary.png</code> (default locations inside the base folder) summarizing <code>&lt;flight_id&gt;_qa_metrics.parquet</code> tables.</p>"},{"location":"usage/cli/#spectralbridge-merge-duckdb","title":"<code>spectralbridge-merge-duckdb</code>","text":"<p>Purpose: Merge per-product Parquet tables into a master parquet and optional QA panel (<code>spectralbridge.merge_duckdb:main</code>).</p> <p>Usage:</p> <pre><code>spectralbridge-merge-duckdb\n</code></pre> <p>Key options: - <code>--data-root</code> (required) and <code>--flightline-glob</code> to locate flightline folders. - <code>--out-name</code> to override the default <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code>. - Input globs: <code>--original-glob</code>, <code>--corrected-glob</code>, <code>--resampled-glob</code>. - QA and format controls: <code>--no-qa</code> to skip PNG, <code>--write-feather</code> to emit Feather alongside Parquet. - Merge tuning: <code>--merge-memory-limit</code>, <code>--merge-threads</code>, <code>--merge-row-group-size</code>, <code>--merge-temp-directory</code>.</p> <p>Outputs: Merged parquet (and optional QA PNG/JSON) matching the naming patterns in Outputs.</p>"},{"location":"usage/notebook-example/","title":"Start Here: Notebook Workflow","text":"<p>This page is the canonical notebook-first path for running SpectralBridge. It walks through one successful flightline run that produces harmonized, Landsat-referenced outputs on disk\u2014not return values\u2014so you can bridge UAS and NEON observations to the long-term Landsat record without touching the CLI.</p>"},{"location":"usage/notebook-example/#1-minimal-setup","title":"1) Minimal setup","text":"<pre><code>import spectralbridge\nfrom spectralbridge.pipelines.pipeline import (\n    process_one_flightline,\n    go_forth_and_multiply,\n)\n</code></pre> <p>Use <code>process_one_flightline</code> when you are exploring or validating a single flightline. Use <code>go_forth_and_multiply</code> when you have a list of flightlines and want the same pipeline applied in batch.</p>"},{"location":"usage/notebook-example/#2-canonical-single-flightline-example","title":"2) Canonical single-flightline example","text":"<pre><code>from pathlib import Path\n\n# Where all artifacts will be written\nbase_folder = Path(\"csc_output\")\n\n# Identify the NEON site and acquisition window for clarity\nsite_code = \"NIWO\"\nyear_month = \"2023-08\"\nflightline_id = \"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"\n\n# Run the structured, skip-aware pipeline for one flightline\nprocess_one_flightline(\n    base_folder=base_folder,\n    product_code=\"DP1.30006.001\",  # NEON hyperspectral product\n    flight_stem=flightline_id,\n)\n</code></pre> <p>The defaults handle topographic + BRDF correction, spectral convolution into the Landsat frame, brightness adjustment, Parquet export, and QA generation. Re-running the cell will skip stages that are already valid so interrupted sessions can resume safely.</p>"},{"location":"usage/notebook-example/#3-what-gets-created","title":"3) What gets created","text":"<p>A successful run produces a directory named after the flightline inside <code>base_folder</code> containing:</p> <ul> <li>Corrected ENVI reflectance cubes.</li> <li>Landsat-resampled ENVI cubes and Parquet sidecars.</li> <li><code>{flightline_id}_merged_pixel_extraction.parquet</code> (the master table that merges all Parquet sidecars).</li> <li><code>{flightline_id}_qa.png</code> and <code>{flightline_id}_qa.json</code> (visual + numeric QA summaries).</li> </ul> <p>Existing, validated outputs are reused on subsequent runs, so partial runs can be resumed without starting over. Seeing both the merged Parquet and QA artifacts is a good signal that the end-to-end pipeline completed.</p>"},{"location":"usage/notebook-example/#4-inspect-results-in-the-notebook","title":"4) Inspect results in the notebook","text":"<p>Load the merged Parquet table to confirm the expected columns and a few rows:</p> <pre><code>import pandas as pd\n\nflight_dir = base_folder / flightline_id\nmerged_parquet = flight_dir / f\"{flightline_id}_merged_pixel_extraction.parquet\"\n\nmerged_df = pd.read_parquet(merged_parquet)\nmerged_df.head()\n</code></pre> <p>Check the available fields to guide downstream analysis:</p> <pre><code>sorted(merged_df.columns)\n</code></pre> <p>Locate the QA outputs so you can open them in your notebook or file browser:</p> <pre><code>qa_png = flight_dir / f\"{flightline_id}_qa.png\"\nqa_json = flight_dir / f\"{flightline_id}_qa.json\"\n\nqa_png, qa_json\n</code></pre> <p>Use your notebook environment to display the PNG or parse the JSON for validation details.</p>"},{"location":"usage/notebook-example/#5-what-to-do-next","title":"5) What to do next","text":"<ul> <li>Browse notebook recipes for batch runs, QA refreshes, and quick exploration patterns.</li> <li>Review Outputs &amp; naming to understand the file contract and where to find products.</li> <li>Read the Concepts section for the rationale behind the Landsat-referenced normalization.</li> <li>If you prefer or need the command-line interface, see the CLI reference.</li> </ul>"},{"location":"usage/parquet/","title":"Working with Parquet Outputs","text":"<p>The SpectralBridge pipeline writes Parquet files for each ENVI product it generates. These tables contain one row per pixel and are optimized for high-performance analytics with DuckDB, pandas, or xarray.</p>"},{"location":"usage/parquet/#why-parquet","title":"Why Parquet?","text":"<ul> <li>Supports efficient columnar reads  </li> <li>Compresses well for large datasets  </li> <li>Easily queryable using SQL (DuckDB)  </li> <li>Allows out-of-core or streaming access  </li> </ul>"},{"location":"usage/parquet/#file-structure","title":"File structure","text":"<p>Typical Parquet file naming:</p> <p>_brdfandtopo_corrected.parquet _landsat_convolved.parquet *_merged_pixel_extraction.parquet</p> <p>Each file contains columns for:</p> <ul> <li>reflectance values  </li> <li>band metadata  </li> <li>masks  </li> <li>pixel coordinates  </li> <li>optional ancillary variables  </li> </ul>"},{"location":"usage/parquet/#quick-preview-using-duckdb","title":"Quick preview using DuckDB","text":"<p>```python import duckdb</p> <p>duckdb.query(\"\"\"     SELECT *     FROM '..._brdfandtopo_corrected.parquet'     LIMIT 5 \"\"\").df() DuckDB provides efficient SQL queries without needing to load the entire dataset into memory. Checking dimensions duckdb.query(\"\"\"     SELECT COUNT(*) AS nrows     FROM '..._landsat_convolved.parquet' \"\"\").df() Loading with pandas import pandas as pd df = pd.read_parquet(\"..._merged_pixel_extraction.parquet\") df.head() Use with caution for large flight lines. Loading with xarray Parquet \u2192 xarray workflows work best after pivoting or aggregating data. For full spatial cubes, ENVI files remain easier to load. Streaming large files DuckDB can scan files lazily: duckdb.query(\"\"\"     SELECT AVG(NIR), AVG(Red)     FROM '..._landsat_convolved.parquet' \"\"\").df() This avoids loading the full table. Next steps CLI usage Pipeline outputs</p>"},{"location":"usage/parquet_preview/","title":"Parquet Preview","text":"pandasDuckDBpolars <pre><code>import pandas as pd\ndf = pd.read_parquet(\"merged/demo_merged_pixel_extraction.parquet\")\ndf.head()\nprint([c for c in df.columns if c.startswith(\"band_\")][:10])\n</code></pre> <pre><code>import duckdb\ncon = duckdb.connect()\ncon.execute(\"SELECT * FROM 'merged/demo_merged_pixel_extraction.parquet' LIMIT 5\").df()\n</code></pre> <pre><code>import polars as pl\ndf = pl.read_parquet(\"merged/demo_merged_pixel_extraction.parquet\")\ndf.head(5)\n</code></pre>"},{"location":"usage/recipes/","title":"Recipes: Notebook Patterns","text":"<p>These short recipes start from files on disk after the pipeline has run. Copy the cells into your notebook to repeat common workflows and stay aligned with the outputs-and-naming contract.</p>"},{"location":"usage/recipes/#recipe-1-run-a-single-flightline-recap","title":"Recipe 1: Run a single flightline (recap)","text":"<p>Use this when you want the canonical, restart-safe run for one flightline. See the Start Here notebook workflow for the full walkthrough.</p> <pre><code>from pathlib import Path\nfrom spectralbridge.pipelines.pipeline import process_one_flightline\n\nbase_folder = Path(\"csc_output\")\nsite_code = \"NIWO\"\nyear_month = \"2023-08\"\nflightline_id = \"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"\n\nprocess_one_flightline(\n    base_folder=base_folder,\n    product_code=\"DP1.30006.001\",\n    flight_stem=flightline_id,\n)\n</code></pre> <p>Expect to see <code>{flightline_id}_merged_pixel_extraction.parquet</code> plus <code>{flightline_id}_qa.png</code>/<code>{flightline_id}_qa.json</code> in <code>base_folder / flightline_id</code> when it finishes.</p>"},{"location":"usage/recipes/#recipe-2-batch-process-multiple-flightlines","title":"Recipe 2: Batch process multiple flightlines","text":"<p><code>go_forth_and_multiply</code> applies the same pipeline to many flightlines and skips work that already succeeded. Safe to re-run if a notebook or kernel restarts mid-way.</p> <pre><code>from pathlib import Path\nfrom spectralbridge.pipelines.pipeline import go_forth_and_multiply\n\nbase_folder = Path(\"csc_output\")\nflightline_ids = [\n    \"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\",\n    \"NEON_D13_NIWO_DP1_L020-2_20230815_directional_reflectance\",\n]\n\ngo_forth_and_multiply(\n    base_folder=base_folder,\n    product_code=\"DP1.30006.001\",\n    flight_stems=flightline_ids,\n)\n</code></pre> <p>Restarting this cell later will fast-forward past any flightlines that already have merged Parquet and QA artefacts.</p>"},{"location":"usage/recipes/#recipe-3-re-run-qa-on-existing-outputs","title":"Recipe 3: Re-run QA on existing outputs","text":"<p>Generate fresh QA artefacts from completed flightlines without recomputing the pipeline.</p> <pre><code>from pathlib import Path\nfrom spectralbridge.qa_plots import render_flightline_panel\n\nflight_dir = Path(\"csc_output\") / \"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"\n\npng_path, metrics = render_flightline_panel(\n    flightline_dir=flight_dir,\n    quick=True,  # deterministic sampling\n    save_json=True,\n)\nprint(\"QA PNG \u2192\", png_path)\nprint(\"Issues:\", metrics.get(\"issues\", []))\n</code></pre> <p>This operates on existing ENVI and Parquet products in <code>flight_dir</code> and rewrites <code>{flight_id}_qa.png</code> and <code>{flight_id}_qa.json</code> only. If you prefer the CLI, <code>spectralbridge-qa</code> wraps the same logic for batch folders.</p>"},{"location":"usage/recipes/#recipe-4-load-and-explore-the-merged-parquet","title":"Recipe 4: Load and explore the merged Parquet","text":"<p>The merged Parquet is the analysis starting point. Use pandas or pyarrow/DuckDB depending on scale.</p> <pre><code>import pandas as pd\nfrom pathlib import Path\n\nflight_dir = Path(\"csc_output\") / \"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"\nmerged_parquet = flight_dir / f\"{flight_dir.name}_merged_pixel_extraction.parquet\"\n\nmerged_df = pd.read_parquet(merged_parquet)\nmerged_df.head()\n</code></pre> <p>Inspect available fields to guide filtering and joins:</p> <pre><code>[col for col in merged_df.columns if \"wl\" in col][:10]  # sample band columns\n</code></pre> <p>For large files, prefer streaming SQL with DuckDB:</p> <pre><code>import duckdb\n\nrel = duckdb.read_parquet(str(merged_parquet))\nrel.limit(5).df()\n</code></pre>"},{"location":"usage/recipes/#recipe-5-extract-spectra-for-polygons","title":"Recipe 5: Extract spectra for polygons","text":"<p>Link pixels to polygons using the optional polygon pipeline utilities built on top of the merged Parquet and ENVI outputs.</p> <pre><code>from spectralbridge.paths import FlightlinePaths\nfrom spectralbridge.polygons import run_polygon_pipeline_for_flightline\n\nflight_paths = FlightlinePaths(\"csc_output\", \"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\")\npolygons_path = \"Datasets/niwot_aop_polygons_2023_12_8_23_analysis_ready_half_diam.gpkg\"\n\nresult = run_polygon_pipeline_for_flightline(\n    flight_paths,\n    polygons_path,\n    products=[\n        \"envi\",\n        \"brdfandtopo_corrected_envi\",\n        \"landsat_tm_envi\",\n        \"landsat_oli_envi\",\n    ],\n)\n\nresult[\"polygon_merged_parquet\"]\n</code></pre> <p>The helper rasterises polygons, filters per-product Parquet tables, and writes <code>&lt;flight_id&gt;_polygons_merged_pixel_extraction.parquet</code> for direct use in modeling notebooks. See <code>docs/pipeline/polygons.md</code> for deeper details.</p>"},{"location":"usage/recipes/#recipe-6-compare-sensors-for-the-same-targets","title":"Recipe 6: Compare sensors for the same targets","text":"<p>Pull harmonized spectra across sensors from the merged Parquet to validate translation results.</p> <pre><code>import pandas as pd\nfrom pathlib import Path\n\nflight_dir = Path(\"csc_output\") / \"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"\nmerged_parquet = flight_dir / f\"{flight_dir.name}_merged_pixel_extraction.parquet\"\n\ndf = pd.read_parquet(merged_parquet)\n\n# Example: pick a handful of pixels and compare corrected NEON vs Landsat-resampled bands\npixel_subset = df.head(100)[\"pixel_id\"]\n\ncorr_cols = [c for c in df.columns if c.startswith(\"corr_\")]\nlandsat_cols = [c for c in df.columns if \"landsat\" in c and c.endswith(\"nm\")]\n\ncomparison = df.loc[df[\"pixel_id\"].isin(pixel_subset), [\"pixel_id\", *corr_cols[:5], *landsat_cols[:5]]]\ncomparison.head()\n</code></pre> <p>This lightweight slice shows matched bands from corrected NEON cubes alongside Landsat-referenced resamples for the same pixels; extend the selection for full-band comparisons or summary statistics.</p>"},{"location":"usage/recipes/#where-to-go-next","title":"Where to go next","text":"<ul> <li>Return to the Start Here notebook workflow if you need to rerun the pipeline.</li> <li>Review Outputs &amp; file structure for naming guarantees.</li> <li>Read the Concepts page for the scientific rationale behind the translation steps.</li> </ul>"}]}