{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#cross-sensor-calibration","title":"Cross-Sensor Calibration","text":"<p>Turn raw NEON hyperspectral flight lines into corrected ENVI cubes, sensor-matched products, tidy Parquet, and a QA panel\u2014in one restart-safe command.</p>"},{"location":"#run-your-first-tile-3-steps","title":"Run your first tile (3 steps)","text":"<pre><code># 1) Create an output base\nBASE=output_demo &amp;&amp; mkdir -p \"$BASE\"\n\n# 2) Process one flight line (replace IDs as needed)\ncscal-pipeline \\\n  --base-folder \"$BASE\" \\\n  --site-code NIWO \\\n  --year-month 2023-08 \\\n  --product-code DP1.30006.001 \\\n  --flight-lines NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance \\\n  --max-workers 2\n\n# 3) Open the QA image (and PDF report)\nopen \"$BASE/NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance/NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance_qa.png\"\nopen \"$BASE/NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance/NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance_qa.pdf\"\n</code></pre> <p>New here? See the Quickstart.</p> <p>Something broke? Jump to Troubleshooting.</p>"},{"location":"#why-teams-use-cross-sensor-cal","title":"Why teams use cross-sensor-cal","text":"<ul> <li>Restart-safe orchestration \u2013 rerun the same command after a crash; completed stages are skipped automatically.</li> <li>Consistent artifacts \u2013 every tile produces ENVI cubes, tidy Parquet, and QA outputs named predictably.</li> <li>Built-in QA and calibration \u2013 each run emits a single-page QA panel, a multi-page QA PDF, and a JSON metrics file. Brightness adjustments between Landsat and MicaSense are applied from a versioned JSON and recorded across every QA artifact for full traceability.</li> <li>Python &amp; CLI parity \u2013 drive the pipeline from scripts or automate it in schedulers with the same arguments.</li> </ul>"},{"location":"#install-in-minutes","title":"Install in minutes","text":"<p>Choose a clean virtual environment (see the detailed Environment page for Conda tips and GDAL notes).</p> venv + PyPIFrom source <pre><code>python -m venv .venv &amp;&amp; source .venv/bin/activate\npip install -U pip\npip install cross-sensor-cal\n</code></pre> <pre><code>git clone https://github.com/earthlab/cross-sensor-cal.git\ncd cross-sensor-cal\npython -m venv .venv &amp;&amp; source .venv/bin/activate\npip install -U pip\npip install -e .[dev]\n</code></pre>"},{"location":"#understand-the-pipeline","title":"Understand the pipeline","text":"<ol> <li>Download NEON HDF5 tiles.</li> <li>Export ENVI cubes and apply topographic + BRDF correction.</li> <li>Convolve to other sensors, flatten to Parquet, and finish with QA outputs (PNG, PDF, JSON).</li> </ol> <p>See the Pipeline Stages overview for purpose, inputs, outputs, and pitfalls at every step.</p>"},{"location":"#next-steps","title":"Next steps","text":"Goal Start with Rerun the full flow on multiple tiles CLI &amp; examples Inspect Parquet outputs in notebooks Parquet preview Tune configuration for HPC or CI Reference \u2192 Configuration Validate artifacts and schemas Reference \u2192 Schemas &amp; Reference \u2192 Validation Extend to a new sensor or reader Reference \u2192 Extending Something looks off Troubleshooting"},{"location":"#quality-assurance-overview","title":"Quality Assurance Overview","text":"<p>All processed tiles automatically produce a QA panel, a multi-page QA PDF, and JSON metrics.</p> <p>\u2705 Good: reflectance within [0, 1.2], low \u0394Reflectance, high mask coverage. \u26a0\ufe0f Needs Review: 1\u20132 metrics outside thresholds. \u274c Fail: large brightness shifts, missing wavelengths, or high spectral error.</p> <p>Each QA artifact lists any Landsat\u2192MicaSense brightness coefficients that were applied so you can audit sensor harmonization settings quickly.</p> <p>Read full QA interpretation \u2192 and the JSON metrics reference.</p>"},{"location":"#release-highlights","title":"Release highlights","text":"<ul> <li>Per-flightline master table written as <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code></li> <li>QA panel <code>&lt;prefix&gt;_qa.png</code> is emitted after the merge during full runs</li> </ul>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"benchmarks/#reproducible-timing-experiment-design","title":"Reproducible timing experiment design","text":"<ul> <li>Pin package versions and record hardware specifications.</li> <li>Use fixed random seeds and keep the system load constant.</li> <li>Run each benchmark multiple times, reporting mean and variance.</li> <li>Save the exact command line and configuration for future runs.</li> </ul>"},{"location":"benchmarks/#ray-cluster-knobs","title":"Ray cluster knobs","text":"<p>When scaling benchmarks on Ray, adjust:</p> <ul> <li><code>--num-cpus</code> and <code>--num-gpus</code> to control available resources.</li> <li><code>--object-store-memory</code> for large in-memory datasets.</li> <li><code>--temp-dir</code> to point to fast local storage.</li> <li><code>--dashboard-port</code> to monitor cluster status.</li> </ul>"},{"location":"benchmarks/#io-bottleneck-tips","title":"I/O bottleneck tips","text":"<ul> <li>Chunk rasters along the row and column dimensions so each worker reads contiguous blocks.</li> <li>Enable compression such as LZW or DEFLATE to reduce disk usage and transfer time.</li> <li>Cache intermediate products or use memory-mapped files to avoid repeated reads.</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The pipeline is configured through a <code>config.yaml</code> file that combines settings for every stage. Values shown below are the defaults unless marked as required.</p>"},{"location":"configuration/#schema","title":"Schema","text":"Key Type Default Required <code>base_folder</code> string <code>\"output\"</code> yes <code>download.site_code</code> string \u2014 yes <code>download.year_month</code> string (YYYYMM) \u2014 yes <code>download.flight_lines</code> list[string] \u2014 yes <code>download.product_code</code> string <code>\"DP1.30006.001\"</code> no <code>convert.export_ancillary</code> bool <code>true</code> no <code>convert.export_brdf_config</code> bool <code>true</code> no <code>topo_brdf.num_cpus</code> int <code>8</code> no <code>topo_brdf.file_type</code> string <code>\"envi\"</code> no <code>topo_brdf.corrections</code> list[string] <code>[\"topo\",\"brdf\"]</code> no <code>topo_brdf.bad_bands</code> list[int] <code>[]</code> no <code>topo_brdf.anc_files</code> map[string,str] \u2014 conditional\u2020 <code>topo_brdf.export.output_dir</code> string <code>\"./\"</code> no <code>topo_brdf.export.suffix</code> string <code>\"_corrected_envi\"</code> no <code>topo_brdf.export.image</code> bool <code>true</code> no <code>topo_brdf.export.masks</code> bool <code>true</code> no <code>topo_brdf.export.coeffs</code> bool <code>true</code> no <code>resample.method</code> string <code>\"convolution\"</code> no <code>resample.sensors</code> list[string] <code>[\"Landsat_8\"]</code> no <code>mask.polygon_layer</code> string \u2014 no <code>mask.raster_crs_override</code> string|int \u2014 no <code>mask.polygons_crs_override</code> string|int \u2014 no <code>mask.plot_output</code> bool <code>false</code> no <code>sort.remote_prefix</code> string <code>\"\"</code> no <code>sort.sync_files</code> bool <code>true</code> no <code>postprocess.reflectance_offset</code> int <code>0</code> no <p>\u2020 required when <code>topo_brdf.file_type</code> is <code>\"envi\"</code>.</p>"},{"location":"configuration/#example","title":"Example","text":"<pre><code>base_folder: output\n\ndownload:\n  site_code: NIWO\n  year_month: \"202008\"\n  flight_lines: [\"FL1\", \"FL2\"]\n  product_code: DP1.30006.001\n\nconvert:\n  export_ancillary: true\n  export_brdf_config: true\n\ntopo_brdf:\n  num_cpus: 8\n  file_type: envi\n  corrections: [\"topo\", \"brdf\"]\n  bad_bands: []\n  anc_files: {}\n  export:\n    output_dir: ./corrected\n    suffix: _corrected_envi\n    image: true\n    masks: true\n    coeffs: true\n\nresample:\n  method: convolution\n  sensors: [\"Landsat_8\"]\n\nmask:\n  polygon_layer: polygons.geojson\n  plot_output: false\n\nsort:\n  remote_prefix: \"\"\n  sync_files: true\n\npostprocess:\n  reflectance_offset: 0\n</code></pre>"},{"location":"configuration/#cli-overrides","title":"CLI overrides","text":"<p>The <code>cscal-pipeline</code> entry point automatically runs the download stage before spinning up per-flightline workers. Use <code>--max-workers</code> to opt into parallel processing once the <code>.h5</code> files are present. Command-line options override the corresponding entries in <code>config.yaml</code>:</p> <ul> <li><code>bin/jefe.py BASE_FOLDER SITE YEAR_MONTH FL1,FL2</code> sets <code>base_folder</code>, <code>download.site_code</code>, <code>download.year_month</code> and <code>download.flight_lines</code>.</li> <li><code>--polygon_layer_path</code> \u2192 <code>mask.polygon_layer</code></li> <li><code>--reflectance-offset</code> \u2192 <code>postprocess.reflectance_offset</code></li> <li><code>--remote-prefix</code> \u2192 <code>sort.remote_prefix</code></li> <li><code>--no-sync</code> sets <code>sort.sync_files</code> to <code>false</code></li> <li><code>--max-workers</code> sets the ThreadPool concurrency for <code>go_forth_and_multiply()</code></li> </ul>"},{"location":"cyverse-irods/","title":"CyVerse iRODS","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>CyVerse storage is accessed through iRODS paths handled by the <code>gocmd</code> utility. Remote locations are written with an <code>i:</code> prefix followed by the iRODS zone, for example <code>i:/iplant/home/your_username</code>.</p> <p>To authenticate, run <code>./gocmd init</code> once. The command records your credentials in <code>~/.irods</code> so future operations can reach the data store without re-entering them.</p> <p>Common operations:</p> <pre><code># list a collection\n./gocmd ls i:/iplant/home/your_username\n\n# download a file\n./gocmd get i:/iplant/home/your_username/data.txt\n\n# upload a file to a collection\n./gocmd put local_file.txt i:/iplant/home/your_username/\n</code></pre> <p>Scripts build remote paths using variables patterned as:</p> <pre><code>remote_path = f\"i:/iplant/{remote_prefix}/{dest_path}\"\n</code></pre> <p>Replace <code>remote_prefix</code> and <code>dest_path</code> with the appropriate subdirectory and filename for your project.</p>"},{"location":"dev-notes/","title":"Developer Notes","text":"<p>Use the following commands to work on the documentation locally:</p> <ol> <li>Install dependencies:    <pre><code>pip install -r docs/requirements.txt\n# or\nuv pip install -r docs/requirements.txt\n</code></pre></li> <li>Start a live preview:    <pre><code>mkdocs serve\n</code></pre></li> <li>Build the static site:    <pre><code>mkdocs build\n</code></pre></li> </ol>"},{"location":"documentation-overview/","title":"Documentation","text":""},{"location":"documentation-overview/#overview","title":"Overview","text":"<p>This directory hosts project documentation, including the style guide that defines how you should write and maintain docs across the repository.</p>"},{"location":"documentation-overview/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Markdown viewer or editor</li> <li>Familiarity with basic Git workflows</li> </ul>"},{"location":"documentation-overview/#step-by-step-tutorial","title":"Step-by-step tutorial","text":"<ol> <li>Review the documentation style guide to    understand structure and formatting conventions.</li> <li>Create or update documentation in other folders using the guide's narrative    approach and examples.</li> <li>After editing, run <code>pytest</code> at the repository root to ensure code snippets    still execute.</li> </ol>"},{"location":"documentation-overview/#reference","title":"Reference","text":"<ul> <li><code>documentation_style_guide.md</code> \u2013 canonical guide for all project docs</li> </ul>"},{"location":"documentation-overview/#next-steps","title":"Next steps","text":"<p>Expand this folder with API references, architecture diagrams, or tutorials as the project evolves.</p>"},{"location":"documentation_style_guide/","title":"Cross-Sensor Calibration Documentation Style Guide","text":"<p>This guide establishes conventions for writing documentation in the Cross-Sensor Calibration project. Its goal is to create a linear, pedagogical narrative that makes the package easy to understand and adopt.</p>"},{"location":"documentation_style_guide/#philosophy","title":"Philosophy","text":"<ul> <li>Clarity first. Explain concepts in plain language before introducing technical jargon.</li> <li>Narrative flow. Documentation should guide the reader from inputs through processing to outputs in a logical order.</li> <li>Pragmatic examples. Every section should include code snippets or workflows that users can run directly.</li> <li>Minimal prerequisites. Link to background materials rather than assuming extensive prior knowledge.</li> </ul>"},{"location":"documentation_style_guide/#structure","title":"Structure","text":"<ol> <li>Overview \u2013 Briefly describe the purpose of the component and how it fits into the larger workflow.</li> <li>Prerequisites \u2013 List required data, dependencies, and setup steps.</li> <li>Step-by-step tutorial \u2013 Present instructions in chronological order.</li> <li>Reference \u2013 Provide detailed API descriptions, parameters, and links to source code.</li> <li>Next steps \u2013 Suggest follow-on tasks or sections.</li> </ol>"},{"location":"documentation_style_guide/#style","title":"Style","text":"<ul> <li>Use Markdown headings (<code>#</code>, <code>##</code>, <code>###</code>) to organize content.</li> <li>Write in the second person (\u201cyou\u201d) and active voice.</li> <li>Keep sentences concise; aim for one idea per sentence.</li> <li>Use numbered lists for sequences and bullet lists for options.</li> <li>Highlight file names, parameters, and code using backticks (<code>like_this</code>).</li> <li>Wrap code examples in fenced blocks with the appropriate language tag.</li> <li>Include diagrams or figures when they clarify complex processes.</li> <li>Cross-link related documents with relative paths.</li> </ul>"},{"location":"documentation_style_guide/#formatting","title":"Formatting","text":"<ul> <li>Line length: soft wrap at 100 characters.</li> <li>Use American English spelling.</li> <li>Date format: YYYY-MM-DD.</li> <li>Reference issues or pull requests with full links.</li> </ul>"},{"location":"documentation_style_guide/#maintenance","title":"Maintenance","text":"<ul> <li>Each documentation page must include a <code>Last updated: YYYY-MM-DD</code> line at the end.</li> <li>When updating docs, ensure examples are tested against the current codebase.</li> <li>Run <code>pytest</code> before committing changes that affect code examples.</li> </ul> <p>Following this guide will keep the documentation consistent and approachable for new contributors and users.</p>"},{"location":"env-setup/","title":"Environment Setup","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"env-setup/#conda-environment","title":"Conda environment","text":"<p>An example environment file for Conda is shown below. Save it as <code>environment.yaml</code> and create the environment with <code>conda env create -f environment.yaml</code>.</p> <pre><code>name: cross-sensor-cal\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.10\n  - gdal\n  - proj\n  - pip\n  - pip:\n      - ray[default]\n</code></pre>"},{"location":"env-setup/#uv-pip-alternative","title":"uv / pip alternative","text":"<p>Instead of Conda you can install the project with <code>uv</code> or plain <code>pip</code>:</p> <pre><code>uv pip install -r requirements.txt\n# or\npip install -r requirements.txt\n</code></pre>"},{"location":"env-setup/#gdal-proj-and-ray-notes","title":"GDAL, PROJ, and Ray notes","text":"<ul> <li>GDAL and PROJ require native libraries. Installing via the   <code>conda-forge</code> channel usually resolves most platform issues.</li> <li>Ray makes heavy use of shared memory. If Ray reports <code>/dev/shm</code> errors,   increase shared memory. For Docker containers use   <code>--shm-size=8g</code> (adjust as needed).</li> </ul>"},{"location":"env-setup/#known-os-quirks","title":"Known OS quirks","text":"<ul> <li>macOS: Homebrew installations of GDAL/PROJ may conflict with Conda.   Prefer the Conda packages or ensure <code>brew</code> paths come after Conda in <code>PATH</code>.</li> <li>Windows: enable long paths (<code>git config --system core.longpaths true</code>) to   avoid checkout errors.</li> </ul>"},{"location":"env-setup/#preview-documentation-locally","title":"Preview documentation locally","text":"<p>Run the MkDocs development server from the repository root:</p> <pre><code>mkdocs serve\n</code></pre> <p>Open http://127.0.0.1:8000 in a browser to view the docs.</p>"},{"location":"env/","title":"Environment","text":"Component Known-good Python 3.10\u20133.12 OS macOS 13+, Ubuntu 22.04+ Core libs numpy, rasterio, gdal, ray, xarray, pandas"},{"location":"env/#setup-venv","title":"Setup (venv)","text":"<pre><code>python -m venv .venv &amp;&amp; source .venv/bin/activate\npip install -U pip\npip install cross-sensor-cal\n</code></pre>"},{"location":"env/#setup-conda","title":"Setup (conda)","text":"<pre><code>conda create -n cscal python=3.11 -y\nconda activate cscal\npip install -U pip\npip install cross-sensor-cal\n</code></pre>"},{"location":"extending/","title":"Extending","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"extending/#add-a-sensor","title":"Add a sensor","text":""},{"location":"extending/#overview","title":"Overview","text":"<p>This recipe shows how to integrate a new sensor into the cross\u2011sensor calibration workflow.</p>"},{"location":"extending/#prerequisites","title":"Prerequisites","text":"<ul> <li>Spectral response function (SRF) curves for the sensor.</li> <li>Familiarity with the project's naming conventions.</li> </ul>"},{"location":"extending/#step-by-step-tutorial","title":"Step-by-step tutorial","text":"<ol> <li>Add SRFs. Place the sensor's SRF files in the data directory and register    them with the SRF loader.</li> <li>Update resampling/convolution mapping. Extend the resampling and    convolution dictionaries so the pipeline knows how to transform the sensor's    bands.</li> <li>Update the naming map. Insert the sensor's canonical name and band    identifiers into the shared naming map used across modules.</li> <li>Add a golden test and validation checklist.</li> <li>Create a golden test case with expected outputs.</li> <li>Document validation steps to confirm the sensor behaves correctly.</li> </ol>"},{"location":"extending/#next-steps","title":"Next steps","text":"<p>Run the full validation suite and submit a pull request for review.</p> <p>Last updated: 2025-08-18</p>"},{"location":"faq/","title":"FAQ","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"faq/#which-crs-should-i-use","title":"Which CRS should I use?","text":"<p>Use a projected CRS (e.g., UTM) consistent across inputs; the workflow reprojects mismatched scenes.</p>"},{"location":"faq/#how-are-missing-ancillary-inputs-handled","title":"How are missing ancillary inputs handled?","text":"<p>Stages log the omission and skip affected products; the run continues with available data.</p>"},{"location":"faq/#can-i-resume-a-partially-completed-run","title":"Can I resume a partially completed run?","text":"<p>Yes. Rerun the same stage and existing outputs are detected and skipped.</p>"},{"location":"faq/#how-do-i-add-support-for-a-new-sensor","title":"How do I add support for a new sensor?","text":"<p>Create a sensor definition with its band metadata and register it in the configuration file.</p>"},{"location":"faq/#why-dont-mesma-fractional-totals-sum-to-1","title":"Why don't MESMA fractional totals sum to 1?","text":"<p>Residual fractions capture unmodeled materials and numerical error, so sums may differ from one.</p>"},{"location":"faq/#where-can-i-find-logs-and-manifests","title":"Where can I find logs and manifests?","text":"<p>Each run writes to <code>logs/</code> and <code>manifests/</code> directories inside the output folder.</p>"},{"location":"faq/#do-i-have-to-run-every-processing-stage","title":"Do I have to run every processing stage?","text":"<p>No. You can run individual stages; each reads from the previous stage's outputs.</p>"},{"location":"faq/#how-do-i-change-the-working-directories","title":"How do I change the working directories?","text":"<p>Set <code>work_dir</code> and <code>output_dir</code> in the configuration to point to desired locations.</p>"},{"location":"faq/#how-should-i-cite-this-project","title":"How should I cite this project?","text":"<p>Reference the <code>CITATION.cff</code> file or the DOI listed in the repository.</p>"},{"location":"faq/#are-intermediate-files-cleaned-up-automatically","title":"Are intermediate files cleaned up automatically?","text":"<p>Temporary products remain unless you enable the cleanup option in the configuration.</p> <p>Last updated: 2025-08-18</p>"},{"location":"glossary/","title":"Glossary","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <ul> <li>AOP: Apparent Optical Property describing how a medium's optical characteristics vary with viewing geometry.</li> <li>BRDF: Bidirectional Reflectance Distribution Function giving reflectance as a function of illumination and view angles.</li> <li>SRF: Spectral Response Function representing a sensor's sensitivity across wavelengths.</li> <li>SNR: Signal-to-Noise Ratio, the level of desired signal relative to background noise.</li> <li>ENVI: Environment for Visualizing Images, a software package for processing geospatial imagery.</li> <li>MESMA: Multiple Endmember Spectral Mixture Analysis, an unmixing algorithm using variable endmember sets.</li> <li>DN: Digital Number, the raw quantized value recorded by a sensor.</li> <li>TOA: Top of Atmosphere reflectance measured above the atmosphere.</li> <li>BOA: Bottom of Atmosphere or surface reflectance after atmospheric correction.</li> <li>NIR: Near Infrared region of the electromagnetic spectrum, roughly 0.7\u20131.3 \u00b5m.</li> <li>SWIR: Shortwave Infrared region spanning approximately 1.3\u20132.5 \u00b5m.</li> <li>VIS: Visible portion of the electromagnetic spectrum between about 0.4\u20130.7 \u00b5m.</li> <li>FLAASH: Fast Line-of-sight Atmospheric Analysis of Spectral Hypercubes, an atmospheric correction tool.</li> <li>LiDAR: Light Detection and Ranging, active remote sensing using laser pulses to measure distance.</li> <li>UAV: Uncrewed Aerial Vehicle used as a platform for acquiring high-resolution imagery.</li> <li>NDVI: Normalized Difference Vegetation Index calculated from NIR and red bands to indicate vegetation vigor.</li> <li>MODIS: Moderate Resolution Imaging Spectroradiometer, a multispectral sensor on NASA's Terra and Aqua satellites.</li> <li>GSD: Ground Sample Distance, the ground size represented by one image pixel.</li> <li>RSR: Relative Spectral Response, the normalized sensitivity of a detector as a function of wavelength.</li> <li>AVIRIS: Airborne Visible/Infrared Imaging Spectrometer, a NASA hyperspectral imaging instrument.</li> </ul>"},{"location":"naming-conventions/","title":"Naming Conventions","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"naming-conventions/#canonical-filename-pattern","title":"Canonical Filename Pattern","text":"<p>All files produced by the pipeline use a common token order:</p> <pre><code>NEON_{site}_{YYYYMMDD}_{HHMMSS}_FL{line}_{product}{suffix}.ext\n</code></pre> <ul> <li><code>site</code> \u2013 NEON site code (e.g., <code>SJER</code>)</li> <li><code>YYYYMMDD</code> and <code>HHMMSS</code> \u2013 acquisition date and time in UTC</li> <li><code>FL{line}</code> \u2013 zero\u2011padded flight line identifier</li> <li><code>product</code> \u2013 base product name (e.g., <code>NIS</code>)</li> <li><code>suffix</code> \u2013 processing state (see table below)</li> <li><code>ext</code> \u2013 file extension such as <code>.img</code> or <code>.hdr</code></li> </ul> <p>Regex</p> <pre><code>^NEON_[A-Z0-9]{4}_\\d{8}_\\d{6}_FL\\d{3}_[A-Za-z0-9]+(?:_radiance|_ancillary|_corrected_envi|_reflectance)\\.(?:img|hdr)$\n</code></pre>"},{"location":"naming-conventions/#standard-suffixes","title":"Standard Suffixes","text":"Suffix Meaning <code>_radiance</code> Raw radiance from HDF5 conversion <code>_ancillary</code> Ancillary data produced with radiance <code>_corrected_envi</code> BRDF/TOPO corrected ENVI image <code>_reflectance</code> Final reflectance product"},{"location":"naming-conventions/#directory-layout","title":"Directory Layout","text":"<pre><code>site/\n\u2514\u2500\u2500 YYYYMMDD/\n    \u2514\u2500\u2500 FL###/\n        \u251c\u2500\u2500 raw/\n        \u2502   \u251c\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_radiance.img\n        \u2502   \u2514\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_ancillary.img\n        \u2514\u2500\u2500 derived/\n            \u251c\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_corrected_envi.img\n            \u2514\u2500\u2500 NEON_SITE_YYYYMMDD_HHMMSS_FL###_NIS_corrected_envi.hdr\n</code></pre>"},{"location":"naming-conventions/#common-violations-fixes","title":"Common Violations &amp; Fixes","text":"Violation Why it matters Fix Missing flight line token Downstream scripts cannot group files Include <code>_FL###</code> before the suffix Wrong suffix for directory (e.g., <code>_radiance</code> in <code>derived/</code>) Causes processing confusion Move file to <code>raw/</code> or rename with proper suffix Lower\u2011case site code Breaks regex patterns Use upper\u2011case site codes Spaces instead of underscores Parsing fails Replace spaces with <code>_</code>"},{"location":"overview/","title":"Overview","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The Cross\u2011Sensor Calibration workflow runs every NEON flight line through an idempotent, restart-safe series of five stages. Each stage emits tqdm-style progress bars, prefixes logs with <code>[flight_stem]</code>, and writes artifacts using canonical paths from :func:<code>cross_sensor_cal.utils.naming.get_flight_paths</code>.</p> <pre><code>flowchart LR\n    D[Download .h5]\n    E[Export ENVI]\n    J[Build BRDF+topo JSON]\n    C[Correct reflectance]\n    R[Resample + Parquet]\n    D --&gt; E --&gt; J --&gt; C --&gt; R\n</code></pre> <ul> <li>Download: <code>stage_download_h5()</code> restores automatic retrieval of NEON   directional reflectance cubes and leaves each <code>.h5</code> in the workspace root for   easy cleanup.</li> <li>ENVI export: Converts the HDF5 cube to   <code>&lt;base&gt;/&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.img/.hdr/.parquet</code> with per-tile   progress updates.</li> <li>BRDF + topo JSON: Computes correction parameters once per flight line and   records them in <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code> inside the   dedicated subdirectory.</li> <li>BRDF + topo correction: Streams a chunk progress bar while writing the   canonical corrected cube (<code>*_brdfandtopo_corrected_envi.img/.hdr/.parquet</code>).</li> <li>Sensor resample + Parquet: Produces per-sensor ENVI pairs and matching   Parquet summaries in the same subfolder, leaving the raw <code>.h5</code> untouched.</li> </ul> <p>Every derived artifact now lives under <code>&lt;base&gt;/&lt;flight_stem&gt;/</code>, keeping the workspace organized and allowing long-term retention of processed products without stockpiling multi-gigabyte <code>.h5</code> inputs. <code>_scoped_log_prefix()</code> keeps parallel runs legible while <code>max_workers</code> lets you opt into ThreadPool-powered concurrency once downloads finish.</p>"},{"location":"overview/#who-is-this-for","title":"Who is this for?","text":"<p>Researchers processing NEON AOP flight lines who need reproducible ENVI deliverables, per-sensor band stacks, and Parquet summaries for cross-sensor analysis. All scientific calculations remain unchanged from previous releases\u2014 the 2025 refresh focuses on workflow, performance, and restart safety.</p>"},{"location":"pipeline/","title":"Pipeline reference","text":"<p>Cross-Sensor Calibration orchestrates the same five ordered stages for every flight line. Each stage consults <code>get_flight_paths()</code> to locate its inputs, per-flightline working directory, and outputs, validates artifacts before working, and emits emoji-rich logs that make the restart-safe behavior explicit. All persistent products land inside <code>&lt;base_folder&gt;/&lt;flight_stem&gt;/</code> (with the raw <code>.h5</code> kept at the base root) and include ENVI (<code>.img/.hdr</code>), JSON metadata, and Parquet summaries.</p>"},{"location":"pipeline/#canonical-paths-via-get_flight_paths","title":"Canonical paths via <code>get_flight_paths()</code>","text":"<p><code>get_flight_paths(base_folder, flight_stem)</code> is the authoritative source of truth for every artifact the pipeline reads or writes. For a flight line with stem <code>&lt;flight_stem&gt;</code> it yields:</p> <ul> <li><code>h5_path</code> \u2192 <code>&lt;base_folder&gt;/&lt;flight_stem&gt;.h5</code></li> <li><code>work_dir</code> \u2192 <code>&lt;base_folder&gt;/&lt;flight_stem&gt;/</code></li> <li><code>raw_envi_img</code> / <code>raw_envi_hdr</code> \u2192 <code>&lt;flight_stem&gt;_envi.img</code> and   <code>&lt;flight_stem&gt;_envi.hdr</code> inside <code>work_dir</code></li> <li><code>correction_json</code> \u2192 <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code> in   <code>work_dir</code></li> <li><code>corrected_img</code> / <code>corrected_hdr</code> \u2192   <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.img</code> and   <code>&lt;flight_stem&gt;_brdfandtopo_corrected_envi.hdr</code></li> <li><code>sensor_products</code> \u2192 a dict mapping each sensor (e.g. <code>landsat_tm</code>,   <code>landsat_etm+</code>, <code>landsat_oli</code>, <code>landsat_oli2</code>, <code>micasense</code>) to   <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.img</code> /   <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.hdr</code></li> <li><code>parquet_products</code> \u2192 optional Parquet summaries colocated with their source   rasters</li> </ul> <p>All stages request their expected paths from this function and refuse to invent filenames on the fly. If naming ever changes, update <code>get_flight_paths()</code> once rather than editing every stage.</p>"},{"location":"pipeline/#stage-by-stage-details","title":"Stage-by-stage details","text":"<p>Every stage is restart-safe: it skips itself when valid outputs already exist. Validation requires both sides of an ENVI pair to exist and be non-empty or, for JSON, the file must parse successfully. When a stage skips, it logs a <code>\u2705 ... (skipping)</code> message; otherwise it performs work and logs what it produced. Live tqdm progress bars accompany downloads, ENVI chunk exports, and BRDF+topo corrections.</p>"},{"location":"pipeline/#0-download-neon-hdf5","title":"0. Download NEON HDF5","text":"<ul> <li>Inputs</li> <li>NEON site code, product code, and flight stem.</li> <li>Outputs</li> <li><code>&lt;base_folder&gt;/&lt;flight_stem&gt;.h5</code> (left in the workspace root).</li> <li>Skip criteria</li> <li>Existing <code>.h5</code> file that passes a size/metadata sanity check.</li> <li>Logging</li> <li>Logs <code>\ud83d\udce5 stage_download_h5()</code> with a streaming byte counter while downloading.</li> <li>On skip emits <code>\u2705 stage_download_h5() found existing .h5 (skipping)</code>.</li> <li>Failure handling</li> <li>Raises on HTTP errors or truncated downloads; reruns resume by revalidating the file.</li> </ul>"},{"location":"pipeline/#1-envi-export","title":"1. ENVI export","text":"<ul> <li>Inputs</li> <li>NEON directional reflectance cube (<code>&lt;flight_stem&gt;.h5</code>).</li> <li>Outputs</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.img</code></li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.hdr</code></li> <li>Extras</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_envi.parquet</code> (summary statistics per tile).</li> <li>Skip criteria</li> <li>Both ENVI files exist, are non-empty, and pass the internal ENVI validation.</li> <li>Logging</li> <li>Always logs <code>\ud83d\udd0e ENVI export target for &lt;flight_stem&gt; is ..._envi.img / ..._envi.hdr</code> with a chunked progress bar.</li> <li>On skip emits     <code>\u2705 ENVI export already complete for &lt;flight_stem&gt; -&gt; ..._envi.img / ..._envi.hdr (skipping heavy export)</code>.</li> <li>Otherwise streams progress as tiles are written and logs success.</li> <li>Failure handling</li> <li>Errors here stop the stage; reruns regenerate if outputs were missing or invalid.</li> </ul>"},{"location":"pipeline/#2-build-correction-json","title":"2. Build correction JSON","text":"<ul> <li>Inputs</li> <li>Uncorrected ENVI pair from stage 1.</li> <li>Output</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.json</code></li> <li>Skip criteria</li> <li>JSON exists and parses.</li> <li>Logging</li> <li>On skip logs     <code>\u2705 Correction JSON already complete for &lt;flight_stem&gt; -&gt; ..._brdfandtopo_corrected_envi.json (skipping)</code>.</li> <li>Otherwise logs that it is computing parameters and then writing the JSON.</li> <li>Failure handling</li> <li>Failures propagate so that reruns recompute the JSON before downstream stages continue.</li> </ul>"},{"location":"pipeline/#3-brdf-topographic-correction","title":"3. BRDF + topographic correction","text":"<ul> <li>Inputs</li> <li>Uncorrected ENVI pair.</li> <li>Correction JSON from stage 2.</li> <li>Outputs</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.img</code></li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.hdr</code></li> <li>Extras</li> <li><code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_brdfandtopo_corrected_envi.parquet</code></li> <li>Skip criteria</li> <li>Corrected ENVI pair exists, is non-empty, and validates.</li> <li>Logging</li> <li>On skip logs     <code>\u2705 BRDF+topo correction already complete for &lt;flight_stem&gt; -&gt; ..._brdfandtopo_corrected_envi.img / ..._brdfandtopo_corrected_envi.hdr (skipping)</code>.</li> <li>When recomputing, streams a chunk progress bar while writing and logs completion.</li> <li>Failure handling</li> <li>Failures raise immediately because the corrected cube is the canonical science product.     Reruns recompute just this stage if its outputs were missing or corrupt.</li> </ul>"},{"location":"pipeline/#4-sensor-convolution-resampling","title":"4. Sensor convolution / resampling","text":"<ul> <li>Inputs</li> <li>Corrected ENVI pair from stage 3. This stage never reads the raw <code>.h5</code>.</li> <li>Sensor spectral response library bundled with the project.</li> <li>Outputs</li> <li>For each known sensor, an ENVI pair following     <code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.img</code> /     <code>&lt;flight_stem&gt;/&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.hdr</code> (e.g.     <code>.../NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance_landsat_tm_envi.img</code>).</li> <li>Extras</li> <li>Optional Parquet tables named <code>&lt;flight_stem&gt;_&lt;sensor_name&gt;_envi.parquet</code> in     the same folder.</li> <li>Skip criteria</li> <li>Individual sensor ENVI pairs that already exist and validate are skipped and reported.</li> <li>Logging</li> <li>Begins with <code>\ud83c\udfaf Convolving corrected reflectance for &lt;flight_stem&gt;</code>.</li> <li>On fresh generation logs     <code>\u2705 Wrote &lt;sensor_name&gt; product for &lt;flight_stem&gt; -&gt; ..._envi.img / ..._envi.hdr</code>.</li> <li>On skip logs     <code>\u2705 &lt;sensor_name&gt; product already complete for &lt;flight_stem&gt; -&gt; ... (skipping)</code>.</li> <li>Ends with     <code>\ud83d\udcca Sensor convolution summary for &lt;flight_stem&gt; | succeeded=[...] skipped=[...] failed=[...]</code>     followed by <code>\ud83c\udf89 Finished pipeline for &lt;flight_stem&gt;</code>.</li> <li>Failure handling</li> <li>Sensors are processed independently. Missing definitions or write failures mark that     sensor as <code>failed</code> but do not abort the stage unless all sensors fail and none were     previously valid. Partial success is acceptable.</li> </ul>"},{"location":"pipeline/#example-run-transcript","title":"Example run transcript","text":"<p>The restart-safe logs surface the exact work performed. A real rerun for one flight line now looks like:</p> <pre><code>[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\ude80 Processing ...\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udce5 stage_download_h5() found existing .h5 (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udd0e ENVI export target is ..._envi.img / ..._envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 ENVI export already complete -&gt; ..._envi.img / ..._envi.hdr (skipping heavy export)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Correction JSON already complete -&gt; ..._brdfandtopo_corrected_envi.json (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 BRDF+topo correction already complete -&gt; ..._brdfandtopo_corrected_envi.img / ..._brdfandtopo_corrected_envi.hdr (skipping)\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83c\udfaf Convolving corrected reflectance\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Wrote landsat_tm product -&gt; ..._landsat_tm_envi.img / ..._landsat_tm_envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \u2705 Wrote micasense product -&gt; ..._micasense_envi.img / ..._micasense_envi.hdr\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83d\udcca Sensor convolution summary | succeeded=['landsat_tm', 'micasense'] skipped=['landsat_etm+', 'landsat_oli', 'landsat_oli2'] failed=[]\n[NEON_D13_NIWO_DP1_L019-1_20230815_directional_reflectance] \ud83c\udf89 Finished pipeline\n</code></pre>"},{"location":"pipeline/#parallel-flightline-execution","title":"Parallel flightline execution","text":"<p>After all downloads succeed, <code>go_forth_and_multiply()</code> dispatches each flightline to a <code>ThreadPoolExecutor</code>. The <code>max_workers</code> argument controls the level of concurrency; leave it <code>None</code> to process sequentially. <code>_scoped_log_prefix()</code> prepends <code>[flight_stem]</code> to every log so parallel runs stay readable, and each worker writes only within its own <code>&lt;base&gt;/&lt;flight_stem&gt;/</code> directory to preserve idempotence.</p> <p>When <code>go_forth_and_multiply(...)</code> finishes looping over every requested flight line it logs <code>\u2705 All requested flightlines processed.</code> to confirm site-level completion.</p>"},{"location":"pipeline/#rerun-guidance","title":"Rerun guidance","text":"<p>Call <code>go_forth_and_multiply(...)</code> with the same parameters to rerun an entire site-month. The restart-safe checks ensure that valid artifacts are reused, missing or invalid stages are recomputed, and partial sensor failures do not stop progress across the rest of the flight lines. Because each sensor is accounted for independently, you can inspect the summary lists to see exactly which products succeeded, which were reused, and which need attention.</p>"},{"location":"qa/","title":"Quality Assurance (QA) panels","text":"<p>The <code>cscal-qa</code> command now emits both a PNG panel and a machine-readable <code>*_qa.json</code> file for every flightline. The PNG highlights spectral checks while the JSON records the underlying metrics so you can track drift over time or feed it into dashboards.</p> <pre><code># Deterministic quick pass (\u226425k sampled pixels per flightline)\ncscal-qa --base-folder output_demo --quick\n\n# Exhaustive sampling with custom RGB mapping\ncscal-qa --base-folder output_demo --full --n-sample 150000 --rgb-bands 650,550,480\n</code></pre> <p>Key sections on the panel:</p> <ul> <li>RGB quicklook \u2013 automatically picks 660/560/490 nm (override with   <code>--rgb-bands</code>). Red callouts overlay any flagged issues from the metrics.</li> <li>Histograms \u2013 pre vs post correction distributions with shared bins so you   can judge how BRDF/topo shifts the scene.</li> <li>\u0394 median vs wavelength \u2013 bandwise medians with IQR ribbon; uses header   wavelengths or sensor defaults.</li> <li>Convolved scatter \u2013 compares corrected data to any <code>*_convolved_envi</code>   or <code>*_resampled_&lt;sensor&gt;_envi</code> outputs with a 1:1 reference line.</li> </ul> <p>Each PNG lives alongside <code>&lt;prefix&gt;_qa.json</code>, which mirrors the <code>QAMetrics</code> dataclass (<code>provenance</code>, <code>header</code>, <code>mask</code>, <code>correction</code>, <code>convolution</code>, <code>negatives_pct</code>, <code>overbright_pct</code>, <code>issues</code>). When the brightness correction stage runs, the JSON also lists per-band gain/offsets so the QA team can trace changes back to illumination harmonisation.</p> <p>Use <code>--out-dir</code> if you want to collect all PNG/JSON pairs into a single folder for review. Re-running the command overwrites previous outputs, so a second pass after fixing headers or rerunning corrections always reflects the current state.</p>"},{"location":"qa/#qa-dashboard","title":"QA Dashboard","text":"<p>The legacy <code>cscal-qa-dashboard</code> command still expects <code>_qa_metrics.parquet</code> files. Until the dashboard is updated to read the new JSON schema, keep legacy parquet artifacts if you rely on that summary view.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>Choose your path:</p> CLI onlyPython controlHPC / many tiles <pre><code>cscal-pipeline \\\n  --base-folder output_demo \\\n  --site-code NIWO \\\n  --year-month 2023-08 \\\n  --product-code DP1.30006.001 \\\n  --flight-lines NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance \\\n  --max-workers 2\n</code></pre> <pre><code>from cross_sensor_cal import go_forth_and_multiply\n\ngo_forth_and_multiply(\n    base_folder=\"output_demo\",\n    site_code=\"NIWO\",\n    year_month=\"2023-08\",\n    product_code=\"DP1.30006.001\",\n    flight_lines=[\"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"],\n    max_workers=2,\n)\n</code></pre> <ul> <li>Use <code>--max-workers</code> conservatively to avoid RAM pressure.</li> <li>Re-run the same command to resume; completed stages are skipped.</li> <li>If <code>/dev/shm</code> is small, limit concurrency.</li> </ul>"},{"location":"refactor_notes/","title":"Refactor Notes: HyTools-Free Pipeline","text":""},{"location":"refactor_notes/#purpose","title":"Purpose","text":"<p>These notes document the current cross-sensor-cal processing pipeline after removing the runtime dependency on HyTools. The steps below describe what the code does today so collaborators can reproduce results and audit intermediate products.</p>"},{"location":"refactor_notes/#end-to-end-pipeline","title":"End-to-End Pipeline","text":"<ol> <li> <p>Acquire NEON reflectance flightlines    Download or copy the required NEON Airborne Observation Platform (AOP) reflectance HDF5 files to a local workspace before running the pipeline.</p> </li> <li> <p>Convert HDF5 to ENVI without HyTools <code>neon_to_envi_no_hytools()</code> opens the HDF5 file with <code>NeonCube</code>, streams the cube out in spatial tiles, and writes a float32 BSQ ENVI dataset via <code>EnviWriter</code>. It simultaneously exports ancillary rasters (solar/sensor geometry, slope, aspect, etc.) needed for correction. The result is an uncorrected directional reflectance <code>.img/.hdr</code> pair for each flightline. HyTools and Ray are not invoked in this stage\u2014the conversion logic is entirely internal.</p> </li> <li> <p>Persist correction parameters <code>build_and_write_correction_json()</code> (in <code>brdf_topo.py</code>) inspects the flightline geometry, fits BRDF coefficients, and serialises the results as <code>&lt;flightline&gt;_brdfandtopo_corrected_envi.json</code>. The helper validates the JSON via <code>is_valid_json()</code> and reuses it on reruns when intact.</p> </li> <li> <p>Topographic and BRDF correction    The pipeline allocates a new corrected cube and uses <code>EnviWriter</code> to persist it. For every spatial tile it:</p> </li> <li>Reads the tile from the uncorrected ENVI export.</li> <li>Applies topographic correction using slope, aspect, and solar geometry rasters.</li> <li>Applies BRDF correction using the saved coefficient JSON. When coefficients are missing, unreadable, or poorly conditioned, the code logs a warning and falls back to neutral BRDF terms so the tile still receives topographic correction.</li> <li> <p>Optionally adds a <code>brightness_offset</code> before writing.    The corrected output <code>&lt;flightline&gt;_brdfandtopo_corrected_envi.img/.hdr</code> carries full spatial metadata plus the wavelength list, FWHM list, and wavelength units required for spectral resampling.</p> </li> <li> <p>Spectral convolution / sensor simulation <code>convolve_resample_product()</code> opens the corrected cube as a BSQ memmap, reads spatial tiles, transposes them to <code>(y, x, bands)</code>, and multiplies each tile by sensor-specific spectral response functions (SRFs). SRFs are loaded from JSON files under <code>cross_sensor_cal/data/</code> via package-relative paths. Each simulated sensor produces its own float32 BSQ ENVI product and header. Existing resampled outputs are validated with <code>is_valid_envi_pair()</code> and skipped when already complete.</p> </li> <li> <p>Downstream consumers (optional)    Additional tooling can derive pixel stacks, polygon summaries, or parquet tables from the corrected and resampled rasters. These consumers still function but are documented separately and are not detailed here.</p> </li> </ol> <p>Every step performs the same validation checks on reruns so the pipeline is safe to resume after interruptions or partial failures.</p> <ol> <li>Recommended artifact retention    Keep the following per flightline so downstream analyses and cross-sensor comparisons remain reproducible:</li> <li><code>&lt;flightline&gt;_directional_reflectance.img/.hdr</code></li> <li><code>&lt;flightline&gt;_brdfandtopo_corrected_envi.json</code></li> <li><code>&lt;flightline&gt;_brdfandtopo_corrected_envi.img/.hdr</code></li> <li><code>&lt;flightline&gt;_resampled_&lt;sensor&gt;.img/.hdr</code></li> </ol>"},{"location":"refactor_notes/#module-structure","title":"Module Structure","text":"<ul> <li><code>cross_sensor_cal/neon_cube.py</code></li> <li><code>NeonCube</code> class</li> <li>Opens NEON HDF5 reflectance, exposes dimensions, wavelengths, ancillary angles, etc.</li> <li>Iterates spatial tiles without requiring HyTools.</li> <li><code>cross_sensor_cal/envi_writer.py</code></li> <li><code>EnviWriter</code> class</li> <li>Writes BSQ float32 rasters (<code>.img/.hdr</code>).</li> <li>Used for uncorrected export, corrected cubes, and resampled products.</li> <li><code>cross_sensor_cal/corrections.py</code></li> <li><code>fit_and_save_brdf_model()</code></li> <li><code>apply_topo_correct()</code></li> <li><code>apply_brdf_correct()</code></li> <li>Includes helpers to load and apply BRDF coefficients.</li> <li><code>cross_sensor_cal/resample.py</code></li> <li><code>resample_chunk_to_sensor()</code></li> <li>SRF loading utilities</li> <li>Convolution-friendly helpers for chunk-wise processing.</li> <li><code>cross_sensor_cal/pipelines/pipeline.py</code></li> <li><code>go_forth_and_multiply()</code></li> <li>Orchestrates downloads, H5\u2192ENVI export (no HyTools), BRDF fitting, topographic+BRDF correction, and spectral convolution.</li> <li><code>cross_sensor_cal/data/</code></li> <li>SRF JSON files for Landsat, Sentinel, etc.</li> <li>Accessed via package-relative paths at runtime.</li> </ul>"},{"location":"refactor_notes/#licensing","title":"Licensing","text":"<p>Several algorithms and data-handling conventions in <code>NeonCube</code>, the correction routines, and ENVI export logic were adapted from the HyTools project (GPLv3). Although the refactored pipeline no longer imports HyTools at runtime, we continue to credit the original HyTools authors and comply with GPLv3 obligations for the adapted code.</p>"},{"location":"references/","title":"References","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"references/#cross-calibration","title":"Cross-calibration","text":"<ul> <li>Roy, D.P., Kovalskyy, V., Zhang, H., Vermote, E.F., &amp; Yan, L. (2016). Landsat-8 and Landsat-7 cross-calibration. Remote Sensing of Environment.</li> <li>Claverie, M., Ju, J., Masek, J.G., et al. (2018). The Harmonized Landsat and Sentinel-2 surface reflectance data set. Remote Sensing of Environment.</li> </ul>"},{"location":"references/#citing-this-project","title":"Citing this project","text":"<ul> <li>Earth Lab Data Innovation Team. (2025). Cross-Sensor Calibration (Version 2.2.0) [Software]. University of Colorado Boulder. https://github.com/earthlab/cross-sensor-cal</li> </ul>"},{"location":"references/#spectral-libraries","title":"Spectral libraries","text":"<ul> <li>Baldridge, A.M., Hook, S.J., Grove, C.I., &amp; Rivera, G. (2009). The ASTER spectral library version 2.0. Remote Sensing of Environment.</li> <li>Kokaly, R.F., Clark, R.N., et al. (2017). USGS Spectral Library Version 7. U.S. Geological Survey Data Series.</li> </ul>"},{"location":"references/#mesma","title":"MESMA","text":"<ul> <li>Roberts, D.A., Gardner, M., Church, R., Ustin, S., Scheer, G., &amp; Green, R.O. (1998). Mapping chaparral in the Santa Monica Mountains using multiple endmember spectral mixture models. Remote Sensing of Environment.</li> <li>Powell, R.L., Roberts, D.A., Dennison, P.E., &amp; Hess, L.L. (2007). Sub-pixel mapping of urban land cover using MESMA. Remote Sensing of Environment.</li> </ul>"},{"location":"references/#brdftopo","title":"BRDF/topo","text":"<ul> <li>Li, X., &amp; Strahler, A.H. (1992). Geometric-optical bidirectional reflectance modeling of the discrete crown vegetation canopy. IEEE Transactions on Geoscience and Remote Sensing.</li> <li>Schaaf, C.B., Gao, F., et al. (2002). First operational BRDF, albedo, and nadir reflectance products from MODIS. Remote Sensing of Environment.</li> <li>Colby, J.D. (1991). Topographic normalization in remote sensing. Remote Sensing of Environment.</li> </ul>"},{"location":"schemas/","title":"Schemas","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"schemas/#raster-band-metadata-schema","title":"Raster band metadata schema","text":"<p>Describes the properties of each raster band after resampling or convolution.</p> Field Type Units Description <code>band</code> int \u2013 Sequential band number <code>wavelength_nm</code> float nm Center wavelength <code>fwhm_nm</code> float nm Full width at half maximum <code>unit</code> string \u2013 Measurement units for reflectance <p>Example JSON:</p> <pre><code>[\n  {\"band\": 1, \"wavelength_nm\": 450.0, \"fwhm_nm\": 20.0, \"unit\": \"nm\"},\n  {\"band\": 2, \"wavelength_nm\": 550.0, \"fwhm_nm\": 25.0, \"unit\": \"nm\"}\n]\n</code></pre>"},{"location":"schemas/#pixel-table-schema","title":"Pixel table schema","text":"<p>Each row represents one pixel extracted from a raster scene.</p> Column Type Units Description <code>Pixel_ID</code> int \u2013 Unique pixel identifier <code>Pixel_Row</code> int row Raster row index (0\u2011based) <code>Pixel_Col</code> int col Raster column index (0\u2011based) <code>B1..Bn</code> float reflectance Band reflectance values <p>Example table:</p> Pixel_ID Pixel_Row Pixel_Col B1 B2 B3 1 10 15 0.12 0.09 0.03 2 11 16 0.10 0.08 0.02"},{"location":"schemas/#spectral-library-schema","title":"Spectral library schema","text":"<p>Spectral libraries store reference spectra for endmembers used during unmixing. When saved as JSON or Parquet, each record contains:</p> Field Type Description <code>spectrum_id</code> string Unique identifier <code>class_label</code> string Endmember class (e.g., soil, vegetation) <code>wavelength_nm</code> array Wavelength centers <code>reflectance</code> array Corresponding reflectance values <code>metadata</code> object Optional information (sensor, date, notes, etc.) <p>Example JSON entry:</p> <pre><code>{\n  \"spectrum_id\": \"veg01\",\n  \"class_label\": \"vegetation\",\n  \"wavelength_nm\": [450, 550, 650],\n  \"reflectance\": [0.12, 0.32, 0.45],\n  \"metadata\": {\"sensor\": \"NEON\", \"acquired\": \"2020-08-01\"}\n}\n</code></pre>"},{"location":"schemas/#mesma-outputs-schema","title":"MESMA outputs schema","text":"<p>Results from Multiple Endmember Spectral Mixture Analysis for each pixel.</p> Column Type Units Description <code>Pixel_ID</code> int \u2013 Input pixel identifier <code>fraction_*</code> float fraction Fractional abundance per endmember band <code>RMSE</code> float reflectance Root mean square error of the model fit <code>QA</code> int \u2013 Quality flag (0=good, higher=worse) <p>Example table:</p> Pixel_ID fraction_soil fraction_veg RMSE QA 1 0.40 0.60 0.01 0 2 0.55 0.45 0.02 1 <p>Example JSON line for one pixel:</p> <pre><code>{\n  \"Pixel_ID\": 1,\n  \"fraction_soil\": 0.40,\n  \"fraction_veg\": 0.60,\n  \"RMSE\": 0.01,\n  \"QA\": 0\n}\n</code></pre> <p>Last updated: 2025-08-18</p>"},{"location":"stage-03-pixel-extraction/","title":"Stage 03 Pixel Extraction","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"stage-03-pixel-extraction/#overview","title":"Overview","text":"<p>At this stage you sample pixels from the sorted scenes and write the values to a tabular file. The table becomes the input to spectral unmixing and other downstream analyses.</p>"},{"location":"stage-03-pixel-extraction/#sampling-rules","title":"Sampling rules","text":"<ol> <li>Define a consistent random seed so repeated runs draw the same pixels.</li> <li>Sample within each land\u2010cover class or tile to avoid geographic bias.</li> <li>Drop any pixel flagged by a quality mask or falling outside the region of interest.</li> </ol>"},{"location":"stage-03-pixel-extraction/#handling-nodata-and-masks","title":"Handling nodata and masks","text":"<ul> <li>Treat nodata values (<code>-9999</code> by default) as missing and skip those records.</li> <li>Apply cloud, shadow, and water masks before sampling so invalid pixels never reach the table.</li> <li>Keep a boolean <code>is_masked</code> column to track which values were rejected.</li> </ul>"},{"location":"stage-03-pixel-extraction/#tile-vs-full-scene","title":"Tile vs full scene","text":"<ul> <li>Tiles scale better for large mosaics and let you parallelize extraction.</li> <li>Full scenes are faster when memory allows and ensure contiguous coverage. Choose the approach that matches your hardware and scene size; the output format is identical.</li> </ul>"},{"location":"stage-03-pixel-extraction/#output-tables","title":"Output tables","text":"<p>Each row represents one pixel. Columns typically include <code>scene_id</code>, <code>tile_id</code>, <code>x</code>, <code>y</code>, band values, and <code>is_masked</code>. Write tables as CSV for quick inspection or Parquet for efficient storage. Keep Parquet outputs in a <code>full_extracted_pixels</code> folder that lives alongside the tile folder so the extracted tables sit next to, not inside, the source data. Partition by scene and tile so you can read subsets without loading the whole dataset.</p>"},{"location":"stage-03-pixel-extraction/#memory-tips","title":"Memory tips","text":"<ul> <li>Process one tile at a time and release arrays with <code>del</code> to free RAM.</li> <li>When writing CSV, stream rows with a generator instead of building a huge DataFrame.</li> <li>Prefer Parquet with compression to reduce disk use and load times.</li> </ul>"},{"location":"stage-03-pixel-extraction/#quick-integrity-checks","title":"Quick integrity checks","text":"<ul> <li>Confirm row counts match the number of valid pixels expected per tile.</li> <li>Scan for remaining nodata values: <code>rg -n \"-9999\" sample.csv</code>.</li> <li>Plot a histogram of one band to detect obvious outliers before moving on.</li> </ul>"},{"location":"stage-03-pixel-extraction/#next-steps","title":"Next steps","text":"<p>Continue to Stage 04 to build the spectral library from the extracted pixels.</p> <p>Last updated: 2025-08-18</p>"},{"location":"stage-04-spectral-library/","title":"Stage 04 Spectral Library","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The spectral library stores every spectrum with its full provenance. Each entry includes:</p> <ul> <li><code>site</code>: location identifier where you collected the field sample.</li> <li><code>sensor</code>: instrument or platform that measured the spectrum.</li> <li><code>wavelengths</code>: array of nanometer values shared across spectra.</li> </ul> <p>These fields live alongside the reflectance values in a row-oriented table or NetCDF group. Use them to filter spectra by site, compare sensors, or align data to the wavelength grid.</p>"},{"location":"stage-04-spectral-library/#quality-controls","title":"Quality controls","text":"<p>You can clean spectra before analysis:</p> <ol> <li>Outlier filtering \u2013 drop samples that exceed three standard deviations from the mean reflectance    at any wavelength.</li> <li>Smoothing \u2013 apply a Savitzky\u2013Golay or moving-average filter to reduce instrument noise while    preserving absorption features.</li> <li>Signal-to-noise ratio (SNR) \u2013 flag spectra with low SNR and exclude them from downstream    modeling.</li> </ol>"},{"location":"stage-04-spectral-library/#versioning-and-provenance","title":"Versioning and provenance","text":"<p>Each library release increments a semantic version. A <code>manifest.json</code> file lists source datasets, processing code commits, and software versions so you can reproduce the library or audit its origin.</p> <p>Last updated: 2025-08-18</p>"},{"location":"stage-05-mesma/","title":"Stage 05 MESMA","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"stage-05-mesma/#using-the-spectral-library","title":"Using the spectral library","text":"<p>The spectral library from Stage 04 provides the candidate endmember spectra. You load it as a NumPy array and pass it to the MESMA routine alongside the target image. MESMA iterates through library combinations to find the model with the lowest root mean square error (RMSE).</p> <pre><code>from unmixing.el_mesma import MesmaCore\n\nmesma = MesmaCore()\nfractions, residuals = mesma._mesma(image, library)\n</code></pre>"},{"location":"stage-05-mesma/#endmember-selection-strategies","title":"Endmember selection strategies","text":"<ul> <li>Exhaustive search \u2013 evaluate all combinations up to a fixed complexity.</li> <li>Class-based \u2013 restrict models to endmembers drawn from predefined   classes such as vegetation or soil.</li> <li>Random sampling \u2013 sample combinations to reduce runtime for large   libraries.</li> </ul>"},{"location":"stage-05-mesma/#outputs","title":"Outputs","text":"<ul> <li>Per-endmember fraction maps showing the proportional contribution of each   material and a shade fraction.</li> <li>A residual raster capturing the difference between observed and reconstructed   spectra.</li> </ul>"},{"location":"stage-05-mesma/#validation","title":"Validation","text":"<ul> <li>Verify that the fractions for each pixel sum to approximately <code>1.0</code>.</li> <li>Discard models with RMSE above a user-defined threshold to ensure a reliable   fit.</li> </ul> <p>Last updated: 2025-08-18</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p>"},{"location":"troubleshooting/#troubleshooting-by-symptom","title":"Troubleshooting (by symptom)","text":"Symptom Likely cause Fix No correction JSON written Stage 3 didn\u2019t run or wrong paths Re-run Stage 3; verify <code>..._brdfandtopo_corrected_envi.json</code> exists Convolution error: wavelengths Missing/garbled HDR wavelength block Regenerate ENVI or fix header; re-run Stage 4 QA fails: ENVI reader missing Helper not installed in env Install QA helper; run Stage 7 again OOM / slow export Too many workers or large chunks Reduce <code>--max-workers</code>; use <code>--chunksize</code> QA issues: \u201cWavelengths not strictly increasing\u201d ENVI header wavelengths out of order or missing Re-export header from HyTools/ENVI; ensure <code>wavelength</code> block is numeric and ordered QA issues: \u201cX% negative pixels\u201d Mask gaps or incorrect brightness/BRDF parameters Inspect mask rasters, rerun <code>cscal-qa --full</code>, adjust brightness/BRDF inputs High RMSE/SAM in QA JSON Resampled cube misaligned with corrected cube Confirm sensor SRFs, regenerate <code>*_convolved_envi</code> / <code>*_resampled_&lt;sensor&gt;_envi</code> products <p>See also: Stages \u2022 Outputs</p>"},{"location":"validation/","title":"Validation","text":"<p>DO NOT EDIT OUTSIDE MARKERS</p> <p>The validation procedure ensures quality across the pipeline.</p>"},{"location":"validation/#stage-01-raster-processing","title":"Stage 01 \u2013 Raster Processing","text":"<ul> <li>[ ] Confirm input rasters exist and are readable.</li> <li>[ ] Check projection and resolution match expected values.</li> <li>[ ] Verify no bands contain all nodata values.</li> <li>[ ] Ensure output rasters write successfully.</li> </ul> <pre><code>import rasterio, numpy as np\nwith rasterio.open(\"image.tif\") as src:\n    data = src.read()\n    assert not np.isnan(data).all(axis=(1, 2))\n</code></pre>"},{"location":"validation/#stage-02-sorting","title":"Stage 02 \u2013 Sorting","text":"<ul> <li>[ ] Confirm filenames follow <code>YYYYMMDD_sensor.tif</code> pattern.</li> <li>[ ] Check chronological ordering after sorting.</li> <li>[ ] Verify number of files per date matches expected counts.</li> </ul> <pre><code>import pandas as pd, glob\nfiles = sorted(glob.glob(\"sorted/*.tif\"))\ndates = pd.to_datetime([f.split(\"_\")[0] for f in files])\nassert dates.is_monotonic_increasing\n</code></pre>"},{"location":"validation/#stage-03-pixel-extraction","title":"Stage 03 \u2013 Pixel Extraction","text":"<ul> <li>[ ] Ensure sample coordinates fall within raster bounds.</li> <li>[ ] Validate pixel value ranges for each band.</li> <li>[ ] Cross-check sample count with original list.</li> </ul> <pre><code>import numpy as np, pandas as pd\npixels = pd.read_csv(\"pixels.csv\")\nassert ((pixels['x']&gt;=0) &amp; (pixels['y']&gt;=0)).all()\nassert pixels.drop(columns=['x','y']).apply(np.isfinite).all().all()\n</code></pre>"},{"location":"validation/#stage-04-spectral-library","title":"Stage 04 \u2013 Spectral Library","text":"<ul> <li>[ ] Verify spectra length equals number of bands.</li> <li>[ ] Check for duplicated materials or IDs.</li> <li>[ ] Inspect outlier reflectance values.</li> </ul> <pre><code>import pandas as pd\nlib = pd.read_csv(\"library.csv\")\nlib.groupby(\"material\").size().pipe(print)\nassert (lib.filter(like=\"band\") &lt;= 1).all().all()\n</code></pre>"},{"location":"validation/#stage-05-mesma","title":"Stage 05 \u2013 MESMA","text":"<ul> <li>[ ] Confirm endmember sets sum to \u22641.</li> <li>[ ] Review residual errors per pixel.</li> <li>[ ] Flag negative abundance values.</li> </ul> <pre><code>import pandas as pd\nabund = pd.read_csv(\"mesma_output.csv\")\nassert (abund.filter(like=\"EM\").sum(axis=1) &lt;= 1.01).all()\nassert (abund.filter(like=\"EM\") &gt;= 0).all().all()\n</code></pre>"},{"location":"_build/doc_drift_report/","title":"Documentation Drift Report","text":""},{"location":"_build/doc_drift_report/#naming-rule","title":"Naming rule","text":"<ul> <li>Merged parquet naming in code: _merged_pixel_extraction.parquet"},{"location":"_build/doc_drift_report/#missing-items-in-docs","title":"Missing items in docs","text":"<ul> <li>Outputs: \u2014</li> <li>Sensors: micasense_to_match_oli_and_oli, micasense_to_match_oli_oli, micasense_to_match_tm_etm_plus</li> </ul>"},{"location":"_build/doc_drift_report/#stale-items-in-docs","title":"Stale items in docs","text":"<ul> <li>Outputs: _landsat_etm+_envi.img, _landsat_oli_envi.parquet, _landsat_tm_envi.hdr, _landsat_tm_envi.img, _micasense*_envi.img, _micasense_envi.hdr, _micasense_envi.img</li> <li>Sensors: MicaSense, MicaSense), MicaSense)., MicaSense,, MicaSense,,, MicaSense,,,, MicaSense,,,,, MicaSense,,,,,, MicaSense,,,,,,, MicaSense,,,,,,,, MicaSense-matched, MicaSense], Micasense,, Micasense,,, Micasense,,,, Micasense,,,,, Micasense,,,,,, Micasense,,,,,,, Micasense,,,,,,,, micasense\",, micasense'], micasense'],, micasense'],,, micasense'],,,, micasense'],,,,, micasense'],,,,,, micasense'],,,,,,, micasense_envi.img,, micasense_envi.img<code>,, micasense.json</code>, micasense.json<code>):, micasense_envi.hdr, micasense_envi.hdr,, micasense_envi.hdr,,, micasense_envi.hdr,,,, micasense_envi.hdr,,,,, micasense_envi.hdr,,,,,, micasense_envi.hdr,,,,,,, micasense_envi.img, micasense_envi.img,, micasense_envi.img,,, micasense_envi.img,,,, micasense_envi.img,,,,, micasense_envi.img,,,,,, micasense_envi.img,,,,,,, micasense_envi.img/.hdr/.parquet, micasense_envi.img/.hdr/.parquet,, micasense_envi.img/.hdr/.parquet,,, micasense_envi.img/.hdr/.parquet,,,, micasense_envi.img/.hdr/.parquet,,,,, micasense_envi.img/.hdr/.parquet,,,,,, micasense_envi.img/.hdr/.parquet,,,,,,, micasense_to_match_oli_and_oli,, micasense_to_match_oli_and_oli,,, micasense_to_match_oli_and_oli,,,, micasense_to_match_oli_and_oli,,,,, micasense_to_match_oli_and_oli,,,,,, micasense_to_match_oli_and_oli,,,,,,, micasense_to_match_oli_oli,, micasense_to_match_oli_oli,,, micasense_to_match_oli_oli,,,, micasense_to_match_oli_oli,,,,, micasense_to_match_oli_oli,,,,,, micasense_to_match_oli_oli,,,,,,, micasense_to_match_tm_etm+,,,,,,, micasense</code>, micasense`)</li> </ul>"},{"location":"_build/doc_drift_report/#entry-points-pyproject","title":"Entry points (pyproject)","text":"<p>{   \"cscal-download\": \"cross_sensor_cal.cli:download_main\",   \"cscal-pipeline\": \"cross_sensor_cal.cli.pipeline_cli:main\",   \"cscal-qa\": \"cross_sensor_cal.cli.qa_cli:main\",   \"cscal-recover-raw\": \"cross_sensor_cal.cli.recover_cli:main\",   \"cscal-qa-dashboard\": \"cross_sensor_cal.qa_dashboard:main\",   \"csc-merge-duckdb\": \"cross_sensor_cal.merge_duckdb:main\" }</p>"},{"location":"_build/doc_drift_report/#cli-flags-discovered","title":"CLI flags discovered","text":"<p>{   \"topo_and_brdf_correction.py\": [     \"--config_file\"   ],   \"neon_to_envi.py\": [     \"--brightness-offset\"   ],   \"qa_dashboard.py\": [     \"--base-folder\",     \"--out-parquet\",     \"--out-png\"   ],   \"merge_duckdb.py\": [     \"--corrected-glob\",     \"--data-root\",     \"--flightline-glob\",     \"--no-qa\",     \"--original-glob\",     \"--out-name\",     \"--resampled-glob\",     \"--write-feather\"   ],   \"standard_resample.py\": [     \"--hdr_path\",     \"--json_file\",     \"--output_path\",     \"--resampling_file_path\",     \"--sensor_type\"   ],   \"qa_cli.py\": [     \"--base-folder\",     \"--full\",     \"--n-sample\",     \"--out-dir\",     \"--quick\",     \"--rgb-bands\",     \"--save-json\"   ],   \"recover_cli.py\": [     \"--base-folder\",     \"--brightness-offset\"   ],   \"pipeline_cli.py\": [     \"--base-folder\",     \"--brightness-offset\",     \"--flight-lines\",     \"--max-workers\",     \"--product-code\",     \"--resample-method\",     \"--site-code\",     \"--year-month\"   ],   \"pipeline.py\": [     \"--brightness-offset\",     \"--no-sync\",     \"--polygon_layer_path\",     \"--reflectance-offset\",     \"--remote-prefix\",     \"--resample-method\",     \"--verbose\"   ],   \"download.py\": [     \"--flight\",     \"--output\",     \"--product\",     \"--year-month\"   ] }</p>"},{"location":"_build/doc_drift_report/#stage-markers-found-in-logs","title":"Stage markers found in logs","text":"<ul> <li>[merge] \u26a0\ufe0f QA panel after merge failed for {prefix}: {e}</li> <li>[merge] \ud83d\uddbc\ufe0f  QA panel \u2192 {out_png_path} </li> <li>[{flight_stem}] \u2b07\ufe0f Download already complete \u2014 reusing existing files ({h5_path.name})</li> <li>[{flight_stem}] \ud83c\udf10 Downloading {flight_stem} ({site_code}, {year_month}) into {h5_path} ...</li> <li>\u23ed\ufe0f Parquet already present for %s -&gt; %s (skipping)</li> <li>\u26a0\ufe0f Cannot create Parquet work directory for %s: %s</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .hdr is missing or empty</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .img is missing or empty</li> <li>\u26a0\ufe0f Cannot locate work directory for Parquet export: %s</li> <li>\u26a0\ufe0f Cannot remove invalid Parquet for %s (%s)</li> <li>\u26a0\ufe0f Existing Parquet for %s is invalid (%s); regenerating</li> <li>\u26a0\ufe0f Failed Parquet export for %s: %s</li> <li>\u26a0\ufe0f Merge failed for {future_map[future]}: {exc}</li> <li>\u26a0\ufe0f Parquet validation reported an issue for %s: %s</li> <li>\u26a0\ufe0f Skipping DuckDB merge for %s because no Parquet outputs were produced</li> <li>\u2705 BRDF+topo correction already complete for %s -&gt; %s / %s (skipping)</li> <li>\u2705 BRDF+topo correction already complete for %s, skipping</li> <li>\u2705 BRDF+topo correction completed for %s -&gt; %s / %s</li> <li>\u2705 Download complete for %s \u2192 %s</li> <li>\u2705 ENVI export created successfully \u2192 {raw_img_path.name} / {raw_hdr_path.name}</li> <li>\u2705 Existing ENVI export found \u2014 skipping heavy export ({raw_img_path.name} / {raw_hdr_path.name})</li> <li>\u2705 Parquet stage complete for %s</li> <li>\u2705 Wrote Parquet for %s -&gt; %s</li> <li>\u2728 Existing ENVI exports detected \u2014 pipeline will reuse validated files automatically.</li> <li>\ud83c\udf89 Finished pipeline for %s</li> <li>\ud83c\udf89 Finished pipeline for %s (parallel worker join)</li> <li>\ud83c\udfaf Convolving corrected reflectance for %s</li> <li>\ud83d\udccd Preparing ENVI export at: {raw_img_path.name} / {raw_hdr_path.name}</li> <li>\ud83d\udce6 No existing ENVI export detected \u2014 creating a new one from source data {h5_path.name}</li> <li>\ud83d\udce6 Parquet export for %s ...</li> </ul> <p>TODO: Review sensor labels in docs for formatting issues.</p>"},{"location":"api/","title":"Python API","text":"<p>Use these functions when you need fine-grained control beyond the CLI.</p>"},{"location":"api/#quick-example","title":"Quick example","text":"<pre><code>from cross_sensor_cal import merge_duckdb\nmerge_duckdb([\"parquet/a.parquet\",\"parquet/b.parquet\"], \"merged/all.parquet\")\n</code></pre>"},{"location":"api/#brightness-correction-entry-point","title":"Brightness correction entry point","text":""},{"location":"api/#apply_brightness_correctioncube-masknone-methodpercentile_match","title":"<code>apply_brightness_correction(cube, mask=None, method='percentile_match', ...)</code>","text":"<p>Normalizes per-band brightness for hyperspectral cubes before BRDF/topo stages. The docstring walks through the affine model, parameter choices, and examples. Use it when you need to harmonise tiles prior to the full pipeline; the QA JSON will surface the per-band gain/offsets when this stage runs.</p> <p>Cross-Sensor Calibration public package surface.</p>"},{"location":"api/#cross_sensor_cal._PLOT_EXPORTS","title":"<code>_PLOT_EXPORTS = (make_micasense_vs_landsat_panels.__name__, make_sensor_vs_neon_panels.__name__)</code>  <code>module-attribute</code>","text":""},{"location":"api/#cross_sensor_cal.__all__","title":"<code>__all__ = sorted(set(__all__ + (['apply_brightness_correction', load_brightness_coefficients.__name__] + list(_PLOT_EXPORTS))))</code>  <code>module-attribute</code>","text":""},{"location":"api/#cross_sensor_cal.__version__","title":"<code>__version__ = '2.2.0'</code>  <code>module-attribute</code>","text":""},{"location":"api/#cross_sensor_cal.__getattr__","title":"<code>__getattr__(name)</code>","text":""},{"location":"api/#cross_sensor_cal.load_brightness_coefficients","title":"<code>load_brightness_coefficients(system_pair='landsat_to_micasense')</code>","text":"<p>Load brightness coefficients for a given system pair.</p>"},{"location":"api/#cross_sensor_cal.load_brightness_coefficients--parameters","title":"Parameters","text":"<p>system_pair : str     Key identifying the pair of systems, e.g. \"landsat_to_micasense\".</p>"},{"location":"api/#cross_sensor_cal.load_brightness_coefficients--returns","title":"Returns","text":"<p>dict[int, float]     Mapping from 1-based band index to brightness coefficient (percent).</p>"},{"location":"api/#cross_sensor_cal.load_brightness_coefficients--notes","title":"Notes","text":"<ul> <li>Values are stored in percent (e.g., -7.3959 means \"reduce by 7.3959%\").</li> </ul>"},{"location":"api/#cross_sensor_cal.make_micasense_vs_landsat_panels","title":"<code>make_micasense_vs_landsat_panels(merged_dir, out_dir=None, *, max_points=50000, sentinel_at_or_below=-9999.0)</code>","text":""},{"location":"api/#cross_sensor_cal.make_sensor_vs_neon_panels","title":"<code>make_sensor_vs_neon_panels(merged_dir, out_dir=None, *, max_points=50000, sentinel_at_or_below=-9999.0)</code>","text":""},{"location":"api/merge_duckdb/","title":"API: merge_duckdb","text":"<p>Merge all pixel-level parquet tables for one flightline.</p>"},{"location":"api/merge_duckdb/#cross_sensor_cal.merge_duckdb.merge_flightline--parameters","title":"Parameters","text":"<p>flightline_dir : Path     Directory containing the flightline's parquet outputs. out_name : str, optional     Custom name for the merged parquet. If None, defaults to:     _merged_pixel_extraction.parquet original_glob : str, optional     Glob used to locate original reflectance parquet tables. corrected_glob : str, optional     Glob used to locate corrected reflectance parquet tables. resampled_glob : str, optional     Glob used to locate resampled sensor parquet tables. write_feather : bool, optional     If True, writes a Feather copy of the merged table alongside the parquet. emit_qa_panel : bool, default True     If True, renders the standard QA panel (_qa.png) after merging."},{"location":"api/merge_duckdb/#cross_sensor_cal.merge_duckdb.merge_flightline--returns","title":"Returns","text":"<p>Path     Path to the merged parquet file.</p>"},{"location":"api/qa_plots/","title":"API: qa_plots","text":"<p>Return (png_path, metrics_dict); also writes _qa.json/_qa.pdf when requested.</p>"},{"location":"dev/contributing/","title":"Contributing","text":"<ul> <li>Run tests</li> <li>Run docs drift audit before committing doc changes:   <pre><code>python tools/doc_drift_audit.py\npython tools/apply_doc_fixes.py\n</code></pre></li> <li>Preview docs locally:   <pre><code>pip install mkdocs mkdocs-material mkdocstrings[python] mkdocs-macros-plugin\nmkdocs serve\n</code></pre></li> </ul>"},{"location":"dev/contributing/#docs-pr-checklist","title":"Docs PR checklist","text":"<ul> <li>[ ] Use Purpose \u2022 Inputs \u2022 Outputs \u2022 Run it \u2022 Pitfalls on how-to pages</li> <li>[ ] Include a CLI copy block and (when relevant) a short Python snippet</li> <li>[ ] Link Stages \u2194 Schemas \u2194 Outputs \u2194 Troubleshooting</li> <li>[ ] <code>mkdocs build</code> passes locally</li> </ul>"},{"location":"dev/contributing/#continuous-integration-checks","title":"Continuous integration checks","text":"<p>Pull requests to <code>main</code> run four main checks:</p> <ol> <li>CI / lite \u2013 fast linting and smoke tests.</li> <li>CI / unit \u2013 full Python test suite.</li> <li>Docs Drift Check / audit \u2013 verifies docs and code stay in sync.</li> <li>QA quick check / qa \u2013 runs a minimal QA pipeline on a small fixture and uploads the PNG/JSON/PDF artifacts.</li> </ol> <p>This layout keeps feedback fast while ensuring the QA pipeline and docs stay healthy. The QA quick check now runs once per PR (and optionally on pushes to <code>main</code>) instead of duplicating work on every branch push.</p>"},{"location":"dev/doc_drift/","title":"Doc Drift","text":"<p>Maintain this page after any behavior change. Surface a short \"What changed?\" callout on Home if user-facing.</p>"},{"location":"dev/doc_drift/#documentation-drift-report","title":"Documentation Drift Report","text":""},{"location":"dev/doc_drift/#naming-rule","title":"Naming rule","text":"<ul> <li>Merged parquet naming in code: _merged_pixel_extraction.parquet"},{"location":"dev/doc_drift/#missing-items-in-docs","title":"Missing items in docs","text":"<ul> <li>Outputs: \u2014</li> <li>Sensors: micasense_to_match_oli_and_oli, micasense_to_match_oli_oli, micasense_to_match_tm_etm+</li> </ul>"},{"location":"dev/doc_drift/#stale-items-in-docs","title":"Stale items in docs","text":"<ul> <li>Outputs: _brdfandtopo_corrected_envi.parquet, _landsat_etm+_envi.img, _landsat_oli_envi.parquet, _landsat_tm_envi.hdr, _landsat_tm_envi.img, _micasense*_envi.img, _micasense_envi.hdr, _micasense_envi.img, _qa.json</li> <li>Sensors: MicaSense, MicaSense,, MicaSense,,, MicaSense,,,, MicaSense,,,,, MicaSense,,,,,, MicaSense,,,,,,, Micasense,, Micasense,,, Micasense,,,, Micasense,,,,, Micasense,,,,,, Micasense,,,,,,, micasense'], micasense'],, micasense'],,, micasense'],,,, micasense'],,,,, micasense'],,,,,, micasense*_envi.img<code>, micasense_envi.hdr, micasense_envi.hdr,, micasense_envi.hdr,,, micasense_envi.hdr,,,, micasense_envi.hdr,,,,, micasense_envi.hdr,,,,,, micasense_envi.img, micasense_envi.img,, micasense_envi.img,,, micasense_envi.img,,,, micasense_envi.img,,,,, micasense_envi.img,,,,,, micasense_envi.img/.hdr/.parquet, micasense_envi.img/.hdr/.parquet,, micasense_envi.img/.hdr/.parquet,,, micasense_envi.img/.hdr/.parquet,,,, micasense_envi.img/.hdr/.parquet,,,,, micasense_envi.img/.hdr/.parquet,,,,,, micasense_to_match_oli_and_oli,, micasense_to_match_oli_and_oli,,, micasense_to_match_oli_and_oli,,,, micasense_to_match_oli_and_oli,,,,, micasense_to_match_oli_and_oli,,,,,, micasense_to_match_oli_oli,, micasense_to_match_oli_oli,,, micasense_to_match_oli_oli,,,, micasense_to_match_oli_oli,,,,, micasense_to_match_oli_oli,,,,,, micasense_to_match_tm_etm+,,,,,, micasense</code>)</li> </ul>"},{"location":"dev/doc_drift/#entry-points-pyproject","title":"Entry points (pyproject)","text":"<p>{   \"cscal-download\": \"cross_sensor_cal.cli:download_main\",   \"cscal-pipeline\": \"cross_sensor_cal.cli.pipeline_cli:main\",   \"cscal-qa\": \"cross_sensor_cal.cli.qa_cli:main\",   \"cscal-recover-raw\": \"cross_sensor_cal.cli.recover_cli:main\",   \"cscal-qa-dashboard\": \"cross_sensor_cal.qa_dashboard:main\",   \"csc-merge-duckdb\": \"cross_sensor_cal.merge_duckdb:main\" }</p>"},{"location":"dev/doc_drift/#cli-flags-discovered","title":"CLI flags discovered","text":"<p>{   \"topo_and_brdf_correction.py\": [     \"--config_file\"   ],   \"merge_duckdb.py\": [     \"--corrected-glob\",     \"--data-root\",     \"--flightline-glob\",     \"--no-qa\",     \"--original-glob\",     \"--out-name\",     \"--resampled-glob\",     \"--write-feather\"   ],   \"qa_metrics.py\": [     \"--base-folder\",     \"--flight-stem\"   ],   \"standard_resample.py\": [     \"--hdr_path\",     \"--json_file\",     \"--output_path\",     \"--resampling_file_path\",     \"--sensor_type\"   ],   \"qa_dashboard.py\": [     \"--base-folder\",     \"--out-parquet\",     \"--out-png\"   ],   \"neon_to_envi.py\": [     \"--brightness-offset\"   ],   \"pipeline_cli.py\": [     \"--base-folder\",     \"--brightness-offset\",     \"--flight-lines\",     \"--max-workers\",     \"--product-code\",     \"--resample-method\",     \"--site-code\",     \"--year-month\"   ],   \"recover_cli.py\": [     \"--base-folder\",     \"--brightness-offset\"   ],   \"qa_cli.py\": [     \"--base-folder\",     \"--out-dir\",     \"--quick\",     \"--full\",     \"--save-json\",     \"--no-save-json\",     \"--n-sample\",     \"--rgb-bands\"   ],   \"pipeline.py\": [     \"--brightness-offset\",     \"--no-sync\",     \"--polygon_layer_path\",     \"--reflectance-offset\",     \"--remote-prefix\",     \"--resample-method\",     \"--verbose\"   ],   \"download.py\": [     \"--flight\",     \"--output\",     \"--product\",     \"--year-month\"   ] }</p>"},{"location":"dev/doc_drift/#stage-markers-found-in-logs","title":"Stage markers found in logs","text":"<ul> <li>[cscal-qa] \u2705 QA panels written to: {target.resolve()}</li> <li>\u23ed\ufe0f Parquet already present for %s -&gt; %s (skipping)</li> <li>\u26a0\ufe0f  QA panel generation failed for %s: %s</li> <li>\u26a0\ufe0f Cannot create Parquet work directory for %s: %s</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .hdr is missing or empty</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .img is missing or empty</li> <li>\u26a0\ufe0f Cannot locate work directory for Parquet export: %s</li> <li>\u26a0\ufe0f Failed Parquet export for %s: %s</li> <li>\u26a0\ufe0f Merge failed for {future_map[future]}: {exc}</li> <li>\u26a0\ufe0f QA panel after merge failed for {flightline_dir.name}: {e}</li> <li>\u2705 BRDF+topo correction already complete for %s -&gt; %s / %s (skipping)</li> <li>\u2705 BRDF+topo correction already complete for %s, skipping</li> <li>\u2705 BRDF+topo correction completed for %s -&gt; %s / %s</li> <li>\u2705 Download complete for %s \u2192 %s</li> <li>\u2705 ENVI export already complete for %s -&gt; %s / %s (skipping heavy export)</li> <li>\u2705 ENVI export completed for %s -&gt; %s / %s</li> <li>\u2705 Parquet stage complete for %s</li> <li>\u2705 Wrote Parquet for %s -&gt; %s</li> <li>\ud83c\udf10 Downloading %s (%s, %s) into %s ...</li> <li>\ud83c\udf89 Finished pipeline for %s</li> <li>\ud83c\udf89 Finished pipeline for %s (parallel worker join)</li> <li>\ud83c\udfaf Convolving corrected reflectance for %s</li> <li>\ud83d\udce6 ENVI export not found or invalid for %s, generating from %s</li> <li>\ud83d\udce6 Parquet export for %s ...</li> <li>\ud83d\udd0e ENVI export target for %s is %s / %s</li> <li>\ud83d\uddbc\ufe0f  Overwriting QA panel -&gt; %s</li> <li>\ud83d\uddbc\ufe0f  QA panel written \u2192 {prefix}_qa.png</li> <li>\ud83d\uddbc\ufe0f  Writing QA panel -&gt; %s</li> <li>\ud83d\uddbc\ufe0f  Wrote QA panel for %s -&gt; %s</li> </ul> <p>TODO: Review sensor labels in docs for formatting issues.</p>"},{"location":"dev/doc_drift_report/","title":"Documentation Drift Report","text":""},{"location":"dev/doc_drift_report/#naming-rule","title":"Naming rule","text":"<ul> <li>Merged parquet naming in code: _merged_pixel_extraction.parquet"},{"location":"dev/doc_drift_report/#missing-items-in-docs","title":"Missing items in docs","text":"<ul> <li>Outputs: \u2014</li> <li>Sensors: micasense_to_match_oli_and_oli, micasense_to_match_oli_oli, micasense_to_match_tm_etm_plus</li> </ul>"},{"location":"dev/doc_drift_report/#stale-items-in-docs","title":"Stale items in docs","text":"<ul> <li>Outputs: _landsat_etm+_envi.img, _landsat_oli_envi.parquet, _landsat_tm_envi.hdr, _landsat_tm_envi.img, _micasense*_envi.img, _micasense_envi.hdr, _micasense_envi.img</li> <li>Sensors: MicaSense, MicaSense), MicaSense)., MicaSense,, MicaSense,,, MicaSense,,,, MicaSense,,,,, MicaSense,,,,,, MicaSense,,,,,,, MicaSense,,,,,,,, MicaSense-matched, MicaSense], Micasense,, Micasense,,, Micasense,,,, Micasense,,,,, Micasense,,,,,, Micasense,,,,,,, Micasense,,,,,,,, micasense\",, micasense'], micasense'],, micasense'],,, micasense'],,,, micasense'],,,,, micasense'],,,,,, micasense'],,,,,,, micasense_envi.img,, micasense_envi.img<code>,, micasense.json</code>, micasense.json<code>):, micasense_envi.hdr, micasense_envi.hdr,, micasense_envi.hdr,,, micasense_envi.hdr,,,, micasense_envi.hdr,,,,, micasense_envi.hdr,,,,,, micasense_envi.hdr,,,,,,, micasense_envi.img, micasense_envi.img,, micasense_envi.img,,, micasense_envi.img,,,, micasense_envi.img,,,,, micasense_envi.img,,,,,, micasense_envi.img,,,,,,, micasense_envi.img/.hdr/.parquet, micasense_envi.img/.hdr/.parquet,, micasense_envi.img/.hdr/.parquet,,, micasense_envi.img/.hdr/.parquet,,,, micasense_envi.img/.hdr/.parquet,,,,, micasense_envi.img/.hdr/.parquet,,,,,, micasense_envi.img/.hdr/.parquet,,,,,,, micasense_to_match_oli_and_oli,, micasense_to_match_oli_and_oli,,, micasense_to_match_oli_and_oli,,,, micasense_to_match_oli_and_oli,,,,, micasense_to_match_oli_and_oli,,,,,, micasense_to_match_oli_and_oli,,,,,,, micasense_to_match_oli_oli,, micasense_to_match_oli_oli,,, micasense_to_match_oli_oli,,,, micasense_to_match_oli_oli,,,,, micasense_to_match_oli_oli,,,,,, micasense_to_match_oli_oli,,,,,,, micasense_to_match_tm_etm+,,,,,,, micasense</code>, micasense`)</li> </ul>"},{"location":"dev/doc_drift_report/#entry-points-pyproject","title":"Entry points (pyproject)","text":"<p>{   \"cscal-download\": \"cross_sensor_cal.cli:download_main\",   \"cscal-pipeline\": \"cross_sensor_cal.cli.pipeline_cli:main\",   \"cscal-qa\": \"cross_sensor_cal.cli.qa_cli:main\",   \"cscal-recover-raw\": \"cross_sensor_cal.cli.recover_cli:main\",   \"cscal-qa-dashboard\": \"cross_sensor_cal.qa_dashboard:main\",   \"csc-merge-duckdb\": \"cross_sensor_cal.merge_duckdb:main\" }</p>"},{"location":"dev/doc_drift_report/#cli-flags-discovered","title":"CLI flags discovered","text":"<p>{   \"topo_and_brdf_correction.py\": [     \"--config_file\"   ],   \"neon_to_envi.py\": [     \"--brightness-offset\"   ],   \"qa_dashboard.py\": [     \"--base-folder\",     \"--out-parquet\",     \"--out-png\"   ],   \"merge_duckdb.py\": [     \"--corrected-glob\",     \"--data-root\",     \"--flightline-glob\",     \"--no-qa\",     \"--original-glob\",     \"--out-name\",     \"--resampled-glob\",     \"--write-feather\"   ],   \"standard_resample.py\": [     \"--hdr_path\",     \"--json_file\",     \"--output_path\",     \"--resampling_file_path\",     \"--sensor_type\"   ],   \"qa_cli.py\": [     \"--base-folder\",     \"--full\",     \"--n-sample\",     \"--out-dir\",     \"--quick\",     \"--rgb-bands\",     \"--save-json\"   ],   \"recover_cli.py\": [     \"--base-folder\",     \"--brightness-offset\"   ],   \"pipeline_cli.py\": [     \"--base-folder\",     \"--brightness-offset\",     \"--flight-lines\",     \"--max-workers\",     \"--product-code\",     \"--resample-method\",     \"--site-code\",     \"--year-month\"   ],   \"pipeline.py\": [     \"--brightness-offset\",     \"--no-sync\",     \"--polygon_layer_path\",     \"--reflectance-offset\",     \"--remote-prefix\",     \"--resample-method\",     \"--verbose\"   ],   \"download.py\": [     \"--flight\",     \"--output\",     \"--product\",     \"--year-month\"   ] }</p>"},{"location":"dev/doc_drift_report/#stage-markers-found-in-logs","title":"Stage markers found in logs","text":"<ul> <li>[merge] \u26a0\ufe0f QA panel after merge failed for {prefix}: {e}</li> <li>[merge] \ud83d\uddbc\ufe0f  QA panel \u2192 {out_png_path} </li> <li>[{flight_stem}] \u2b07\ufe0f Download already complete \u2014 reusing existing files ({h5_path.name})</li> <li>[{flight_stem}] \ud83c\udf10 Downloading {flight_stem} ({site_code}, {year_month}) into {h5_path} ...</li> <li>\u23ed\ufe0f Parquet already present for %s -&gt; %s (skipping)</li> <li>\u26a0\ufe0f Cannot create Parquet work directory for %s: %s</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .hdr is missing or empty</li> <li>\u26a0\ufe0f Cannot export Parquet for %s because .img is missing or empty</li> <li>\u26a0\ufe0f Cannot locate work directory for Parquet export: %s</li> <li>\u26a0\ufe0f Cannot remove invalid Parquet for %s (%s)</li> <li>\u26a0\ufe0f Existing Parquet for %s is invalid (%s); regenerating</li> <li>\u26a0\ufe0f Failed Parquet export for %s: %s</li> <li>\u26a0\ufe0f Merge failed for {future_map[future]}: {exc}</li> <li>\u26a0\ufe0f Parquet validation reported an issue for %s: %s</li> <li>\u26a0\ufe0f Skipping DuckDB merge for %s because no Parquet outputs were produced</li> <li>\u2705 BRDF+topo correction already complete for %s -&gt; %s / %s (skipping)</li> <li>\u2705 BRDF+topo correction already complete for %s, skipping</li> <li>\u2705 BRDF+topo correction completed for %s -&gt; %s / %s</li> <li>\u2705 Download complete for %s \u2192 %s</li> <li>\u2705 ENVI export created successfully \u2192 {raw_img_path.name} / {raw_hdr_path.name}</li> <li>\u2705 Existing ENVI export found \u2014 skipping heavy export ({raw_img_path.name} / {raw_hdr_path.name})</li> <li>\u2705 Parquet stage complete for %s</li> <li>\u2705 Wrote Parquet for %s -&gt; %s</li> <li>\u2728 Existing ENVI exports detected \u2014 pipeline will reuse validated files automatically.</li> <li>\ud83c\udf89 Finished pipeline for %s</li> <li>\ud83c\udf89 Finished pipeline for %s (parallel worker join)</li> <li>\ud83c\udfaf Convolving corrected reflectance for %s</li> <li>\ud83d\udccd Preparing ENVI export at: {raw_img_path.name} / {raw_hdr_path.name}</li> <li>\ud83d\udce6 No existing ENVI export detected \u2014 creating a new one from source data {h5_path.name}</li> <li>\ud83d\udce6 Parquet export for %s ...</li> </ul> <p>TODO: Review sensor labels in docs for formatting issues.</p>"},{"location":"pipeline/outputs/","title":"Outputs","text":""},{"location":"pipeline/outputs/#envi-export-_enviimghdr","title":"ENVI export (<code>*_envi.img/.hdr</code>)","text":"<ul> <li>What: Source H5 as ENVI for fast banded IO.</li> <li>Produced by: Stage 2</li> <li>Example: <code>NEON_D13_NIWO_..._directional_reflectance_envi.img</code></li> <li>Next: Stages \u2192 3 Correction \u2022 Schemas \u2022 Preview</li> </ul>"},{"location":"pipeline/outputs/#corrected-envi-_brdfandtopo_corrected_envi","title":"Corrected ENVI (<code>*_brdfandtopo_corrected_envi.*</code>)","text":"<ul> <li>What: Topo+BRDF-corrected cube with JSON sidecar.</li> <li>Produced by: Stage 3</li> <li>Example: <code>..._brdfandtopo_corrected_envi.img</code> + <code>..._brdfandtopo_corrected_envi.json</code></li> <li>Next: Convolution \u2022 Schemas</li> </ul>"},{"location":"pipeline/outputs/#convolved-envi-__envi_sensor","title":"Convolved ENVI (<code>*_..._envi_&lt;sensor&gt;.*</code>)","text":"<ul> <li>What: Resampled to target sensor bandpasses.</li> <li>Produced by: Stage 4</li> <li>Example: <code>..._brdfandtopo_corrected_envi_OLI.img</code></li> <li>Next: Parquet export \u2022 Schemas</li> </ul>"},{"location":"pipeline/outputs/#parquet-per-product","title":"Parquet (per product)","text":"<ul> <li>What: Tidy columns for pixels and bands.</li> <li>Produced by: Stage 5</li> <li>Next: Merge \u2022 Preview</li> </ul>"},{"location":"pipeline/outputs/#merged-parquet","title":"Merged parquet","text":"<ul> <li>What: Analysis-ready combined table.</li> <li>Produced by: Stage 6</li> <li>Example: <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code></li> <li>Next: QA panel</li> </ul>"},{"location":"pipeline/qa_panel/","title":"QA panel","text":"<p>The QA panel couples a metrics JSON file with an annotated PNG so that engineering and science teams can track both spectral statistics and the visual context for every flightline. See How to Interpret the Panel and the validation reference for deeper guidance on each metric.</p> <p>Additional QA products created from the merged Parquet:</p> <ul> <li> <p><code>&lt;prefix&gt;_merged__BY_SENSOR_vs_NEON_directional_BRDFTopo.png</code>   Sensor-by-sensor scatter panels versus NEON directional BRDFTopo.</p> </li> <li> <p><code>&lt;prefix&gt;_merged__MS_vs_Landsat_FIXED.png</code>   MicaSense-matched (X) versus Landsat (Y) scatter panels by band.</p> </li> </ul>"},{"location":"pipeline/qa_panel/#multi-page-qa-report","title":"Multi-page QA report","text":"<p>In addition to the single PNG QA panel (<code>&lt;prefix&gt;_qa.png</code>), the pipeline now writes a multi-page PDF report (<code>&lt;prefix&gt;_qa.pdf</code>) with three pages:</p> <ol> <li> <p>Page 1 \u2013 ENVI overview    One row with one panel per ENVI product. This is a quick visual check that    all ENVI files exist and render correctly.</p> </li> <li> <p>Page 2 \u2013 Topographic &amp; BRDF diagnostics </p> </li> <li>Row 1: pre vs post histograms and \u0394 median vs wavelength for the combined      topographic + BRDF correction stage.  </li> <li> <p>Row 2: summaries of topographic (slope/aspect) and BRDF geometry      (solar/sensor angles) derived from the correction JSON.</p> </li> <li> <p>Page 3 \u2013 Remaining QA diagnostics </p> </li> <li>Convolution scatter plots (expected vs computed bands).  </li> <li>Header and wavelength integrity summary (flags when sensor defaults are used).</li> <li>Mask coverage, negatives %, and &gt;1.2 reflectance % summary.</li> <li>Issues/warnings, including brightness coefficients that were applied.</li> </ol>"},{"location":"pipeline/qa_panel/#qa-panel-and-validation-tests","title":"QA Panel and Validation Tests","text":"<p>The QA panel is the final diagnostic step of the Cross-Sensor Calibration pipeline. It provides both a visual and quantitative summary of how well each product behaved through all correction stages (topographic, BRDF, brightness, convolution).  </p>"},{"location":"pipeline/qa_panel/#what-the-qa-tests-measure","title":"What the QA Tests Measure","text":"Test What It Checks Why It Matters Reflectance Range (negatives &amp; &gt;1.2 %) Fraction of pixels below 0 or above 1.2 Reflectance should remain physically bounded. Large negative or &gt;1.2 values indicate poor radiometric scaling or unmasked clouds/shadows. Header &amp; Wavelength Integrity Presence, count, monotonicity, and provenance of <code>wavelength</code> values in ENVI headers Ensures each band is correctly aligned; missing, non-monotonic, or defaulted wavelengths break convolution and spectral analyses. \u0394Reflectance (Pre\u2192Post Correction) Median and IQR difference in reflectance before and after BRDF/topo correction Quantifies how much the correction changed the data. Large deltas in flat terrain suggest over-correction; near-zero deltas in complex terrain may suggest under-correction. Brightness Normalization (if applied) Per-band gain and offset used in brightness correction Tracks whether correction parameters remain within expected limits (e.g., gain \u2208 [0.9, 1.1]). Large deviations imply inconsistent illumination normalization. Convolution Accuracy (per target sensor) RMSE and Spectral Angle Mapper (SAM) between expected vs computed bands Confirms spectral resampling is physically consistent. High RMSE or large SAM (&gt;0.05 radians) indicates wavelength misalignment or incorrect response functions. Mask Coverage % of valid pixels used for metrics Low valid coverage (&lt;60%) signals missing masks or unfiltered NaNs. Histogram Shape Consistency Visual histogram overlay of pre/post corrections Skewed or bimodal shapes suggest scene heterogeneity or masking issues."},{"location":"pipeline/qa_panel/#brightness-coefficients","title":"Brightness coefficients","text":"<p>When NEON data are convolved to Landsat bands, we optionally apply small per-band brightness adjustments so that Landsat-like products match a MicaSense reference.</p> <ul> <li>Coefficients are stored in <code>landsat_to_micasense.json</code> (units: percent).</li> <li>The adjustment is multiplicative:</li> </ul> <p><code>L_adj = L_raw * (1 + coeff / 100)</code>, where negative coefficients darken   Landsat bands slightly.</p> <ul> <li>Applied coefficients are recorded in the QA JSON under   <code>brightness_coefficients.landsat_to_micasense</code> and displayed on Page 3 of   the QA PDF.</li> </ul> <p>This makes it easy to verify when a brightness adjustment was applied and to audit the exact per-band values.</p>"},{"location":"pipeline/qa_panel/#why-these-tests-are-appropriate","title":"Why These Tests Are Appropriate","text":"<p>These diagnostics are physically interpretable and sensor-agnostic:</p> <ul> <li>Radiometric realism: Reflectance outside [0,1.2] is physically implausible and signals calibration drift or shadow contamination.  </li> <li>Spectral continuity: Monotonic wavelengths ensure that per-band corrections and convolutions follow real sensor band order.  </li> <li>Conservation principle: \u0394Reflectance checks whether corrections preserve brightness globally (no systematic over-darkening).  </li> <li>Geometric realism: Mask coverage and illumination correlation prevent interpreting shadowed or topographically inverted pixels as valid reflectance.  </li> <li>Spectral fidelity: RMSE and SAM compare corrected spectra to expected bandpasses, verifying physical sensor compatibility.</li> </ul>"},{"location":"pipeline/qa_panel/#how-to-interpret-the-panel","title":"How to Interpret the Panel","text":"<p>Each panel includes:</p> <ol> <li>Left: RGB quicklook using auto-selected bands (660, 560, 490 nm).  </li> <li>Uniform color tone: good illumination normalization.  </li> <li>Patchy shadows or gradients: check DTM alignment or BRDF model.</li> <li>Top-right: Pre (gray) vs Post (green) histograms.  </li> <li>Slight narrowing: normal (flattening illumination gradients).  </li> <li>Severe shift left/right: over- or under-correction.</li> <li>Middle-right: \u0394Reflectance vs Wavelength curve (median \u00b1 IQR).  </li> <li>Smooth near-zero line: ideal.  </li> <li>Large band-specific spikes: band-specific sensor noise or cloud edges.</li> <li>Bottom-right: Convolution scatter (expected vs computed).  </li> <li>Points close to 1:1 line: good.  </li> <li>Systematic bias or slope \u2260 1: check wavelength alignment or FWHM mismatch.</li> <li>Footer: Metadata (flightline ID, date, package version, git SHA).</li> </ol>"},{"location":"pipeline/qa_panel/#quantitative-thresholds-for-not-good","title":"Quantitative Thresholds for \u201cNot Good\u201d","text":"Metric Acceptable Range \u201cNeeds Review\u201d \u201cProblematic\u201d Negatives % &lt; 0.5 % 0.5\u20132 % &gt; 2 % &gt;1.2 reflectance % &lt; 0.5 % 0.5\u20132 % &gt; 2 % \u0394Reflectance median &lt; 0.02 (normally good) &gt; 0.05 (over/under-correction) Brightness gain 0.9\u20131.1 0.85\u20130.9 / 1.1\u20131.15 &lt; 0.85 or &gt; 1.15 Convolution RMSE &lt; 0.02 0.02\u20130.05 &gt; 0.05 SAM (radians) &lt; 0.03 0.03\u20130.05 &gt; 0.05 Mask coverage &gt; 80 % 60\u201380 % &lt; 60 %"},{"location":"pipeline/qa_panel/#deciding-when-a-product-fails-qa","title":"Deciding When a Product Fails QA","text":"<p>Mark a product as Needs Review when: - \u2265 2 metrics fall in the \u201cNeeds Review\u201d column, or - Any single metric hits the \u201cProblematic\u201d range.</p> <p>Mark a product as Fail when: - &gt; 10 % of bands exceed thresholds (e.g., \u0394Reflectance &gt; 0.05), - Wavelengths are missing or non-monotonic, - Convolution RMSE &gt; 0.05 and SAM &gt; 0.05, - Mask coverage &lt; 60 %.</p> <p>All QA results are summarized in the sidecar JSON (<code>*_qa.json</code>), enabling programmatic filtering.</p>"},{"location":"pipeline/qa_panel/#next-steps-after-qa-flags","title":"Next Steps After QA Flags","text":"Issue Likely Cause Recommended Fix Many negatives or high reflectance Mis-scaled input, wrong gain offset Re-run brightness correction or check calibration constants. Non-monotonic wavelengths Corrupted or edited header Re-export ENVI or fix <code>wavelength</code> list manually. Large \u0394Reflectance Over-aggressive BRDF correction Adjust BRDF parameters or review illumination mask. High RMSE/SAM Wrong sensor response curves Verify target sensor config file. Low mask coverage Cloud or DTM mask mismatch Improve masking or fill small gaps before QA."},{"location":"pipeline/qa_panel/#automating-qa-review","title":"Automating QA Review","text":"<p>Each QA JSON includes numeric thresholds. You can quickly summarize or flag tiles programmatically:</p> <pre><code>import json, glob\nbad = []\nfor f in glob.glob(\"*/**/*_qa.json\", recursive=True):\n    q = json.load(open(f))\n    if (\n        q[\"negatives_pct\"] &gt; 2.0\n        or q.get(\"overbright_pct\", 0) &gt; 2.0\n        or q[\"mask\"][\"valid_pct\"] &lt; 60\n    ):\n        bad.append(f)\nprint(\"Tiles needing review:\", bad)\n</code></pre>"},{"location":"pipeline/stages/","title":"Pipeline Stages","text":"<p>TL;DR: This pipeline takes NEON hyperspectral HDF5, produces corrected ENVI cubes, optionally convolves them to other sensors, then exports tidy Parquet for analysis\u2014plus a visual QA panel.</p> <pre><code>flowchart TD\n  A[H5 download\\n*_directional_reflectance.h5] --&gt; B[ENVI export\\n*_envi.img/.hdr]\n  B --&gt; C[Topo + BRDF correction\\n*_brdfandtopo_corrected_envi.* + JSON]\n  C --&gt; D[Cross-sensor convolution\\nTM/ETM+/OLI/OLI-2/MicaSense]\n  D --&gt; E[Parquet export\\nall ENVI products]\n  E --&gt; F[DuckDB merge\\n&lt;prefix&gt;_merged_pixel_extraction.parquet]\n  F --&gt; G[QA panel\\n&lt;prefix&gt;_qa.png]\n</code></pre>"},{"location":"pipeline/stages/#1-download-neon-hdf5","title":"1) Download NEON HDF5","text":"<p>Purpose Pull <code>*_directional_reflectance.h5</code> tiles. Inputs \u2192 Outputs H5 \u2192 same (no transform). Run it <pre><code>cross-sensor-cal download --site NIWO --year 2023 --tiles L019-1 L020-1\n</code></pre> Pitfalls Existing files are skipped (expected).</p>"},{"location":"pipeline/stages/#2-export-to-envi","title":"2) Export to ENVI","text":"<p>Purpose Convert H5 \u2192 ENVI <code>.img/.hdr</code>. Inputs \u2192 Outputs H5 \u2192 <code>*_directional_reflectance_envi.img/.hdr</code>. Run it <pre><code>cross-sensor-cal envi-export --in data/*.h5 --out envi/\n</code></pre> Pitfalls Disk usage; <code>_envi</code> suffix used downstream.</p>"},{"location":"pipeline/stages/#3-topographic-brdf-correction","title":"3) Topographic + BRDF correction","text":"<p>Purpose Apply topo/BRDF; write sidecar JSON with parameters. Optional: run <code>apply_brightness_correction</code> on cubes in Python before this stage to harmonise illumination; the QA JSON will expose the per-band gain/offsets. Inputs \u2192 Outputs <code>*_envi.img/.hdr</code> \u2192 <code>*_brdfandtopo_corrected_envi.img/.hdr</code> + <code>*_brdfandtopo_corrected_envi.json</code>. Run it <pre><code>cross-sensor-cal correct --in envi/*_envi.img --dtm dtm/NIWO.tif --out corrected/\n</code></pre> Pitfalls If JSON is missing, correction didn\u2019t run; fix paths and rerun.</p>"},{"location":"pipeline/stages/#4-cross-sensor-convolution","title":"4) Cross-sensor convolution","text":"<p>Purpose Resample to target sensor bandpasses. Inputs \u2192 Outputs corrected ENVI \u2192 <code>*_resampled_&lt;sensor&gt;_envi.img/.hdr</code> inside <code>Convolution_Reflectance_Resample_&lt;sensor&gt;</code> directories. Run it <pre><code>cross-sensor-cal convolve --in corrected/*_brdfandtopo_corrected_envi.img --sensor OLI --out convolved/\n</code></pre> Pitfalls HDR must contain a valid wavelength block.</p>"},{"location":"pipeline/stages/#5-parquet-export","title":"5) Parquet export","text":"<p>Purpose Flatten ENVI to tidy Parquet. Inputs \u2192 Outputs ENVI products \u2192 <code>*.parquet</code>. Run it <pre><code>cross-sensor-cal export-parquet --in corrected/*.img Convolution_Reflectance_Resample_*/*.img --out parquet/\n</code></pre> Pitfalls Use <code>--chunksize</code> to keep memory low.</p>"},{"location":"pipeline/stages/#6-duckdb-merge","title":"6) DuckDB merge","text":"<p>Purpose Merge parquet tables into one analysis-ready file. Inputs \u2192 Outputs <code>parquet/*.parquet</code> \u2192 <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code>. Run it <pre><code>cross-sensor-cal merge-duckdb --in parquet/*.parquet --out merged/&lt;prefix&gt;_merged_pixel_extraction.parquet\n</code></pre> Pitfalls Ensure filenames follow Outputs conventions before merging.</p>"},{"location":"pipeline/stages/#7-qa-panel","title":"7) QA panel","text":"<p>Purpose Visual checks and metrics; saves <code>&lt;prefix&gt;_qa.png</code> and <code>&lt;prefix&gt;_qa.json</code>. Run it <pre><code>cscal-qa --base-folder processed/flightlines --quick\n</code></pre> Pitfalls Deterministic quick mode samples ~25k pixels; rerun with <code>--full</code> if you need denser stats.</p>"},{"location":"pipeline/stages/#file-naming-at-a-glance","title":"File-naming at a glance","text":"<ul> <li>Raw H5 \u2192 <code>..._directional_reflectance.h5</code></li> <li>ENVI export \u2192 <code>..._directional_reflectance_envi.img/.hdr</code></li> <li>Corrected \u2192 <code>..._brdfandtopo_corrected_envi.img/.hdr</code> + JSON</li> <li>Convolved \u2192 <code>..._brdfandtopo_corrected_envi_&lt;sensor&gt;.img/.hdr</code></li> <li>Merged parquet \u2192 <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code></li> <li>QA \u2192 <code>&lt;prefix&gt;_qa.png</code></li> </ul>"},{"location":"reference/configuration/","title":"Configuration","text":"<p>When do I need this? When you want to override defaults for correction/convolution or run headless in CI. Includes examples and links to producing/consuming stages.</p>"},{"location":"reference/configuration/#purpose","title":"Purpose","text":"<p>Explain optional overrides that change how Pipeline Stages behave\u2014especially Stage 3 (correction), Stage 4 (convolution), and Stage 6 (merge).</p>"},{"location":"reference/configuration/#inputs","title":"Inputs","text":"<ul> <li>YAML or JSON files loaded via <code>--config</code></li> <li>Environment variables read by orchestrators</li> <li>Inline CLI overrides such as <code>--sensor</code> or <code>--max-workers</code></li> </ul>"},{"location":"reference/configuration/#outputs","title":"Outputs","text":"<p>A normalized configuration object passed into each stage; affects artifact naming in Outputs.</p>"},{"location":"reference/configuration/#brightness-configuration","title":"Brightness configuration","text":"<p>Brightness adjustments between sensor systems (e.g., Landsat\u2192MicaSense) are defined via small JSON files shipped with the package:</p> <ul> <li>Location: <code>cross_sensor_cal/data/brightness/*.json</code></li> <li>Loader: <code>cross_sensor_cal.load_brightness_coefficients(system_pair)</code></li> </ul> <p>Example (<code>landsat_to_micasense.json</code>):</p> <pre><code>{\n  \"system_pair\": \"landsat_to_micasense\",\n  \"unit\": \"percent\",\n  \"bands\": {\n    \"1\": -7.40,\n    \"2\": -2.75,\n    \"3\": -6.94,\n    \"4\": -10.12,\n    \"5\": -6.65,\n    \"6\": -2.74,\n    \"7\": -1.11\n  }\n}\n</code></pre> <p>These coefficients are applied to Landsat convolution products as: <code>L_adj = L_raw * (1 + coeff / 100)</code> and are surfaced in:</p> <ul> <li>The brightness summary table (per-band values).</li> <li>The QA JSON (<code>brightness_coefficients</code>).</li> <li>The multi-page QA PDF (Page 3).</li> </ul>"},{"location":"reference/configuration/#how-to-change-coefficients","title":"How to change coefficients","text":"<ol> <li>Create a new JSON file under <code>cross_sensor_cal/data/brightness/</code>.</li> <li>Set <code>\"system_pair\"</code> and a <code>\"bands\"</code> mapping of 1-based band indices to    percent adjustments.</li> <li>Call <code>load_brightness_coefficients(\"&lt;your_system_pair&gt;\")</code> from your    pipeline extension or configuration.</li> </ol>"},{"location":"reference/configuration/#run-it","title":"Run it","text":"<pre><code>cscal-pipeline --base-folder out --config configs/niwo_gpu.yaml \\\n  --site-code NIWO --year-month 2023-08 \\\n  --flight-lines NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\n</code></pre> <pre><code>from cross_sensor_cal.config import load_config\n\ncfg = load_config(\"configs/niwo_gpu.yaml\")\nprint(cfg.pipeline.stages[\"convolution\"].sensors)\n</code></pre>"},{"location":"reference/configuration/#pitfalls","title":"Pitfalls","text":"<ul> <li>Missing sensor definitions lead to empty Stage 4 outputs\u2014double-check <code>sensors:</code> blocks.</li> <li>Keep path references relative to the working directory used during Stage 2\u20137 execution.</li> <li>For CI, pin random seeds where applicable to keep QA metrics stable.</li> </ul>"},{"location":"reference/extending/","title":"Extending","text":"<p>When do I need this? When adding a new target sensor or swapping readers/writers; follow the extension points listed here.</p>"},{"location":"reference/extending/#purpose","title":"Purpose","text":"<p>Guide contributions that add sensors to Stage 4 or new exporters feeding Outputs.</p>"},{"location":"reference/extending/#inputs","title":"Inputs","text":"<ul> <li>Bandpass definitions (CSV/JSON) for the new sensor</li> <li>Implementation classes under <code>cross_sensor_cal</code> to register</li> <li>Tests covering the new workflow</li> </ul>"},{"location":"reference/extending/#outputs","title":"Outputs","text":"<p>Updated convolution products and schemas consumed by Parquet export and Merge.</p>"},{"location":"reference/extending/#run-it","title":"Run it","text":"<pre><code>pytest tests/convolution/test_new_sensor.py\n</code></pre> <pre><code>from cross_sensor_cal.convolution import registry\n\nprint(registry.available_sensors())\n</code></pre>"},{"location":"reference/extending/#pitfalls","title":"Pitfalls","text":"<ul> <li>Forgetting to update schemas will break Stage 6 merges.</li> <li>Ship lightbox-friendly QA thumbnails when adding new visualization layers.</li> <li>Document new sensors in Pipeline Stages and Troubleshooting.</li> </ul>"},{"location":"reference/schemas/","title":"Schemas","text":"<p>When do I need this? When validating outputs or writing downstream tooling that expects consistent columns and metadata.</p>"},{"location":"reference/schemas/#purpose","title":"Purpose","text":"<p>Document the shape of artifacts emitted by Stage 5 (Parquet export) and Stage 6 (merge) so you can trust what Outputs deliver.</p>"},{"location":"reference/schemas/#inputs","title":"Inputs","text":"<ul> <li>Schema JSON files bundled with the project (see <code>schemas/</code> in the repo)</li> <li>Sample Parquet files from Parquet export or Merge</li> </ul>"},{"location":"reference/schemas/#outputs","title":"Outputs","text":"<p>Validation reports confirming column presence, dtypes, and metadata blocks for ENVI-derived tables.</p>"},{"location":"reference/schemas/#run-it","title":"Run it","text":"<pre><code>python scripts/validate_schema.py parquet/demo_brdfandtopo_corrected_envi.parquet schemas/parquet_brdfandtopo.json\n</code></pre> <pre><code>import json\nimport pyarrow.parquet as pq\n\nwith open(\"schemas/parquet_brdfandtopo.json\", \"r\", encoding=\"utf-8\") as fp:\n    spec = json.load(fp)\nmeta = pq.read_table(\"parquet/demo_brdfandtopo_corrected_envi.parquet\")\nmissing = set(spec[\"columns\"]) - set(meta.schema.names)\nprint(f\"Missing columns: {sorted(missing)}\")\n</code></pre>"},{"location":"reference/schemas/#pitfalls","title":"Pitfalls","text":"<ul> <li>Always match schema files to the correct stage; merged tables include joined metadata absent in Stage 5 outputs.</li> <li>Case-sensitive column names can fail equality checks\u2014normalize before comparing.</li> <li>When adding sensors, update both the schema and the Troubleshooting page to reflect new failure modes.</li> </ul>"},{"location":"reference/validation/","title":"Validation","text":"<p>Purpose: This section explains the QA tests in quantitative terms.</p> <p>Validation routines in <code>cross_sensor_cal.qa_plots</code> compute physical and statistical diagnostics designed to be interpretable by scientists. They check not only numeric stability but physical plausibility (reflectance bounds, wavelength order, spectral coherence).</p> <p>For each metric, expected ranges are derived from NEON calibration standards and cross-sensor comparisons (Landsat OLI, Sentinel-2 MSI, and MicaSense). These ranges were validated empirically across 2021\u20132024 flight lines and provide confidence that corrected products maintain absolute reflectance fidelity within \u00b12 %.</p>"},{"location":"reference/validation/#reflectance-test","title":"\u0394Reflectance Test","text":"<p>Measures the magnitude of change introduced by correction; large uniform shifts imply over- or under-correction.</p>"},{"location":"reference/validation/#convolution-accuracy-test","title":"Convolution Accuracy Test","text":"<p>Computes RMSE and SAM between expected and computed spectral bands; high errors indicate sensor response mismatch.</p>"},{"location":"reference/validation/#brightness-gainoffset-check","title":"Brightness Gain/Offset Check","text":"<p>Evaluates brightness normalization stability; flags gain &lt; 0.85 or &gt; 1.15.</p>"},{"location":"reference/validation/#landsatmicasense-brightness-adjustment","title":"Landsat\u2194MicaSense brightness adjustment","text":"<p>When the pipeline convolves corrected NEON cubes to Landsat bands, it now applies a small per-band brightness adjustment so the results align with a MicaSense reference.</p> <ul> <li>Coefficients live in <code>data/brightness/landsat_to_micasense.json</code> and are shipped with the   package.</li> <li>The applied values are written into QA JSON files under <code>brightness_coefficients</code> and are   also rendered on Page 3 of the QA PDF alongside other issues.</li> <li>The Landsat ENVI headers record the same coefficients so downstream tools can reproduce   the exact multiplicative adjustment (<code>L_adj = L_raw * (1 + coeff / 100)</code>).</li> </ul> <p>See detailed interpretation \u2192</p> <p>When do I need this? When a stage fails or a QA smell appears; validate inputs/outputs against known-good schema.</p>"},{"location":"reference/validation/#purpose","title":"Purpose","text":"<p>Provide targeted checks for Pipeline Stages that frequently fail\u2014especially Stage 3 corrections and Stage 6 merges.</p>"},{"location":"reference/validation/#inputs","title":"Inputs","text":"<ul> <li>Paths to ENVI <code>.img/.hdr</code> or Parquet files from Outputs</li> <li>Schema definitions or expected ranges for QA metrics</li> </ul>"},{"location":"reference/validation/#outputs","title":"Outputs","text":"<p>Console reports or CSV summaries highlighting missing bands, mismatched wavelengths, or schema drift.</p>"},{"location":"reference/validation/#run-it","title":"Run it","text":"<pre><code>python scripts/check_envi_headers.py corrected/*_brdfandtopo_corrected_envi.hdr\npython scripts/validate_schema.py merged/demo_merged_pixel_extraction.parquet schemas/merged_schema.json\n</code></pre> <pre><code>from cross_sensor_cal.validation import validate_parquet\n\nvalidate_parquet(\"merged/demo_merged_pixel_extraction.parquet\", strict=True)\n</code></pre>"},{"location":"reference/validation/#pitfalls","title":"Pitfalls","text":"<ul> <li>Skipping validation can hide silent failures; automate checks in CI before trusting Stage 7 QA images.</li> <li>Keep Ray workers pinned to the same package version to avoid mixed schema outputs.</li> <li>When QA histograms look wrong, verify both the input parquet and the ENVI wavelength metadata.</li> </ul>"},{"location":"usage/cli/","title":"CLI &amp; Examples","text":""},{"location":"usage/cli/#full-pipeline-one-tile","title":"Full pipeline (one tile)","text":"<p>Purpose Run every stage end-to-end for a single flight line.</p> <p>Inputs Base folder, NEON site/month/product, flight line IDs.</p> <p>Outputs Per-flight directory with ENVI exports, corrected/resampled cubes, Parquet tables, merged parquet, QA panel PNG, QA PDF, and QA JSON.</p> <p>Run it <pre><code>cscal-pipeline --base-folder out --site-code NIWO --year-month 2023-08 \\\n  --product-code DP1.30006.001 \\\n  --flight-lines NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance \\\n  --max-workers 2\n</code></pre> Pitfalls High worker counts can exhaust <code>/dev/shm</code>; rerun with the same arguments to resume safely.</p> <p>The CLI logs are designed to be affirmative. Messages like:</p> <p>\ud83d\udce6 No existing ENVI export detected \u2014 creating a new one from source data ...</p> <p>are normal and indicate that the tool is creating outputs for the first time. Only <code>WARNING</code> or <code>ERROR</code> messages require attention.</p>"},{"location":"usage/cli/#convolve-only","title":"Convolve only","text":"<p>Purpose Resample corrected ENVI cubes to a target sensor.</p> <p>Inputs Corrected ENVI <code>.img</code> files, target sensor code, output folder.</p> <p>Outputs <code>&lt;prefix&gt;_resampled_&lt;sensor&gt;_envi.img/.hdr</code> inside per-sensor resample folders.</p> <p>Run it <pre><code>cross-sensor-cal convolve --in corrected/*_brdfandtopo_corrected_envi.img --sensor OLI --out convolved/\n</code></pre> Pitfalls Ensure corrected HDR files include valid wavelength metadata.</p>"},{"location":"usage/cli/#export-parquet-only","title":"Export parquet only","text":"<p>Purpose Flatten ENVI products into tidy Parquet files.</p> <p>Inputs One or more ENVI <code>.img</code> paths (corrected and/or resampled) and an output directory.</p> <p>Outputs One Parquet per ENVI input plus logs describing chunk sizes.</p> <p>Run it <pre><code>cross-sensor-cal export-parquet --in corrected/*.img Convolution_Reflectance_Resample_*/*.img --out parquet/\n</code></pre> Pitfalls Use <code>--chunksize</code> when RAM is limited.</p>"},{"location":"usage/cli/#merge-qa","title":"Merge + QA","text":"<p>Purpose Consolidate product Parquet tables and rebuild QA panels.</p> <p>Inputs Set of Parquet files, target merged filename, optional QA output directory.</p> <p>Outputs <code>&lt;prefix&gt;_merged_pixel_extraction.parquet</code>, <code>&lt;prefix&gt;_qa.png</code>, <code>&lt;prefix&gt;_qa.pdf</code>, and <code>&lt;prefix&gt;_qa.json</code>.</p> <p>Run it <pre><code>cross-sensor-cal merge-duckdb --in parquet/*.parquet --out merged/demo_merged_pixel_extraction.parquet\ncross-sensor-cal qa-panel --merged merged/demo_merged_pixel_extraction.parquet --out qa/\n</code></pre> Pitfalls <code>merge-duckdb</code> expects consistent schemas; if QA fails, check Troubleshooting.</p>"},{"location":"usage/cli/#minimal-python-equivalent","title":"Minimal Python equivalent","text":"<pre><code>from cross_sensor_cal import go_forth_and_multiply\n\ngo_forth_and_multiply(\n    base_folder=\"out\",\n    site_code=\"NIWO\",\n    year_month=\"2023-08\",\n    product_code=\"DP1.30006.001\",\n    flight_lines=[\"NEON_D13_NIWO_DP1_L020-1_20230815_directional_reflectance\"],\n    max_workers=2,\n)\n</code></pre>"},{"location":"usage/cli/#qa","title":"QA","text":"<p>The pipeline saves:</p> <ul> <li><code>&lt;prefix&gt;_qa.png</code> \u2013 a compact single-page QA panel.</li> <li><code>&lt;prefix&gt;_qa.pdf</code> \u2013 a multi-page QA report (ENVI overview, topo/BRDF diagnostics, and additional QA metrics).</li> <li><code>&lt;prefix&gt;_qa.json</code> \u2013 machine-readable QA metrics, including header, mask, convolution error, and brightness coefficients when applied.</li> </ul>"},{"location":"usage/parquet_preview/","title":"Parquet Preview","text":"pandasDuckDBpolars <pre><code>import pandas as pd\ndf = pd.read_parquet(\"merged/demo_merged_pixel_extraction.parquet\")\ndf.head()\nprint([c for c in df.columns if c.startswith(\"band_\")][:10])\n</code></pre> <pre><code>import duckdb\ncon = duckdb.connect()\ncon.execute(\"SELECT * FROM 'merged/demo_merged_pixel_extraction.parquet' LIMIT 5\").df()\n</code></pre> <pre><code>import polars as pl\ndf = pl.read_parquet(\"merged/demo_merged_pixel_extraction.parquet\")\ndf.head(5)\n</code></pre>"}]}