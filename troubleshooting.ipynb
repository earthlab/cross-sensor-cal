{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05c4ca96-6308-491d-bcdf-91916f749634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spectral in /opt/conda/envs/macrosystems/lib/python3.10/site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/macrosystems/lib/python3.10/site-packages (from spectral) (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "435ae824-88b8-44e3-8acb-09c91766dea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "['ENVIProcessor', 'GradientBoostingRegressor', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'apply_topo_and_brdf_corrections', 'boosted_quantile_plot', 'boosted_quantile_plot_by_sensor', 'box', 'clean_data_and_write_to_csv', 'concatenate_sensors', 'control_function', 'download_neon_file', 'download_neon_flight_lines', 'extract_overlapping_layers_to_2d_dataframe', 'find_raster_files', 'fit_models_with_different_alpha', 'flight_lines_to_envi', 'generate_config_json', 'generate_correction_configs', 'generate_correction_configs_for_directory', 'get_spectral_data_and_wavelengths', 'glob', 'go_forth_and_multiply', 'gpd', 'h5py', 'ht', 'jefe', 'json', 'load_and_combine_rasters', 'load_spectra', 'mask', 'np', 'os', 'pd', 'plot_each_sensor_with_highlight', 'plot_spectral_data', 'plot_with_highlighted_sensors', 'plt', 'prepare_spectral_data', 'process_all_subdirectories', 'process_and_flatten_array', 'process_hdf5_with_neon2envi', 'random', 'rasterio', 'rasterize', 'rasterize_polygons_to_match_envi', 'ray', 'requests', 'resample_translation_to_other_sensors', 'reshape_spectra', 'show', 'show_rgb', 'subprocess', 'time', 'translate_to_other_sensors']\n"
     ]
    }
   ],
   "source": [
    "### Loading Earth Lab Spectral Tools\n",
    "\n",
    "# 1. Enable autoreload in your Jupyter Notebook:\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# 2. Import the custom tools module:\n",
    "\n",
    "import spectral_unmixing_tools as el_spectral\n",
    "\n",
    "# 3. Verify that the tools loaded correctly by printing the module's directory:\n",
    "\n",
    "print(dir(el_spectral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68934a86-6822-4dbe-90ba-46352c11f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf86f6a9-b8c3-4f4c-ab24-770ce3ee5b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 20:41:07,520\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.11gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-12-06 20:41:08,662\tINFO worker.py:1673 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray task completed successfully: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-12-06 20:42:08,625 E 70019 70019] (raylet) node_manager.cc:3035: 4 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: f0145d10ec123932af3fd1be24a2b7c32bec4f48e9d75ae483350d4d, IP: 10.34.32.21) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.34.32.21`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()\n",
    "@ray.remote\n",
    "def test_task(x):\n",
    "    return x * 2\n",
    "\n",
    "result = ray.get(test_task.remote(5))\n",
    "print(f\"Ray task completed successfully: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "309f9ad2-bd7d-47d8-aabc-3f5abd65efb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting topo and BRDF correction. This takes a long time.\n",
      "Processing folder: NIWOT_calibration_flight_08_2020/NEON_D13_NIWO_DP1_20200807_170802_reflectance\n",
      "Looking for JSON file: NIWOT_calibration_flight_08_2020/NEON_D13_NIWO_DP1_20200807_170802_reflectance/NEON_D13_NIWO_DP1_20200807_170802_reflectance_config__envi.json\n",
      "Error executing command: /opt/conda/envs/macrosystems/bin/python image_correct.py NIWOT_calibration_flight_08_2020/NEON_D13_NIWO_DP1_20200807_170802_reflectance/NEON_D13_NIWO_DP1_20200807_170802_reflectance_config__envi.json\n",
      "Standard Output: NIWOT_calibration_flight_08_2020/NEON_D13_NIWO_DP1_20200807_170802_reflectance/NEON_D13_NIWO_DP1_20200807_170802_reflectance_config__envi.json\n",
      "Using 1 CPUs.\n",
      "\n",
      "Error Output: 2024-12-06 20:45:00,494\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.36gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-12-06 20:45:01,625\tINFO worker.py:1673 -- Started a local Ray instance.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/data-store/cross-sensor-cal/image_correct.py\", line 261, in <module>\n",
      "    main()\n",
      "  File \"/home/jovyan/data-store/cross-sensor-cal/image_correct.py\", line 79, in main\n",
      "    _ = ray.get([a.read_file.remote(image,config_dict['file_type'],\n",
      "  File \"/opt/conda/envs/macrosystems/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/macrosystems/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/macrosystems/lib/python3.10/site-packages/ray/_private/worker.py\", line 2565, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "def apply_topo_and_brdf_corrections(base_folder_path, conda_env_path='/opt/conda/envs/macrosystems'):\n",
    "    # Construct the full path to the Python executable in the specified Conda environment\n",
    "    python_executable = os.path.join(conda_env_path, \"bin\", \"python\")\n",
    "    print(\"Starting topo and BRDF correction. This takes a long time.\")\n",
    "    \n",
    "    # Find all subfolders in the base folder\n",
    "    subfolders = [f for f in glob.glob(os.path.join(base_folder_path, '*')) if os.path.isdir(f)]\n",
    "    \n",
    "    for folder in subfolders:\n",
    "        folder_name = os.path.basename(os.path.normpath(folder))\n",
    "        json_file_name = f\"{folder_name}_config__envi.json\"\n",
    "        json_file_path = os.path.join(folder, json_file_name)  # Removed unnecessary slash\n",
    "        \n",
    "        print(f\"Processing folder: {folder}\")\n",
    "        print(f\"Looking for JSON file: {json_file_path}\")\n",
    "        \n",
    "        # Check if the JSON file exists\n",
    "        if os.path.isfile(json_file_path):\n",
    "            # Call the script with the JSON file path\n",
    "            command = f\"{python_executable} image_correct.py {json_file_path}\"\n",
    "            process = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "            \n",
    "            if process.returncode != 0:\n",
    "                print(f\"Error executing command: {command}\")\n",
    "                print(f\"Standard Output: {process.stdout}\")\n",
    "                print(f\"Error Output: {process.stderr}\")\n",
    "            else:\n",
    "                print(f\"Successfully processed: {json_file_path}\")\n",
    "                print(f\"Standard Output: {process.stdout}\")\n",
    "        else:\n",
    "            print(f\"JSON file not found: {json_file_path}\")\n",
    "    \n",
    "    print(\"All done!\")\n",
    "\n",
    "# Example call to the function\n",
    "base_folder = \"NIWOT_calibration_flight_08_2020\"\n",
    "apply_topo_and_brdf_corrections(base_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b7716a0-3780-4248-941d-00fd4f108be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting topo and BRDF correction. This takes a long time.\n",
      "Processing folder: NIWOT_calibration_flight_08_2020/NEON_D13_NIWO_DP1_20200807_170802_reflectance\n",
      "Looking for JSON file: NIWOT_calibration_flight_08_2020/NEON_D13_NIWO_DP1_20200807_170802_reflectance/NEON_D13_NIWO_DP1_20200807_170802_reflectance_config__envi.json\n",
      "Error executing command: /opt/conda/envs/macrosystems/bin/python image_correct.py NIWOT_calibration_flight_08_2020/NEON_D13_NIWO_DP1_20200807_170802_reflectance/NEON_D13_NIWO_DP1_20200807_170802_reflectance_config__envi.json\n",
      "Standard Output: NIWOT_calibration_flight_08_2020/NEON_D13_NIWO_DP1_20200807_170802_reflectance/NEON_D13_NIWO_DP1_20200807_170802_reflectance_config__envi.json\n",
      "Using 1 CPUs.\n",
      "\n",
      "Error Output: 2024-12-06 20:35:06,992\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.19gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-12-06 20:35:07,119\tINFO worker.py:1673 -- Started a local Ray instance.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/data-store/cross-sensor-cal/image_correct.py\", line 261, in <module>\n",
      "    main()\n",
      "  File \"/home/jovyan/data-store/cross-sensor-cal/image_correct.py\", line 79, in main\n",
      "    _ = ray.get([a.read_file.remote(image,config_dict['file_type'],\n",
      "  File \"/opt/conda/envs/macrosystems/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/macrosystems/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/macrosystems/lib/python3.10/site-packages/ray/_private/worker.py\", line 2565, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "#~13 minutes per file. 5 files here for ~65 minute runtime\n",
    "base_folder = \"NIWOT_calibration_flight_08_2020\"\n",
    "apply_topo_and_brdf_corrections(base_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b834672-afb9-4f62-99a2-4432dd8b87a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage: 5.0%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def log_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Memory Usage: {memory.percent}%\")\n",
    "\n",
    "log_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba322017-678e-4fb3-a6f4-f71a11fe7a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Memory: 473.94 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "available_memory = psutil.virtual_memory().available\n",
    "print(f\"Available Memory: {available_memory / (1024 ** 3):.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macrosystems",
   "language": "python",
   "name": "macrosystems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
