{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175c36ca-226b-4031-8507-930368404839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def merge_random_sampled_csvs(input_folder: str, percent_sites: float = 100.0, percent_pixels: float = 1.0, output_folder: str = \".\", min_age_minutes: int = 10):\n",
    "    \"\"\"\n",
    "    Merges a subset of CSV files and a subset of rows from each file into a single CSV.\n",
    "    The output file is named after the input folder and includes a progress bar.\n",
    "    Returns a list of skipped files due to errors.\n",
    "\n",
    "    Parameters:\n",
    "        input_folder (str): Path to the folder containing CSV files.\n",
    "        percent_sites (float): Percentage of files to randomly select (default: 100%).\n",
    "        percent_pixels (float): Percentage of rows to randomly select from each file (default: 1%).\n",
    "        output_folder (str): Path to save the merged output CSV.\n",
    "        min_age_minutes (int): Minimum age (in minutes) a file must be before processing (default: 10).\n",
    "\n",
    "    Returns:\n",
    "        list: List of files that were skipped due to errors.\n",
    "    \"\"\"\n",
    "    folder_name = os.path.basename(os.path.normpath(input_folder))\n",
    "    output_file = os.path.join(output_folder, f\"{folder_name}_summary.csv\")\n",
    "\n",
    "    # Skip processing if summary already exists\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"‚úÖ Skipping {folder_name}: Summary file already exists.\")\n",
    "        return []\n",
    "\n",
    "    # Get current time and filter out recently updated files\n",
    "    current_time = time.time()\n",
    "    csv_files = [\n",
    "        os.path.join(input_folder, f) for f in os.listdir(input_folder)\n",
    "        if f.endswith('.csv') and (current_time - os.path.getmtime(os.path.join(input_folder, f)) > min_age_minutes * 60)\n",
    "    ]\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"Skipping {folder_name}: No CSV files found or all files are too new (<{min_age_minutes} min).\")\n",
    "        return []\n",
    "\n",
    "    num_files = max(1, int(len(csv_files) * (percent_sites / 100.0)))\n",
    "    num_files = min(num_files, len(csv_files))  # Ensure we don't select more than available\n",
    "    sampled_files = random.sample(csv_files, num_files)\n",
    "\n",
    "    merged_data = []\n",
    "    skipped_files = []\n",
    "\n",
    "    for file in tqdm(sampled_files, desc=f\"Processing {folder_name}\", unit=\"file\"):\n",
    "        try:\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "            num_rows = max(1, int(len(df) * (percent_pixels / 100.0)))\n",
    "            num_rows = min(num_rows, len(df))  # Ensure we don't sample more rows than available\n",
    "            sampled_rows = df.sample(n=num_rows, random_state=42)\n",
    "            merged_data.append(sampled_rows)\n",
    "        except Exception as e:\n",
    "            skipped_files.append((file, str(e)))\n",
    "\n",
    "    if merged_data:\n",
    "        final_df = pd.concat(merged_data, ignore_index=True)\n",
    "        try:\n",
    "            final_df.to_csv(output_file, index=False)\n",
    "            print(f\"‚úÖ Merged file saved to {output_file}\")\n",
    "        except OSError as e:\n",
    "            print(f\"‚ö†Ô∏è Remote I/O error while saving {output_file}: {e}\")\n",
    "            skipped_files.append((output_file, str(e)))\n",
    "    else:\n",
    "        print(f\"No data to merge in {folder_name}\")\n",
    "\n",
    "    return skipped_files\n",
    "\n",
    "\n",
    "def merge_all_folders_with_resume_and_retry(parent_directory: str, percent_sites: float = 100.0, percent_pixels: float = 1.0, summary_output_folder: str = \".\", max_retries: int = 3, min_age_minutes: int = 10):\n",
    "    \"\"\"\n",
    "    Applies the merge_random_sampled_csvs function to all subfolders within a parent directory,\n",
    "    excluding the 'summary' and 'Uncategorized' folders. If a folder fails, it will retry up to max_retries times.\n",
    "\n",
    "    Parameters:\n",
    "        parent_directory (str): Path to the parent directory containing multiple folders with CSV files.\n",
    "        percent_sites (float): Percentage of files to randomly select (default: 100%).\n",
    "        percent_pixels (float): Percentage of rows to randomly select from each file (default: 1%).\n",
    "        summary_output_folder (str): Path to save all summary CSV outputs.\n",
    "        max_retries (int): Number of times to retry failed folders (default: 3).\n",
    "        min_age_minutes (int): Minimum file age (in minutes) before processing (default: 10).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping folder names to lists of skipped files.\n",
    "    \"\"\"\n",
    "    skipped_files_report = {}\n",
    "    excluded_folders = {\"summary\", \"uncategorized\"}\n",
    "    \n",
    "    os.makedirs(summary_output_folder, exist_ok=True)\n",
    "\n",
    "    for attempt in range(max_retries + 1):\n",
    "        if attempt > 0:\n",
    "            print(f\"\\nüîÑ Retrying failed folders (Attempt {attempt}/{max_retries})...\\n\")\n",
    "\n",
    "        failed_folders = skipped_files_report.copy()\n",
    "        skipped_files_report = {}\n",
    "\n",
    "        folders_to_process = failed_folders.keys() if attempt > 0 else os.listdir(parent_directory)\n",
    "\n",
    "        for folder in sorted(folders_to_process):\n",
    "            folder_path = os.path.join(parent_directory, folder)\n",
    "            output_file = os.path.join(summary_output_folder, f\"{folder}_summary.csv\")\n",
    "\n",
    "            if os.path.isdir(folder_path) and folder.lower() not in excluded_folders:\n",
    "                if os.path.exists(output_file):\n",
    "                    print(f\"‚úÖ Skipping {folder}: Already processed.\")\n",
    "                    continue\n",
    "\n",
    "                print(f\"Processing folder: {folder}\")\n",
    "\n",
    "                try:\n",
    "                    skipped_files = merge_random_sampled_csvs(folder_path, percent_sites, percent_pixels, summary_output_folder, min_age_minutes)\n",
    "                    if skipped_files:\n",
    "                        skipped_files_report[folder] = skipped_files\n",
    "                except OSError as e:\n",
    "                    print(f\"‚ö†Ô∏è Remote I/O error on {folder}: {e}\")\n",
    "                    skipped_files_report[folder] = [(\"ERROR\", str(e))]\n",
    "\n",
    "        if not skipped_files_report:\n",
    "            print(\"‚úÖ All folders processed successfully.\")\n",
    "            break\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    if skipped_files_report:\n",
    "        print(\"\\n‚ùå Some folders still failed after retries:\", skipped_files_report)\n",
    "\n",
    "    return skipped_files_report\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d4798e6-eac9-45ce-98d5-ed8d4694dcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: .ipynb_checkpoints\n",
      "Skipping .ipynb_checkpoints: No CSV files found or all files are too new (<10 min).\n",
      "‚úÖ Skipping Landsat_5_TM: Already processed.\n",
      "‚úÖ Skipping Landsat_7_ETMplus: Already processed.\n",
      "‚úÖ Skipping Landsat_8_OLI: Already processed.\n",
      "Processing folder: Landsat_9_OLI-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Landsat_9_OLI-2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.50file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Remote I/O error while saving home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/Landsat_9_OLI-2_summary.csv: [Errno 121] Remote I/O error: 'home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/Landsat_9_OLI-2_summary.csv'\n",
      "Processing folder: MicaSense\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MicaSense: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:10<00:00,  1.09file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged file saved to home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/MicaSense_summary.csv\n",
      "Processing folder: MicaSense_to_match_OLI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MicaSense_to_match_OLI: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:14<00:00,  1.08s/file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged file saved to home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/MicaSense_to_match_OLI_summary.csv\n",
      "Processing folder: MicaSense_to_match_TM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MicaSense_to_match_TM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:12<00:00,  1.02file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Remote I/O error while saving home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/MicaSense_to_match_TM_summary.csv: [Errno 121] Remote I/O error: 'home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/MicaSense_to_match_TM_summary.csv'\n",
      "‚úÖ Skipping corrected: Already processed.\n",
      "Processing folder: original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing original: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.94s/file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged file saved to home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/original_summary.csv\n",
      "\n",
      "üîÑ Retrying failed folders (Attempt 1/3)...\n",
      "\n",
      "Processing folder: Landsat_9_OLI-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Landsat_9_OLI-2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:10<00:00,  1.11file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged file saved to home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/Landsat_9_OLI-2_summary.csv\n",
      "‚úÖ Skipping MicaSense_to_match_OLI: Already processed.\n",
      "Processing folder: MicaSense_to_match_TM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MicaSense_to_match_TM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:06<00:00,  2.03file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Remote I/O error while saving home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/MicaSense_to_match_TM_summary.csv: [Errno 121] Remote I/O error: 'home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/MicaSense_to_match_TM_summary.csv'\n",
      "‚úÖ Skipping original: Already processed.\n",
      "\n",
      "üîÑ Retrying failed folders (Attempt 2/3)...\n",
      "\n",
      "Processing folder: MicaSense_to_match_TM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MicaSense_to_match_TM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:10<00:00,  1.21file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged file saved to home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary/MicaSense_to_match_TM_summary.csv\n",
      "‚úÖ All folders processed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "skipped_files_report = merge_all_folders_with_resume_and_retry(\n",
    "    parent_directory=\"home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked\",\n",
    "    percent_sites=100,\n",
    "    percent_pixels=100,\n",
    "    summary_output_folder=\"home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/masked/summary\",\n",
    "    max_retries=3,\n",
    "    min_age_minutes=10  # Ensure files are at least 10 minutes old\n",
    ")\n",
    "\n",
    "# Print final skipped files\n",
    "for folder, skipped_files in skipped_files_report.items():\n",
    "    print(f\"\\n‚ùå Still failed after retries: {folder}\")\n",
    "    for file, error in skipped_files:\n",
    "        print(f\" - {file}: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3d6b0-df5a-47c2-b28e-cf465b0d77e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: Landsat_5_TM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Landsat_5_TM:   0%|          | 0/1 [00:00<?, ?file/s]"
     ]
    }
   ],
   "source": [
    "skipped_files_report = merge_all_folders_with_resume_and_retry(\n",
    "    parent_directory=\"home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/unmasked\",\n",
    "    percent_sites=100,\n",
    "    percent_pixels=100,\n",
    "    summary_output_folder=\"home/shared/earthlab/macrosystems/cross-sensor-cal/sorted_files/unmasked/summary\",\n",
    "    max_retries=3,\n",
    "    min_age_minutes=10  # Ensure files are at least 10 minutes old\n",
    ")\n",
    "\n",
    "# Print final skipped files\n",
    "for folder, skipped_files in skipped_files_report.items():\n",
    "    print(f\"\\n‚ùå Still failed after retries: {folder}\")\n",
    "    for file, error in skipped_files:\n",
    "        print(f\" - {file}: {error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macrosystems",
   "language": "python",
   "name": "macrosystems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
